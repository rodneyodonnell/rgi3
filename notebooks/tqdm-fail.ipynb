{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step run of alphazero self-play & training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_config_fields: {'n_head', 'n_embd', 'n_max_context', 'dropout', 'bias', 'n_layer'}\n",
      "train_config_fields: {'model_version', 'log_interval', 'grad_clip', 'decay_lr', 'eval_only', 'lr_decay_iters', 'eval_iters', 'eval_interval', 'min_lr', 'always_save_checkpoint', 'batch_size', 'compile', 'device', 'warmup_iters', 'gradient_accumulation_steps', 'learning_rate', 'beta1', 'max_epochs', 'dtype', 'wandb_log', 'weight_decay', 'model_name', 'beta2', 'max_iters'}\n",
      "Detected device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Game and players\n",
    "from rgi.rgizero.experiment import ExperimentRunner, ExperimentConfig\n",
    "from rgi.rgizero.data.trajectory_dataset import Vocab, print_dataset_stats, TrajectoryDataset\n",
    "from rgi.rgizero.evaluators import ActionHistoryTransformerEvaluator, AsyncNetworkEvaluator\n",
    "from rgi.rgizero.models.tuner import create_random_model\n",
    "\n",
    "import notebook_utils\n",
    "from notebook_utils import reload_local_modules\n",
    "\n",
    "device = notebook_utils.detect_device()\n",
    "\n",
    "## Disable for debugger stability?\n",
    "# # Allow asyncio to work with jupyter notebook\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# Increase numpy print width\n",
    "np.set_printoptions(linewidth=300)\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_GENERATIONS = True\n",
    "\n",
    "\n",
    "# Create Experiment Config\n",
    "experiment_config = ExperimentConfig(\n",
    "    experiment_name='smoketest-e2e',\n",
    "    game_name='connect4',\n",
    "    num_generations=3,\n",
    "    num_games_per_gen=50,\n",
    "    num_simulations=10,\n",
    "    model_size=\"tiny\",\n",
    "    train_batch_size=10,\n",
    "    max_training_epochs=2,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up game and experiment runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Runner initialized\n",
      "Game: connect4, Players: 2, Actions: [1, 2, 3, 4, 5, 6, 7]\n",
      "Data dir:  /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data\n",
      "Model dir:  /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models\n"
     ]
    }
   ],
   "source": [
    "from rgi.rgizero.data.trajectory_dataset import Vocab\n",
    "from rgi.rgizero.common import TOKENS\n",
    "\n",
    "# Initialize Experiment Runner\n",
    "experiment_base_dir = Path.cwd().parent / 'experiments'\n",
    "experiment_runner = ExperimentRunner(experiment_config, experiment_base_dir)\n",
    "game = experiment_runner.game\n",
    "action_vocab = experiment_runner.action_vocab\n",
    "n_max_context = experiment_runner.n_max_context\n",
    "\n",
    "DATA_DIR = experiment_runner.data_dir\n",
    "MODEL_DIR = experiment_runner.models_dir\n",
    "\n",
    "print('✅ Runner initialized')\n",
    "print(f'Game: {experiment_runner.config.game_name}, Players: {experiment_runner.num_players}, Actions: {list(game.base_game.all_actions())}')\n",
    "print('Data dir: ', DATA_DIR)\n",
    "print('Model dir: ', MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create random generation_0 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiment: smoketest-e2e\n",
      "Initializing Random Gen 0 model.\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-0.pt\n"
     ]
    }
   ],
   "source": [
    "# Initialize (creates Random Gen 0 if needed)\n",
    "model_0 = experiment_runner.initialize()\n",
    "current_model = model_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25.16s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "! rm -rf ../experiments/smoketest-e2e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generation 1 ===\n",
      "Playing 50 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:   0%|          | 0/50 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n",
      "Self Play: 100%|██████████| 50/50 [00:06<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 50 trajectories...\n",
      "Training model for gen 1...\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.7720, train_policy_loss:2.0774, train_value_loss:0.6946, val:2.7773, val_policy_loss:2.0808, val_value_loss:0.6965\n",
      "iter 0/5/5000: loss 2.7796, policy_loss:2.0794, value_loss:0.7002, time 0.48s, iter_time: 0.00ms\n",
      "iter 1/5/5000: loss 2.7671, policy_loss:2.0766, value_loss:0.6905, time 0.05s, iter_time: 51.92ms\n",
      "iter 2/5/5000: loss 2.7766, policy_loss:2.0775, value_loss:0.6990, time 0.02s, iter_time: 17.54ms\n",
      "iter 3/5/5000: loss 2.7661, policy_loss:2.0756, value_loss:0.6905, time 0.05s, iter_time: 48.67ms\n",
      "iter 4/5/5000: loss 2.7698, policy_loss:2.0765, value_loss:0.6933, time 0.09s, iter_time: 89.52ms\n",
      "iter 5/10/5000: loss 2.7732, policy_loss:2.0762, value_loss:0.6969, time 0.05s, iter_time: 0.00ms\n",
      "iter 6/10/5000: loss 2.7674, policy_loss:2.0761, value_loss:0.6913, time 0.05s, iter_time: 49.15ms\n",
      "iter 7/10/5000: loss 2.7738, policy_loss:2.0776, value_loss:0.6963, time 0.05s, iter_time: 46.03ms\n",
      "iter 8/10/5000: loss 2.7667, policy_loss:2.0772, value_loss:0.6895, time 0.05s, iter_time: 46.78ms\n",
      "iter 9/10/5000: loss 2.7808, policy_loss:2.0787, value_loss:0.7021, time 0.04s, iter_time: 44.43ms\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RUN_GENERATIONS:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m generation_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, experiment_config.num_generations+\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         current_model = \u001b[38;5;28;01mawait\u001b[39;00m experiment_runner.run_generation_step_async(generation_id, current_model)\n\u001b[32m      9\u001b[39m         dataset_path = experiment_runner.get_trajectory_path(generation_id)\n\u001b[32m     11\u001b[39m         \u001b[38;5;66;03m# print stats for visibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3-sync/src/rgi/rgizero/experiment.py:214\u001b[39m, in \u001b[36mExperimentRunner.run_generation_step_async\u001b[39m\u001b[34m(self, gen_id, current_model)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining model for gen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     updated_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m updated_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3-sync/src/rgi/rgizero/experiment.py:417\u001b[39m, in \u001b[36mExperimentRunner.train_generation\u001b[39m\u001b[34m(self, model, gen_id)\u001b[39m\n\u001b[32m    411\u001b[39m trainer = Trainer(\n\u001b[32m    412\u001b[39m     model=model, train_config=train_config, train_loader=train_loader, val_loader=val_loader, device=\u001b[38;5;28mself\u001b[39m.device\n\u001b[32m    413\u001b[39m )\n\u001b[32m    415\u001b[39m trainer.train()\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinal_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3-sync/src/rgi/rgizero/experiment.py:168\u001b[39m, in \u001b[36mExperimentRunner.save_model\u001b[39m\u001b[34m(self, model, gen_id, trainer_stats)\u001b[39m\n\u001b[32m    160\u001b[39m path = \u001b[38;5;28mself\u001b[39m.models_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgen-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    161\u001b[39m checkpoint = {\n\u001b[32m    162\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model.state_dict(),\n\u001b[32m    163\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m\"\u001b[39m: dataclasses.asdict(model.config),\n\u001b[32m   (...)\u001b[39m\u001b[32m    166\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnum_players\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.num_players,\n\u001b[32m    167\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/serialization.py:966\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    963\u001b[39m     f = os.fspath(f)\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    967\u001b[39m         _save(\n\u001b[32m    968\u001b[39m             obj,\n\u001b[32m    969\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    972\u001b[39m             _disable_byteorder_record,\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/serialization.py:828\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/serialization.py:792\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    786\u001b[39m         torch._C.PyTorchFileWriter(\n\u001b[32m    787\u001b[39m             \u001b[38;5;28mself\u001b[39m.file_stream, get_crc32_options(), _get_storage_alignment()\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    791\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_crc32_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_storage_alignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Parent directory /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models does not exist."
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "trajectory_paths_dict = {}\n",
    "model_dict = {0: model_0}\n",
    "\n",
    "current_model = model_dict[0]\n",
    "if RUN_GENERATIONS:\n",
    "    for generation_id in range(1, experiment_config.num_generations+1):\n",
    "        current_model = await experiment_runner.run_generation_step_async(generation_id, current_model)\n",
    "        dataset_path = experiment_runner.get_trajectory_path(generation_id)\n",
    "        \n",
    "        # print stats for visibility\n",
    "        print_dataset_stats(dataset_path, f'gen-{generation_id}', n_max_context, action_vocab)\n",
    "        \n",
    "        model_dict[generation_id] = current_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
