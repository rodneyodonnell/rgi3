{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step run of alphazero self-play & training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_config_fields: {'bias', 'n_layer', 'dropout', 'n_embd', 'n_head', 'n_max_context'}\n",
      "train_config_fields: {'max_epochs', 'min_lr', 'log_interval', 'eval_iters', 'learning_rate', 'compile', 'model_name', 'eval_interval', 'device', 'warmup_iters', 'always_save_checkpoint', 'lr_decay_iters', 'batch_size', 'wandb_log', 'beta1', 'max_iters', 'model_version', 'gradient_accumulation_steps', 'dtype', 'weight_decay', 'grad_clip', 'beta2', 'eval_only', 'decay_lr'}\n",
      "Detected device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Game and players\n",
    "from rgi.rgizero.experiment import ExperimentRunner, ExperimentConfig\n",
    "from rgi.rgizero.data.trajectory_dataset import Vocab, print_dataset_stats, TrajectoryDataset\n",
    "from rgi.rgizero.evaluators import ActionHistoryTransformerEvaluator, AsyncNetworkEvaluator\n",
    "from rgi.rgizero.models.tuner import create_random_model\n",
    "\n",
    "import notebook_utils\n",
    "from notebook_utils import reload_local_modules\n",
    "\n",
    "device = notebook_utils.detect_device()\n",
    "\n",
    "## Disable for debugger stability?\n",
    "# # Allow asyncio to work with jupyter notebook\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# Increase numpy print width\n",
    "np.set_printoptions(linewidth=300)\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_GENERATIONS = True\n",
    "\n",
    "\n",
    "# Create Experiment Config\n",
    "experiment_config = ExperimentConfig(\n",
    "    experiment_name='smoketest-e2e-v2',\n",
    "    parent_experiment_name='smoketest-e2e',\n",
    "    game_name='connect4',\n",
    "    num_generations=5,\n",
    "    num_games_per_gen=10_000,\n",
    "    num_simulations=50,\n",
    "    model_size=\"tiny\",\n",
    "    train_batch_size=10,\n",
    "    max_training_epochs=2,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up game and experiment runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Runner initialized\n",
      "Game: connect4, Players: 2, Actions: [1, 2, 3, 4, 5, 6, 7]\n",
      "Data dir:  /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data\n",
      "Model dir:  /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/models\n"
     ]
    }
   ],
   "source": [
    "from rgi.rgizero.data.trajectory_dataset import Vocab\n",
    "from rgi.rgizero.common import TOKENS\n",
    "\n",
    "# Initialize Experiment Runner\n",
    "experiment_base_dir = Path.cwd().parent / 'experiments'\n",
    "experiment_runner = ExperimentRunner(experiment_config, experiment_base_dir)\n",
    "game = experiment_runner.game\n",
    "action_vocab = experiment_runner.action_vocab\n",
    "n_max_context = experiment_runner.n_max_context\n",
    "\n",
    "DATA_DIR = experiment_runner.data_dir\n",
    "MODEL_DIR = experiment_runner.models_dir\n",
    "\n",
    "print('✅ Runner initialized')\n",
    "print(f'Game: {experiment_runner.config.game_name}, Players: {experiment_runner.num_players}, Actions: {list(game.base_game.all_actions())}')\n",
    "print('Data dir: ', DATA_DIR)\n",
    "print('Model dir: ', MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create random generation_0 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiment: smoketest-e2e-v2\n",
      "Loading existing Gen 0 model.\n"
     ]
    }
   ],
   "source": [
    "# Initialize (creates Random Gen 0 if needed)\n",
    "model_0 = experiment_runner.initialize()\n",
    "current_model = model_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generation 1 ===\n",
      "Using forked data for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1\n",
      "Dataset for gen 1 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1. Skipping play.\n",
      "Using forked model for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-1.pt\n",
      "Model for gen 1 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-1.pt. Loading.\n",
      "Using forked model for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-1.pt\n",
      "Using forked data for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1\n",
      "Dataset Stats:\n",
      "  Trajectories: 1000\n",
      "  Total actions: 14552\n",
      "  Avg trajectory length: 14.55\n",
      "Prefix Stats:\n",
      "actions=(): 1000 win=618 loss=382 draw=0 win1%=61.80 model-win1%=46.08\n",
      "actions=(1,): 157 win=80 loss=77 draw=0 win1%=50.96 model-win1%=59.98\n",
      "actions=(2,): 124 win=79 loss=45 draw=0 win1%=63.71 model-win1%=58.56\n",
      "actions=(3,): 113 win=71 loss=42 draw=0 win1%=62.83 model-win1%=57.37\n",
      "actions=(4,): 136 win=104 loss=32 draw=0 win1%=76.47 model-win1%=58.82\n",
      "actions=(5,): 178 win=117 loss=61 draw=0 win1%=65.73 model-win1%=59.77\n",
      "actions=(6,): 134 win=80 loss=54 draw=0 win1%=59.70 model-win1%=59.79\n",
      "actions=(7,): 158 win=87 loss=71 draw=0 win1%=55.06 model-win1%=59.88\n",
      "\n",
      "=== Generation 2 ===\n",
      "Using forked data for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2\n",
      "Dataset for gen 2 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2. Skipping play.\n",
      "Using forked model for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-2.pt\n",
      "Model for gen 2 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-2.pt. Loading.\n",
      "Using forked model for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-2.pt\n",
      "Using forked data for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1\n",
      "Using forked data for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2\n",
      "Dataset Stats:\n",
      "  Trajectories: 2000\n",
      "  Total actions: 28575\n",
      "  Avg trajectory length: 14.29\n",
      "Prefix Stats:\n",
      "actions=(): 2000 win=1245 loss=755 draw=0 win1%=62.25 model-win1%=41.47\n",
      "actions=(1,): 314 win=167 loss=147 draw=0 win1%=53.18 model-win1%=62.91\n",
      "actions=(2,): 264 win=161 loss=103 draw=0 win1%=60.98 model-win1%=62.54\n",
      "actions=(3,): 235 win=160 loss=75 draw=0 win1%=68.09 model-win1%=61.35\n",
      "actions=(4,): 266 win=201 loss=65 draw=0 win1%=75.56 model-win1%=62.52\n",
      "actions=(5,): 331 win=223 loss=108 draw=0 win1%=67.37 model-win1%=63.84\n",
      "actions=(6,): 289 win=165 loss=124 draw=0 win1%=57.09 model-win1%=63.89\n",
      "actions=(7,): 301 win=168 loss=133 draw=0 win1%=55.81 model-win1%=63.32\n",
      "\n",
      "=== Generation 3 ===\n",
      "Using forked data for gen 3 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3\n",
      "Dataset for gen 3 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3. Skipping play.\n",
      "Using forked model for gen 3 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-3.pt\n",
      "Model for gen 3 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-3.pt. Loading.\n",
      "Using forked model for gen 3 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/models/gen-3.pt\n",
      "Using forked data for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1\n",
      "Using forked data for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2\n",
      "Using forked data for gen 3 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3\n",
      "Dataset Stats:\n",
      "  Trajectories: 3000\n",
      "  Total actions: 43386\n",
      "  Avg trajectory length: 14.46\n",
      "Prefix Stats:\n",
      "actions=(): 3000 win=1840 loss=1160 draw=0 win1%=61.33 model-win1%=44.55\n",
      "actions=(1,): 471 win=254 loss=217 draw=0 win1%=53.93 model-win1%=57.67\n",
      "actions=(2,): 375 win=219 loss=156 draw=0 win1%=58.40 model-win1%=56.50\n",
      "actions=(3,): 345 win=224 loss=121 draw=0 win1%=64.93 model-win1%=56.74\n",
      "actions=(4,): 411 win=307 loss=104 draw=0 win1%=74.70 model-win1%=58.14\n",
      "actions=(5,): 519 win=347 loss=172 draw=0 win1%=66.86 model-win1%=58.52\n",
      "actions=(6,): 449 win=254 loss=195 draw=0 win1%=56.57 model-win1%=58.00\n",
      "actions=(7,): 430 win=235 loss=195 draw=0 win1%=54.65 model-win1%=57.32\n",
      "\n",
      "=== Generation 4 ===\n",
      "Dataset for gen 4 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-4. Skipping play.\n",
      "Model for gen 4 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/models/gen-4.pt. Loading.\n",
      "Using forked data for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1\n",
      "Using forked data for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2\n",
      "Using forked data for gen 3 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3\n",
      "Dataset Stats:\n",
      "  Trajectories: 13000\n",
      "  Total actions: 197884\n",
      "  Avg trajectory length: 15.22\n",
      "Prefix Stats:\n",
      "actions=(): 13000 win=7734 loss=5263 draw=3 win1%=59.49 model-win1%=54.18\n",
      "actions=(1,): 1965 win=1009 loss=954 draw=2 win1%=51.35 model-win1%=56.78\n",
      "actions=(2,): 1585 win=875 loss=710 draw=0 win1%=55.21 model-win1%=55.52\n",
      "actions=(3,): 1551 win=968 loss=583 draw=0 win1%=62.41 model-win1%=56.89\n",
      "actions=(4,): 1785 win=1328 loss=457 draw=0 win1%=74.40 model-win1%=57.89\n",
      "actions=(5,): 2354 win=1520 loss=833 draw=1 win1%=64.57 model-win1%=58.64\n",
      "actions=(6,): 1983 win=1104 loss=879 draw=0 win1%=55.67 model-win1%=57.33\n",
      "actions=(7,): 1777 win=930 loss=847 draw=0 win1%=52.34 model-win1%=57.53\n",
      "\n",
      "=== Generation 5 ===\n",
      "Dataset for gen 5 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-5. Skipping play.\n",
      "Model for gen 5 exists at /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/models/gen-5.pt. Loading.\n",
      "Using forked data for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1\n",
      "Using forked data for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2\n",
      "Using forked data for gen 3 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3\n",
      "Dataset Stats:\n",
      "  Trajectories: 23000\n",
      "  Total actions: 351053\n",
      "  Avg trajectory length: 15.26\n",
      "Prefix Stats:\n",
      "actions=(): 23000 win=14023 loss=8971 draw=6 win1%=60.97 model-win1%=50.31\n",
      "actions=(1,): 3384 win=1795 loss=1587 draw=2 win1%=53.04 model-win1%=59.61\n",
      "actions=(2,): 2408 win=1369 loss=1038 draw=1 win1%=56.85 model-win1%=56.83\n",
      "actions=(3,): 2829 win=1828 loss=1001 draw=0 win1%=64.62 model-win1%=58.46\n",
      "actions=(4,): 3498 win=2569 loss=928 draw=1 win1%=73.44 model-win1%=58.65\n",
      "actions=(5,): 4276 win=2791 loss=1484 draw=1 win1%=65.27 model-win1%=60.01\n",
      "actions=(6,): 3478 win=2019 loss=1459 draw=0 win1%=58.05 model-win1%=59.86\n",
      "actions=(7,): 3127 win=1652 loss=1474 draw=1 win1%=52.83 model-win1%=60.73\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "trajectory_paths_dict = {}\n",
    "model_dict = {0: model_0}\n",
    "\n",
    "current_model = model_dict[0]\n",
    "if RUN_GENERATIONS:\n",
    "    for generation_id in range(1, experiment_config.num_generations+1):\n",
    "        current_model = await experiment_runner.run_generation_step_async(generation_id, current_model)\n",
    "        dataset_paths = experiment_runner.get_trajectory_paths(generation_id)\n",
    "        \n",
    "        # print stats for visibility\n",
    "        print_dataset_stats(dataset_paths, n_max_context, action_vocab, model=current_model, game=game)\n",
    "        \n",
    "        model_dict[generation_id] = current_model\n",
    "\n",
    "# 10m to play 2x10k generations... probabilities still very wrong.\n",
    "# Evaluation time: 0.015 seconds, size=574, eval-per-second=37837.60, total-batches=6000, mean-eval-per-second=94963.99, mean-time-per-batch=0.010, mean-batch-size=990.34\n",
    "\n",
    "# >>> log(2) + log(7) -> 2.6390573296152584\n",
    "## Model doesn't seem to improve loss at all?\n",
    "# step.   0: losses: train:2.5971, train_policy_loss:1.9146, train_value_loss:0.6825, val:2.5972, val_policy_loss:1.9147, val_value_loss:0.6825\n",
    "# step 1000: losses: train:2.6036, train_policy_loss:1.9122, train_value_loss:0.6914, val:2.6050, val_policy_loss:1.9132, val_value_loss:0.6917\n",
    "# step 2000: losses: train:2.6056, train_policy_loss:1.9119, train_value_loss:0.6937, val:2.6056, val_policy_loss:1.9123, val_value_loss:0.6933\n",
    "# iter    0/1170/5000: loss 2.5699, policy_loss:1.9129, value_loss:0.6570, time 5.18s, iter_time: 0.00ms\n",
    "# iter 1000/1170/5000: loss 2.5996, policy_loss:1.9068, value_loss:0.6928, time 1.96s, iter_time: 1957.74ms\n",
    "# iter 2339/2340/5000: loss 2.6014, policy_loss:1.9131, value_loss:0.6884, time 0.01s, iter_time: 14.61ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model (initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_config_fields: {'bias', 'n_layer', 'dropout', 'n_embd', 'n_head', 'n_max_context'}\n",
      "train_config_fields: {'max_epochs', 'min_lr', 'log_interval', 'eval_iters', 'learning_rate', 'compile', 'model_name', 'eval_interval', 'device', 'warmup_iters', 'always_save_checkpoint', 'lr_decay_iters', 'batch_size', 'wandb_log', 'beta1', 'max_iters', 'model_version', 'gradient_accumulation_steps', 'dtype', 'weight_decay', 'grad_clip', 'beta2', 'eval_only', 'decay_lr'}\n",
      "Using forked data for gen 1 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1\n",
      "Using forked data for gen 2 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2\n",
      "Using forked data for gen 3 from /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.59692284795973 elapsed=4.492679834365845s, val_policy=1.9120, val_value=0.6849\n",
      "## Searching generation 0 with 17 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'beta1: 0.9 -> 0.95', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.5997 elapsed=4.92s, mutation learning_rate: 0.02 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=4.86s, mutation learning_rate: 0.02 -> 0.01\n",
      "## improved: False, loss=2.5984 elapsed=5.11s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5994 elapsed=4.89s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5971 elapsed=4.48s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.5997 elapsed=5.31s, mutation n_embd: 8 -> 16\n",
      "## improved: False, loss=2.5968 elapsed=5.94s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5942 elapsed=5.15s, mutation batch_size: 32 -> 16\n",
      "## improved: False, loss=2.5952 elapsed=8.35s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.5984 elapsed=17.93s, mutation batch_size: 32 -> 64\n",
      "## improved: False, loss=2.5970 elapsed=4.91s, mutation weight_decay: 0.01 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=11.78s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5973 elapsed=4.84s, mutation dropout: 0.01 -> 0.02\n",
      "## improved: False, loss=2.5963 elapsed=4.63s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.5969 elapsed=5.44s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.5962 elapsed=4.79s, mutation dropout: 0.01 -> 0.0\n",
      "## improved: False, loss=2.5969 elapsed=4.86s, mutation dtype: bfloat16 -> float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 2.59692284795973,\n",
       " 4.492679834365845,\n",
       " {'batch_size': 32,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.98,\n",
       "  'bias': False,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.01,\n",
       "  'dtype': 'bfloat16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'learning_rate': 0.02,\n",
       "  'lr_decay_iters': 100,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 100,\n",
       "  'min_lr': 0.002,\n",
       "  'n_embd': 8,\n",
       "  'n_head': 1,\n",
       "  'n_layer': 1,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 0,\n",
       "  'weight_decay': 0.01,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-4'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-5')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "state_0 = game.initial_state()\n",
    "NUM_GENERATIONS = 5\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "# Parameters which will never be used for tuning.\n",
    "fixed_params = dict(\n",
    "    model_name='c4-smoketest',\n",
    "    model_version='0.1',\n",
    "    num_players = game.num_players(state_0),\n",
    "    vocab_size = action_vocab.vocab_size,\n",
    "    dataset_paths = tuple(experiment_runner.get_trajectory_paths(NUM_GENERATIONS)),\n",
    "\n",
    "\n",
    "    eval_iters = 200,\n",
    "    log_interval = 1000,\n",
    "    eval_interval = 10_000,\n",
    "\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "initial_params = dict(\n",
    "    n_layer=2,\n",
    "    n_head=2,\n",
    "    n_embd=8,  # tiny model\n",
    "\n",
    "    n_max_context=n_max_context,\n",
    "    batch_size = 32,\n",
    "    gradient_accumulation_steps = 1,\n",
    "\n",
    "    max_iters=100,\n",
    "    max_epochs=1_000_000, # Make max_epoch high, rely on max_iters to stop.\n",
    "        \n",
    "    learning_rate = LEARNING_RATE,    \n",
    "    decay_lr = True,  # whether to decay the learning rate\n",
    "    lr_decay_iters = 100,  # make equal to max_iters usually\n",
    "    min_lr = LEARNING_RATE / 10,  # learning_rate / 10 usually\n",
    "    warmup_iters = 0,  # not super necessary potentially\n",
    "\n",
    "    weight_decay = 1e-1,\n",
    "    beta1 = 0.9,\n",
    "    beta2 = 0.95,\n",
    "    grad_clip = 1.0,  # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "    dtype = \"float16\",\n",
    "\n",
    "    dropout = 0.0,\n",
    "    bias = False,  # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    ")\n",
    "\n",
    "tune_options = dict(\n",
    "    n_layer = [1, 2, 3, 4, 5, 6, 8, 10, 12, 16, 32],\n",
    "    # n_head = [1, 2, 4, 8, 16, 32],   # Needs to be calcualted to ensure n_embed % n_head == 0\n",
    "    n_embd = [8, 16, 32, 64, 128, 256, 512, 1024, 2048],\n",
    "\n",
    "    n_max_context = [initial_params['n_max_context']],\n",
    "    batch_size = [16, 32, 64, 128, 256, 512, 1024],\n",
    "    gradient_accumulation_steps = [1],  # TODO: We only support 1 for now. This fails is we don't have an exact multiple of the batch size per epoch.\n",
    "\n",
    "    max_iters = [100, 300, 1_000, 3_000, 5_000, 10_000, 30_000, 100_000, 300_000],\n",
    "    max_epochs = [1_000_000], # Make max_epoch high, rely on max_iters to stop.\n",
    " \n",
    "    learning_rate = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0],\n",
    "    decay_lr = [False, True],\n",
    "\n",
    "    # TODO: What is a sensible range here?\n",
    "    beta1 = [0.90, 0.95, 0.99],\n",
    "    beta2 = [0.95, 0.98, 0.99],\n",
    "\n",
    "    weight_decay = [0.01, 0.05, 0.1, 0.2],\n",
    "    grad_clip = [0,0, 1.0],  # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "    dtype = [\"bfloat16\", \"float16\"],\n",
    "    dropout = [0.0, 0.01, 0.02, 0.05, 0.1],\n",
    "    bias = [True, False],    \n",
    ")\n",
    "\n",
    "_n_head_options = [1, 2, 4, 8, 16, 32]\n",
    "computed_tune_options = dict(\n",
    "    min_lr = lambda opt: [opt['learning_rate'] / 10],\n",
    "    lr_decay_iters = lambda opt: [opt['max_iters']],\n",
    "    warmup_iters = lambda opt: [x for x in [0, 100, 500, 1000] if x < opt['lr_decay_iters']] if opt['decay_lr'] else [0],\n",
    "    n_head = lambda opt: [n for n in _n_head_options if opt['n_embd'] % n == 0],\n",
    ")\n",
    "\n",
    "TUNER_VERSION = \"0.0.4-smoketest\"\n",
    "\n",
    "from rgi.rgizero.models.tuner import Tuner\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=1.00)\n",
    "tuner.autotune_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.560657819112142 elapsed=7.751740217208862s, val_policy=1.9066, val_value=0.6541\n",
      "## Searching generation 0 with 20 candidates, including ['learning_rate: 0.005 -> 0.01', 'learning_rate: 0.005 -> 0.002', 'dropout: 0.0 -> 0.01', 'n_head: 2 -> 1', 'n_head: 2 -> 4']\n",
      "## improved: False, loss=2.5649 elapsed=7.85s, mutation learning_rate: 0.005 -> 0.01\n",
      "## improved: False, loss=2.5639 elapsed=7.81s, mutation learning_rate: 0.005 -> 0.002\n",
      "## improved: False, loss=2.5612 elapsed=7.98s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5750 elapsed=7.85s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5613 elapsed=8.03s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5627 elapsed=7.87s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5607 elapsed=7.86s, mutation weight_decay: 0.05 -> 0.01\n",
      "## improved: False, loss=2.5680 elapsed=7.96s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5606 elapsed=7.85s, mutation weight_decay: 0.05 -> 0.1\n",
      "## improved: False, loss=2.5669 elapsed=7.42s, mutation n_embd: 64 -> 32\n",
      "## improved: False, loss=2.5644 elapsed=8.21s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5646 elapsed=9.49s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5794 elapsed=7.98s, mutation warmup_iters: 100 -> 0\n",
      "## improved: False, loss=2.5755 elapsed=9.64s, mutation n_embd: 64 -> 128\n",
      "## improved: False, loss=2.5613 elapsed=40.43s, mutation batch_size: 64 -> 128\n",
      "## improved: False, loss=2.5882 elapsed=7.55s, mutation batch_size: 64 -> 32\n",
      "## improved: False, loss=2.5847 elapsed=7.77s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5607 elapsed=7.84s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.6026 elapsed=4.63s, mutation max_iters: 300 -> 100\n",
      "## improved: False, loss=2.5531 elapsed=18.77s, mutation max_iters: 300 -> 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 2.560657819112142,\n",
       " 7.751740217208862,\n",
       " {'batch_size': 64,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.95,\n",
       "  'bias': False,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.0,\n",
       "  'dtype': 'bfloat16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'learning_rate': 0.005,\n",
       "  'lr_decay_iters': 300,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 300,\n",
       "  'min_lr': 0.0005,\n",
       "  'n_embd': 64,\n",
       "  'n_head': 2,\n",
       "  'n_layer': 1,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 100,\n",
       "  'weight_decay': 0.05,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-4'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-5')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.1)\n",
    "tuner.autotune_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 2.498758872350057,\n",
       " 72.13808417320251,\n",
       " {'batch_size': 256,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.95,\n",
       "  'bias': True,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.0,\n",
       "  'dtype': 'float16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'learning_rate': 0.002,\n",
       "  'lr_decay_iters': 1000,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 1000,\n",
       "  'min_lr': 0.0002,\n",
       "  'n_embd': 256,\n",
       "  'n_head': 2,\n",
       "  'n_layer': 3,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 500,\n",
       "  'weight_decay': 0.1,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-4'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-5')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.01)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 2.498758872350057,\n",
       " 72.13808417320251,\n",
       " {'batch_size': 256,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.95,\n",
       "  'bias': True,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.0,\n",
       "  'dtype': 'float16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'learning_rate': 0.002,\n",
       "  'lr_decay_iters': 1000,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 1000,\n",
       "  'min_lr': 0.0002,\n",
       "  'n_embd': 256,\n",
       "  'n_head': 2,\n",
       "  'n_layer': 3,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 500,\n",
       "  'weight_decay': 0.1,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-4'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-5')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.59692284795973 elapsed=4.492679834365845s, val_policy=1.9120, val_value=0.6849\n",
      "## Searching generation 0 with 17 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'beta1: 0.9 -> 0.95', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.5997 elapsed=4.92s, mutation learning_rate: 0.02 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=4.86s, mutation learning_rate: 0.02 -> 0.01\n",
      "## improved: False, loss=2.5984 elapsed=5.11s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5994 elapsed=4.89s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5971 elapsed=4.48s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.5997 elapsed=5.31s, mutation n_embd: 8 -> 16\n",
      "## improved: False, loss=2.5968 elapsed=5.94s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5942 elapsed=5.15s, mutation batch_size: 32 -> 16\n",
      "## improved: False, loss=2.5952 elapsed=8.35s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.5984 elapsed=17.93s, mutation batch_size: 32 -> 64\n",
      "## improved: False, loss=2.5970 elapsed=4.91s, mutation weight_decay: 0.01 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=11.78s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5973 elapsed=4.84s, mutation dropout: 0.01 -> 0.02\n",
      "## improved: False, loss=2.5963 elapsed=4.63s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.5969 elapsed=5.44s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.5962 elapsed=4.79s, mutation dropout: 0.01 -> 0.0\n",
      "## improved: False, loss=2.5969 elapsed=4.86s, mutation dtype: bfloat16 -> float16\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.560657819112142 elapsed=7.751740217208862s, val_policy=1.9066, val_value=0.6541\n",
      "## Searching generation 0 with 20 candidates, including ['learning_rate: 0.005 -> 0.01', 'learning_rate: 0.005 -> 0.002', 'dropout: 0.0 -> 0.01', 'n_head: 2 -> 1', 'n_head: 2 -> 4']\n",
      "## improved: False, loss=2.5649 elapsed=7.85s, mutation learning_rate: 0.005 -> 0.01\n",
      "## improved: False, loss=2.5639 elapsed=7.81s, mutation learning_rate: 0.005 -> 0.002\n",
      "## improved: False, loss=2.5612 elapsed=7.98s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5750 elapsed=7.85s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5613 elapsed=8.03s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5627 elapsed=7.87s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5607 elapsed=7.86s, mutation weight_decay: 0.05 -> 0.01\n",
      "## improved: False, loss=2.5680 elapsed=7.96s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5606 elapsed=7.85s, mutation weight_decay: 0.05 -> 0.1\n",
      "## improved: False, loss=2.5669 elapsed=7.42s, mutation n_embd: 64 -> 32\n",
      "## improved: False, loss=2.5644 elapsed=8.21s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5646 elapsed=9.49s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5794 elapsed=7.98s, mutation warmup_iters: 100 -> 0\n",
      "## improved: False, loss=2.5755 elapsed=9.64s, mutation n_embd: 64 -> 128\n",
      "## improved: False, loss=2.5613 elapsed=40.43s, mutation batch_size: 64 -> 128\n",
      "## improved: False, loss=2.5882 elapsed=7.55s, mutation batch_size: 64 -> 32\n",
      "## improved: False, loss=2.5847 elapsed=7.77s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5607 elapsed=7.84s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.6026 elapsed=4.63s, mutation max_iters: 300 -> 100\n",
      "## improved: False, loss=2.5531 elapsed=18.77s, mutation max_iters: 300 -> 1000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.59692284795973 elapsed=4.492679834365845s, val_policy=1.9120, val_value=0.6849\n",
      "## Searching generation 0 with 17 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'beta1: 0.9 -> 0.95', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.5997 elapsed=4.92s, mutation learning_rate: 0.02 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=4.86s, mutation learning_rate: 0.02 -> 0.01\n",
      "## improved: False, loss=2.5984 elapsed=5.11s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5994 elapsed=4.89s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5971 elapsed=4.48s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.5997 elapsed=5.31s, mutation n_embd: 8 -> 16\n",
      "## improved: False, loss=2.5968 elapsed=5.94s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5942 elapsed=5.15s, mutation batch_size: 32 -> 16\n",
      "## improved: False, loss=2.5952 elapsed=8.35s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.5984 elapsed=17.93s, mutation batch_size: 32 -> 64\n",
      "## improved: False, loss=2.5970 elapsed=4.91s, mutation weight_decay: 0.01 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=11.78s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5973 elapsed=4.84s, mutation dropout: 0.01 -> 0.02\n",
      "## improved: False, loss=2.5963 elapsed=4.63s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.5969 elapsed=5.44s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.5962 elapsed=4.79s, mutation dropout: 0.01 -> 0.0\n",
      "## improved: False, loss=2.5969 elapsed=4.86s, mutation dtype: bfloat16 -> float16\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.560657819112142 elapsed=7.751740217208862s, val_policy=1.9066, val_value=0.6541\n",
      "## Searching generation 0 with 20 candidates, including ['learning_rate: 0.005 -> 0.01', 'learning_rate: 0.005 -> 0.002', 'dropout: 0.0 -> 0.01', 'n_head: 2 -> 1', 'n_head: 2 -> 4']\n",
      "## improved: False, loss=2.5649 elapsed=7.85s, mutation learning_rate: 0.005 -> 0.01\n",
      "## improved: False, loss=2.5639 elapsed=7.81s, mutation learning_rate: 0.005 -> 0.002\n",
      "## improved: False, loss=2.5612 elapsed=7.98s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5750 elapsed=7.85s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5613 elapsed=8.03s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5627 elapsed=7.87s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5607 elapsed=7.86s, mutation weight_decay: 0.05 -> 0.01\n",
      "## improved: False, loss=2.5680 elapsed=7.96s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5606 elapsed=7.85s, mutation weight_decay: 0.05 -> 0.1\n",
      "## improved: False, loss=2.5669 elapsed=7.42s, mutation n_embd: 64 -> 32\n",
      "## improved: False, loss=2.5644 elapsed=8.21s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5646 elapsed=9.49s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5794 elapsed=7.98s, mutation warmup_iters: 100 -> 0\n",
      "## improved: False, loss=2.5755 elapsed=9.64s, mutation n_embd: 64 -> 128\n",
      "## improved: False, loss=2.5613 elapsed=40.43s, mutation batch_size: 64 -> 128\n",
      "## improved: False, loss=2.5882 elapsed=7.55s, mutation batch_size: 64 -> 32\n",
      "## improved: False, loss=2.5847 elapsed=7.77s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5607 elapsed=7.84s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.6026 elapsed=4.63s, mutation max_iters: 300 -> 100\n",
      "## improved: False, loss=2.5531 elapsed=18.77s, mutation max_iters: 300 -> 1000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.59692284795973 elapsed=4.492679834365845s, val_policy=1.9120, val_value=0.6849\n",
      "## Searching generation 0 with 17 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'beta1: 0.9 -> 0.95', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.5997 elapsed=4.92s, mutation learning_rate: 0.02 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=4.86s, mutation learning_rate: 0.02 -> 0.01\n",
      "## improved: False, loss=2.5984 elapsed=5.11s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5994 elapsed=4.89s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5971 elapsed=4.48s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.5997 elapsed=5.31s, mutation n_embd: 8 -> 16\n",
      "## improved: False, loss=2.5968 elapsed=5.94s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5942 elapsed=5.15s, mutation batch_size: 32 -> 16\n",
      "## improved: False, loss=2.5952 elapsed=8.35s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.5984 elapsed=17.93s, mutation batch_size: 32 -> 64\n",
      "## improved: False, loss=2.5970 elapsed=4.91s, mutation weight_decay: 0.01 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=11.78s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5973 elapsed=4.84s, mutation dropout: 0.01 -> 0.02\n",
      "## improved: False, loss=2.5963 elapsed=4.63s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.5969 elapsed=5.44s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.5962 elapsed=4.79s, mutation dropout: 0.01 -> 0.0\n",
      "## improved: False, loss=2.5969 elapsed=4.86s, mutation dtype: bfloat16 -> float16\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.560657819112142 elapsed=7.751740217208862s, val_policy=1.9066, val_value=0.6541\n",
      "## Searching generation 0 with 20 candidates, including ['learning_rate: 0.005 -> 0.01', 'learning_rate: 0.005 -> 0.002', 'dropout: 0.0 -> 0.01', 'n_head: 2 -> 1', 'n_head: 2 -> 4']\n",
      "## improved: False, loss=2.5649 elapsed=7.85s, mutation learning_rate: 0.005 -> 0.01\n",
      "## improved: False, loss=2.5639 elapsed=7.81s, mutation learning_rate: 0.005 -> 0.002\n",
      "## improved: False, loss=2.5612 elapsed=7.98s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5750 elapsed=7.85s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5613 elapsed=8.03s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5627 elapsed=7.87s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5607 elapsed=7.86s, mutation weight_decay: 0.05 -> 0.01\n",
      "## improved: False, loss=2.5680 elapsed=7.96s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5606 elapsed=7.85s, mutation weight_decay: 0.05 -> 0.1\n",
      "## improved: False, loss=2.5669 elapsed=7.42s, mutation n_embd: 64 -> 32\n",
      "## improved: False, loss=2.5644 elapsed=8.21s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5646 elapsed=9.49s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5794 elapsed=7.98s, mutation warmup_iters: 100 -> 0\n",
      "## improved: False, loss=2.5755 elapsed=9.64s, mutation n_embd: 64 -> 128\n",
      "## improved: False, loss=2.5613 elapsed=40.43s, mutation batch_size: 64 -> 128\n",
      "## improved: False, loss=2.5882 elapsed=7.55s, mutation batch_size: 64 -> 32\n",
      "## improved: False, loss=2.5847 elapsed=7.77s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5607 elapsed=7.84s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.6026 elapsed=4.63s, mutation max_iters: 300 -> 100\n",
      "## improved: False, loss=2.5531 elapsed=18.77s, mutation max_iters: 300 -> 1000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.59692284795973 elapsed=4.492679834365845s, val_policy=1.9120, val_value=0.6849\n",
      "## Searching generation 0 with 17 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'beta1: 0.9 -> 0.95', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.5997 elapsed=4.92s, mutation learning_rate: 0.02 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=4.86s, mutation learning_rate: 0.02 -> 0.01\n",
      "## improved: False, loss=2.5984 elapsed=5.11s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5994 elapsed=4.89s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5971 elapsed=4.48s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.5997 elapsed=5.31s, mutation n_embd: 8 -> 16\n",
      "## improved: False, loss=2.5968 elapsed=5.94s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5942 elapsed=5.15s, mutation batch_size: 32 -> 16\n",
      "## improved: False, loss=2.5952 elapsed=8.35s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.5984 elapsed=17.93s, mutation batch_size: 32 -> 64\n",
      "## improved: False, loss=2.5970 elapsed=4.91s, mutation weight_decay: 0.01 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=11.78s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5973 elapsed=4.84s, mutation dropout: 0.01 -> 0.02\n",
      "## improved: False, loss=2.5963 elapsed=4.63s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.5969 elapsed=5.44s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.5962 elapsed=4.79s, mutation dropout: 0.01 -> 0.0\n",
      "## improved: False, loss=2.5969 elapsed=4.86s, mutation dtype: bfloat16 -> float16\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.560657819112142 elapsed=7.751740217208862s, val_policy=1.9066, val_value=0.6541\n",
      "## Searching generation 0 with 20 candidates, including ['learning_rate: 0.005 -> 0.01', 'learning_rate: 0.005 -> 0.002', 'dropout: 0.0 -> 0.01', 'n_head: 2 -> 1', 'n_head: 2 -> 4']\n",
      "## improved: False, loss=2.5649 elapsed=7.85s, mutation learning_rate: 0.005 -> 0.01\n",
      "## improved: False, loss=2.5639 elapsed=7.81s, mutation learning_rate: 0.005 -> 0.002\n",
      "## improved: False, loss=2.5612 elapsed=7.98s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5750 elapsed=7.85s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5613 elapsed=8.03s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5627 elapsed=7.87s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5607 elapsed=7.86s, mutation weight_decay: 0.05 -> 0.01\n",
      "## improved: False, loss=2.5680 elapsed=7.96s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5606 elapsed=7.85s, mutation weight_decay: 0.05 -> 0.1\n",
      "## improved: False, loss=2.5669 elapsed=7.42s, mutation n_embd: 64 -> 32\n",
      "## improved: False, loss=2.5644 elapsed=8.21s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5646 elapsed=9.49s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5794 elapsed=7.98s, mutation warmup_iters: 100 -> 0\n",
      "## improved: False, loss=2.5755 elapsed=9.64s, mutation n_embd: 64 -> 128\n",
      "## improved: False, loss=2.5613 elapsed=40.43s, mutation batch_size: 64 -> 128\n",
      "## improved: False, loss=2.5882 elapsed=7.55s, mutation batch_size: 64 -> 32\n",
      "## improved: False, loss=2.5847 elapsed=7.77s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5607 elapsed=7.84s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.6026 elapsed=4.63s, mutation max_iters: 300 -> 100\n",
      "## improved: False, loss=2.5531 elapsed=18.77s, mutation max_iters: 300 -> 1000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.59692284795973 elapsed=4.492679834365845s, val_policy=1.9120, val_value=0.6849\n",
      "## Searching generation 0 with 17 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'beta1: 0.9 -> 0.95', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.5997 elapsed=4.92s, mutation learning_rate: 0.02 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=4.86s, mutation learning_rate: 0.02 -> 0.01\n",
      "## improved: False, loss=2.5984 elapsed=5.11s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5994 elapsed=4.89s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5971 elapsed=4.48s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.5997 elapsed=5.31s, mutation n_embd: 8 -> 16\n",
      "## improved: False, loss=2.5968 elapsed=5.94s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5942 elapsed=5.15s, mutation batch_size: 32 -> 16\n",
      "## improved: False, loss=2.5952 elapsed=8.35s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.5984 elapsed=17.93s, mutation batch_size: 32 -> 64\n",
      "## improved: False, loss=2.5970 elapsed=4.91s, mutation weight_decay: 0.01 -> 0.05\n",
      "## improved: False, loss=2.5988 elapsed=11.78s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5973 elapsed=4.84s, mutation dropout: 0.01 -> 0.02\n",
      "## improved: False, loss=2.5963 elapsed=4.63s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.5969 elapsed=5.44s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.5962 elapsed=4.79s, mutation dropout: 0.01 -> 0.0\n",
      "## improved: False, loss=2.5969 elapsed=4.86s, mutation dtype: bfloat16 -> float16\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.560657819112142 elapsed=7.751740217208862s, val_policy=1.9066, val_value=0.6541\n",
      "## Searching generation 0 with 20 candidates, including ['learning_rate: 0.005 -> 0.01', 'learning_rate: 0.005 -> 0.002', 'dropout: 0.0 -> 0.01', 'n_head: 2 -> 1', 'n_head: 2 -> 4']\n",
      "## improved: False, loss=2.5649 elapsed=7.85s, mutation learning_rate: 0.005 -> 0.01\n",
      "## improved: False, loss=2.5639 elapsed=7.81s, mutation learning_rate: 0.005 -> 0.002\n",
      "## improved: False, loss=2.5612 elapsed=7.98s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5750 elapsed=7.85s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5613 elapsed=8.03s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5627 elapsed=7.87s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5607 elapsed=7.86s, mutation weight_decay: 0.05 -> 0.01\n",
      "## improved: False, loss=2.5680 elapsed=7.96s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.5606 elapsed=7.85s, mutation weight_decay: 0.05 -> 0.1\n",
      "## improved: False, loss=2.5669 elapsed=7.42s, mutation n_embd: 64 -> 32\n",
      "## improved: False, loss=2.5644 elapsed=8.21s, mutation bias: False -> True\n",
      "## improved: False, loss=2.5646 elapsed=9.49s, mutation n_layer: 1 -> 2\n",
      "## improved: False, loss=2.5794 elapsed=7.98s, mutation warmup_iters: 100 -> 0\n",
      "## improved: False, loss=2.5755 elapsed=9.64s, mutation n_embd: 64 -> 128\n",
      "## improved: False, loss=2.5613 elapsed=40.43s, mutation batch_size: 64 -> 128\n",
      "## improved: False, loss=2.5882 elapsed=7.55s, mutation batch_size: 64 -> 32\n",
      "## improved: False, loss=2.5847 elapsed=7.77s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5607 elapsed=7.84s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.6026 elapsed=4.63s, mutation max_iters: 300 -> 100\n",
      "## improved: False, loss=2.5531 elapsed=18.77s, mutation max_iters: 300 -> 1000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n",
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.498758872350057 elapsed=72.13808417320251s, val_policy=1.8752, val_value=0.6236\n",
      "## Searching generation 0 with 21 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'weight_decay: 0.1 -> 0.05', 'n_head: 2 -> 4', 'n_layer: 3 -> 4']\n",
      "## improved: False, loss=2.5027 elapsed=72.29s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.5676 elapsed=72.10s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.4994 elapsed=72.49s, mutation weight_decay: 0.1 -> 0.05\n",
      "## improved: False, loss=2.5213 elapsed=73.28s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.5238 elapsed=91.03s, mutation n_layer: 3 -> 4\n",
      "## improved: False, loss=2.5187 elapsed=35.42s, mutation n_embd: 256 -> 128\n",
      "## improved: False, loss=2.5500 elapsed=46.74s, mutation batch_size: 256 -> 128\n",
      "## improved: False, loss=2.5033 elapsed=69.71s, mutation bias: True -> False\n",
      "## improved: False, loss=2.5027 elapsed=72.18s, mutation weight_decay: 0.1 -> 0.2\n",
      "## improved: False, loss=2.5600 elapsed=127.06s, mutation batch_size: 256 -> 512\n",
      "## improved: False, loss=2.5664 elapsed=194.45s, mutation n_embd: 256 -> 512\n",
      "## improved: False, loss=2.4994 elapsed=72.69s, mutation dtype: float16 -> bfloat16\n",
      "## improved: False, loss=2.5015 elapsed=78.07s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.5483 elapsed=72.29s, mutation warmup_iters: 500 -> 100\n",
      "## improved: False, loss=2.5377 elapsed=67.88s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.5179 elapsed=72.07s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.4990 elapsed=72.08s, mutation beta2: 0.95 -> 0.98\n",
      "## improved: False, loss=2.5230 elapsed=52.95s, mutation n_layer: 3 -> 2\n",
      "## improved: False, loss=2.5828 elapsed=72.04s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.5783 elapsed=24.97s, mutation max_iters: 1000 -> 300\n",
      "## improved: False, loss=2.8518 elapsed=207.50s, mutation max_iters: 1000 -> 3000\n"
     ]
    }
   ],
   "source": [
    "# Iterate a bunch of times trying to find an optimal.\n",
    "for _ in range(5):\n",
    "    for target_improvement in [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "        tuner = Tuner(\n",
    "            fixed_params=fixed_params.copy(),\n",
    "            initial_params=initial_params.copy(),\n",
    "            tune_options=tune_options.copy(), \n",
    "            computed_tune_options=computed_tune_options.copy(),\n",
    "            cache_version=TUNER_VERSION,\n",
    "            target_improvement_per_minute=target_improvement)\n",
    "        tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Skip this...",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSkip this...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Skip this..."
     ]
    }
   ],
   "source": [
    "raise NotImplementedError(\"Skip this...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect training data\n",
    "td_array = [TrajectoryDataset(DATA_DIR, f\"gen-{generation_id}\", block_size=n_max_context) for generation_id in range(1, NUM_GENERATIONS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [td for td in td_array]\n",
    "unrolled = [(generation+1, d) for generation, td in enumerate(td_array) for d in td]\n",
    "\n",
    "# gen, d = unrolled[0], \n",
    "# d.action[:2]\n",
    "# d.value[0]\n",
    "\n",
    "dd = defaultdict(lambda: defaultdict(lambda: torch.tensor([0., 0.])))\n",
    "\n",
    "for gen, d in unrolled:\n",
    "    for g in ['*', gen]:    \n",
    "        # dd[tuple(tuple(d.action[:0].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:1].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:2].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:3].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:4].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:5].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:6].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:7].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:8].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:9].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:10].tolist()))][g] += d.value[0]\n",
    "\n",
    "print(f\"len(dd) = {len(dd)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prefix(model, game, prefix):\n",
    "    serial_evaluator = ActionHistoryTransformerEvaluator(model, device=device, block_size=n_max_context, vocab=action_vocab)\n",
    "    state = game.initial_state()\n",
    "    for action in prefix:\n",
    "        state = game.next_state(state, action)\n",
    "    legal_actions = game.legal_actions(state)\n",
    "    result = serial_evaluator.evaluate(game, state, legal_actions)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Someting is borked? Player1 win percent should be much higher??\n",
    "def compare_model_vs_data(model, game, dd):    \n",
    "    list(dd.items())[10][1]['*'].sum() > 100\n",
    "    top_k = sorted(dd.items(), key=lambda kv: kv[1]['*'].sum(), reverse=True)[:20]\n",
    "    top_k_keys = sorted(k for k, v in top_k)\n",
    "    \n",
    "    prefix_list = top_k_keys\n",
    "\n",
    "    # prefix_list = [\n",
    "    #     (0,), \n",
    "    #     (0,1), (0,2), (0,3), (0,4), (0,5), (0,6), (0,7),\n",
    "    #     (0,1,1), (0,1,2), (0,1,3), (0,1,4), (0,1,5), (0,1,6), (0,1,7),\n",
    "    #     (0,4,1), (0,4,2), (0,4,3), (0,4,4), (0,4,5), (0,4,6), (0,4,7),\n",
    "    # ]\n",
    "\n",
    "    for prefix in prefix_list:\n",
    "        print(f\"\\nprefix={prefix}\")\n",
    "        for gen, counts in dd[prefix].items():\n",
    "            if gen == '*':\n",
    "                print(f\"gen={gen}: {counts}, win_pct={100*counts[0]/sum(counts):.2f}%, sum={sum(counts)}\")\n",
    "        # # assert prefix[0] == 0\n",
    "        actions = prefix[1:]\n",
    "        eval_result = eval_prefix(model, game, actions)\n",
    "        # print(f'legal_policy={eval_result.legal_policy}')\n",
    "        # print(f'player_values={eval_result.player_values}')\n",
    "        print(f'player_probs={(eval_result.player_values+1)/2}')\n",
    "\n",
    "compare_model_vs_data(current_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model\n",
    "model_0 = create_random_model(model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42, device=device)\n",
    "if RUN_GENERATIONS:\n",
    "    model_1 = load_model(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n### Model 0\")\n",
    "print(model_0.action_embedding.weight)\n",
    "compare_model_vs_data(model_0, game, dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GENERATIONS:\n",
    "    print(\"\\n\\n### Model 1\")\n",
    "    print(model_1.action_embedding.weight)\n",
    "    compare_model_vs_data(model_1, game, dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tournament to calcualte ELO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import numpy as np\n",
    "from contextlib import asynccontextmanager\n",
    "from rgi.rgizero.tournament import Tournament\n",
    "from rgi.rgizero.players.alphazero import AlphazeroPlayer\n",
    "from rgi.rgizero.models.action_history_transformer import ActionHistoryTransformerEvaluator, AsyncNetworkEvaluator\n",
    "\n",
    "@asynccontextmanager\n",
    "async def create_player_factory(model, simulations, game, device, block_size, action_vocab, max_batch_size):\n",
    "    \"\"\"\n",
    "    Creates a shared evaluator and returns a factory function that produces \n",
    "    new AlphazeroPlayer instances using that shared evaluator.\n",
    "    \"\"\"\n",
    "    # 1. Setup the shared evaluator\n",
    "    serial_evaluator = ActionHistoryTransformerEvaluator(\n",
    "        model, \n",
    "        device=device, \n",
    "        block_size=n_max_context, \n",
    "        vocab=action_vocab\n",
    "    )\n",
    "    async_evaluator = AsyncNetworkEvaluator(\n",
    "        base_evaluator=serial_evaluator, \n",
    "        max_batch_size=max_batch_size, \n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 2. Start the evaluator background task\n",
    "    await async_evaluator.start()\n",
    "    \n",
    "    try:\n",
    "        # 3. Define the factory. This is called by Tournament for every game.\n",
    "        # It creates a NEW player instance but uses the SHARED async_evaluator.\n",
    "        def player_factory():\n",
    "            # Create a fresh RNG for each game/player instance\n",
    "            rng = np.random.default_rng(np.random.randint(0, 2**31))\n",
    "            return AlphazeroPlayer(\n",
    "                game, \n",
    "                async_evaluator, \n",
    "                rng=rng, \n",
    "                add_noise=True, \n",
    "                simulations=simulations\n",
    "            )\n",
    "            \n",
    "        yield player_factory\n",
    "        \n",
    "    finally:\n",
    "        # 4. Cleanup\n",
    "        await async_evaluator.stop()\n",
    "\n",
    "async def run_tournament_async():\n",
    "    # Use async with to manage the lifecycle of the evaluators\n",
    "    async with (\n",
    "        # create_player_factory(model_dict[0], 100, game, device, block_size, action_vocab, 10) as factory_gen0_100,\n",
    "        # create_player_factory(model_dict[1], 100, game, device, block_size, action_vocab, 10) as factory_gen1_100,\n",
    "        # create_player_factory(model_dict[2], 100, game, device, block_size, action_vocab, 10) as factory_gen2_100,\n",
    "        # create_player_factory(model_dict[3], 100, game, device, block_size, action_vocab, 10) as factory_gen3_100,\n",
    "        # create_player_factory(model_dict[4], 100, game, device, block_size, action_vocab, 10) as factory_gen4_100,\n",
    "        # create_player_factory(model_dict[5], 100, game, device, block_size, action_vocab, 10) as factory_gen5_100,\n",
    "        # create_player_factory(model_dict[10], 100, game, device, block_size, action_vocab, 10) as factory_gen6_100,\n",
    "        # create_player_factory(model_dict[15], 100, game, device, block_size, action_vocab, 10) as factory_gen7_100,\n",
    "        # create_player_factory(model_dict[20], 100, game, device, block_size, action_vocab, 10) as factory_gen8_100,\n",
    "\n",
    "        create_player_factory(model_dict[0], 200, game, device, block_size, action_vocab, 10) as factory_gen0_200,\n",
    "        #create_player_factory(model_dict[1], 200, game, device, block_size, action_vocab, 10) as factory_gen1_200,\n",
    "        #create_player_factory(model_dict[2], 200, game, device, block_size, action_vocab, 10) as factory_gen2_200,\n",
    "        #create_player_factory(model_dict[3], 200, game, device, block_size, action_vocab, 10) as factory_gen3_200,\n",
    "        #create_player_factory(model_dict[4], 200, game, device, block_size, action_vocab, 10) as factory_gen4_200,\n",
    "        create_player_factory(model_dict[5], 200, game, device, block_size, action_vocab, 10) as factory_gen5_200,\n",
    "        #create_player_factory(model_dict[10], 200, game, device, block_size, action_vocab, 10) as factory_gen10_200,\n",
    "        #create_player_factory(model_dict[15], 200, game, device, block_size, action_vocab, 10) as factory_gen15_200,\n",
    "        create_player_factory(model_dict[20], 200, game, device, block_size, action_vocab, 10) as factory_gen20_200,\n",
    "        ):\n",
    "        \n",
    "        # The dictionary now maps names to FACTORIES (Callables), not Player instances\n",
    "        player_factories = {\n",
    "            # \"factory_gen0_100\": factory_gen0_100,\n",
    "            # \"factory_gen1_100\": factory_gen1_100,\n",
    "            # \"factory_gen2_100\": factory_gen2_100,\n",
    "            # \"factory_gen3_100\": factory_gen3_100,\n",
    "            # \"factory_gen4_100\": factory_gen4_100,\n",
    "            # \"factory_gen5_100\": factory_gen5_100,\n",
    "            # \"factory_gen6_100\": factory_gen6_100,\n",
    "            # \"factory_gen7_100\": factory_gen7_100,\n",
    "\n",
    "            \"factory_gen0_200\": factory_gen0_200,\n",
    "            #\"factory_gen1_200\": factory_gen1_200,\n",
    "            #\"factory_gen2_200\": factory_gen2_200,\n",
    "            #\"factory_gen3_200\": factory_gen3_200,\n",
    "            #\"factory_gen4_200\": factory_gen4_200,\n",
    "            \"factory_gen5_200\": factory_gen5_200,\n",
    "            #\"factory_gen10_200\": factory_gen10_200,\n",
    "            #\"factory_gen15_200\": factory_gen15_200,\n",
    "            \"factory_gen20_200\": factory_gen20_200,\n",
    "        }\n",
    "        \n",
    "        tournament = Tournament(game, player_factories, initial_elo=1000)\n",
    "        \n",
    "        print(\"Running tournament...\")\n",
    "        # await tournament.run(num_games=1_000, concurrent_games=2000)\n",
    "        await tournament.run(num_games=100, concurrent_games=2000)\n",
    "        tournament.print_standings()\n",
    "\n",
    "# RUN_TOURNAMENT = True\n",
    "if RUN_TOURNAMENT:\n",
    "    await run_tournament_async()\n",
    "\n",
    "# Running tournament...\n",
    "# Tournament Progress: 100%|██████████| 10000/10000 [1:25:59<00:00,  1.94it/s]\n",
    "\n",
    "# Tournament Standings:\n",
    "# Rank  Player               ELO        Games    W-L-D          \n",
    "# -----------------------------------------------------------------\n",
    "# 1     factory_gen6_200     1140.5     1247     827-419-1      \n",
    "# 2     factory_gen2_200     1100.1     1251     693-554-4      \n",
    "# 3     factory_gen5_100     1074.4     1251     598-652-1      \n",
    "# 4     factory_gen3_200     1029.1     1252     674-573-5      \n",
    "# 5     factory_gen4_200     1027.0     1248     711-536-1      \n",
    "# 6     factory_gen0_200     1020.0     1254     444-810-0      \n",
    "# 7     factory_gen5_200     990.2      1248     742-502-4      \n",
    "# 8     factory_gen7_100     987.5      1250     650-597-3      \n",
    "# 9     factory_gen7_200     979.2      1248     768-476-4      \n",
    "# 10    factory_gen2_100     974.0      1249     522-723-4      \n",
    "# 11    factory_gen6_100     966.6      1248     684-564-0      \n",
    "# 12    factory_gen4_100     964.2      1251     557-693-1      \n",
    "# 13    factory_gen1_100     962.5      1252     547-705-0      \n",
    "# 14    factory_gen3_100     947.0      1251     528-723-0      \n",
    "# 15    factory_gen1_200     941.1      1252     630-620-2      \n",
    "# 16    factory_gen0_100     896.5      1248     410-838-0     \n",
    "\n",
    "\n",
    "## 20 generations.\n",
    "# Running tournament...\n",
    "# Tournament Progress: 100%|██████████| 1000/1000 [08:35<00:00,  1.94it/s]\n",
    "\n",
    "# Tournament Standings:\n",
    "# Rank  Player               ELO        Games    W-L-D          \n",
    "# -----------------------------------------------------------------\n",
    "# 1     factory_gen10_200    1114.2     333      212-120-1      \n",
    "# 2     factory_gen2_200     1032.6     333      190-141-2      \n",
    "# 3     factory_gen1_200     1003.9     334      159-175-0      \n",
    "# 4     factory_gen20_200    1000.9     335      171-164-0      \n",
    "# 5     factory_gen5_200     974.6      331      183-146-2      \n",
    "# 6     factory_gen0_200     873.8      334      82-251-1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model (continued)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.01)\n",
    "tuner.autotune_smart()\n",
    "\n",
    "# Using initial model as baseline.\n",
    "# ## Initial Model, loss=2.1298508644104004 elapsed=171.78943705558777s\n",
    "# ## Searching generation 0 with 22 candidates, including ['bias: False -> True', 'learning_rate: 0.005 -> 0.002', 'learning_rate: 0.005 -> 0.002', 'dtype: bfloat16 -> float16', 'weight_decay: 0.1 -> 0.2']\n",
    "# ## improved: False, loss=2.1332 elapsed=178.64s, mutation bias: False -> True\n",
    "# ## improved: False, loss=2.1395 elapsed=172.03s, mutation learning_rate: 0.005 -> 0.002\n",
    "# ## improved: False, loss=2.1395 elapsed=172.03s, mutation learning_rate: 0.005 -> 0.002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "tuner.autotune_smart()\n",
    "from rgi.rgizero.models.action_history_transformer import ActionHistoryTransformer, ActionHistoryTransformerEvaluator\n",
    "from rgi.rgizero.models.transformer import TransformerConfig\n",
    "\n",
    "tiny_config: TransformerConfig = TransformerConfig(n_max_context=100, n_layer=2, n_head=2, n_embd=8)\n",
    "tiny_model = ActionHistoryTransformer(config=tiny_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0))\n",
    "tiny_model.to(device)\n",
    "tiny_evaluator = ActionHistoryTransformerEvaluator(tiny_model, device=device, block_size=5, vocab=action_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.0001)\n",
    "tuner.autotune_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    initial_params=initial_params.copy(),\n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.0)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "best_model = tuner.load_best_model()\n",
    "compare_model_vs_data(best_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "print(f'tuner.best_loss={tuner.best_loss}')\n",
    "print(f'tuner.best_loss_elapsed={int(tuner.best_loss_elapsed)//60}m{tuner.best_loss_elapsed%60:.0f}s')\n",
    "pprint(tuner.best_params)\n",
    "# best_params = tuner.initial_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print tuner stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    initial_params=initial_params.copy(),\n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "# print stats based on cached results.\n",
    "tuner_stats = tuner.print_hparam_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(k,v['mean_val_delta']) for (k,v) in sorted(tuner_stats.items(), key=lambda x: x[1]['mean_val_delta'], reverse=True)]\n",
    "\n",
    "for x in  sorted([(v['mean_val_delta'], k, v['mean_val_1'], v['mean_val_2']) for (k,v) in tuner_stats.items() if not np.isnan(v['mean_val_delta'])], reverse=True): print(x)\n",
    "# sorted([(v['mean_val_delta'], k) for (k,v) in tuner_stats.items() if not np.isnan(v['mean_val_delta'])], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sorted([(v['std_val_delta'], k, v['mean_val_1'], v['mean_val_2']) for (k,v) in tuner_stats.items() if not np.isnan(v['std_val_delta'])], reverse=True): print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Convergence\n",
    "\n",
    "Synthetic sanity-check: train on a toy 2-step game where the first action strongly determines the winner. This verifies the value head and training loop can learn simple patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"xxx STOP HERE xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_0 = game.initial_state()\n",
    "all_actions_0 = game.all_actions()\n",
    "\n",
    "print(all_actions_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def play_random_game_with_fake_reward(game, max_actions) -> dict:\n",
    "    state = game.initial_state()\n",
    "    action_history = []\n",
    "    legal_policies = []\n",
    "    legal_action_idx_list = []\n",
    "\n",
    "    all_actions = game.all_actions()\n",
    "    all_action_idx_map = {action: idx for idx, action in enumerate(all_actions)}\n",
    "\n",
    "    num_actions = 0\n",
    "    while not game.is_terminal(state) and num_actions < max_actions:\n",
    "        current_player = game.current_player_id(state)\n",
    "        legal_actions = game.legal_actions(state)\n",
    "        action_idx = random.randrange(len(legal_actions))\n",
    "        action = legal_actions[action_idx]\n",
    "\n",
    "        action_history.append(action)\n",
    "        legal_policies.append(np.ones(len(legal_actions))/len(legal_actions))\n",
    "        legal_action_idx = np.array([all_action_idx_map[action] for action in legal_actions])\n",
    "        legal_action_idx_list.append(legal_action_idx)\n",
    "\n",
    "        state = game.next_state(state, action)\n",
    "        num_actions += 1\n",
    "\n",
    "    # Determine outcome\n",
    "    fake_reward = np.mean(action_history) / len(legal_actions)\n",
    "    rewards = np.array([fake_reward, 1.0-fake_reward])\n",
    "    if fake_reward >= 0.5:\n",
    "        winner = 1\n",
    "    else:\n",
    "        winner = 2\n",
    "\n",
    "    return {\n",
    "        \"winner\": winner,\n",
    "        \"rewards\": rewards,\n",
    "        \"action_history\": action_history,\n",
    "        \"legal_policies\": legal_policies,\n",
    "        \"final_state\": state,\n",
    "        \"legal_action_idx\": legal_action_idx_list,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_game_with_fake_reward(game, max_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [play_random_game_with_fake_reward(game, max_actions=2) for _ in range(100_000)]\n",
    "print_game_stats(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_gen_name = \"fake-0\"\n",
    "trajectory_path = write_trajectory_dataset(results, action_vocab, fake_gen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_model_config = model_config_dict[MODEL_SIZE]\n",
    "fake_model_config = model_config_dict[\"large\"]\n",
    "fake_model = create_random_model(fake_model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42, device=device)\n",
    "\n",
    "training_splits = [f'gen-{fake_gen_name}']\n",
    "fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n",
    "save_model(fake_model, fake_trainer, fake_gen_name)\n",
    "\n",
    "## model_size=tiny\n",
    "# num decayed parameter tensors: 11, with 1,968 parameters\n",
    "# num non-decayed parameter tensors: 7, with 50 parameters\n",
    "# using fused AdamW: False\n",
    "# step 0: train loss 2.7817, val loss 2.7816\n",
    "# iter 0/49/488: loss 2.7821, time 2537.56ms\n",
    "# iter 100/147/488: loss 2.6890, time 53.61ms\n",
    "# iter 200/245/488: loss 2.6342, time 63.05ms\n",
    "# iter 300/343/488: loss 2.6187, time 55.31ms\n",
    "# iter 400/441/488: loss 2.6147, time 61.11ms\n",
    "\n",
    "## model_size=large\n",
    "# num decayed parameter tensors: 35, with 1,579,776 parameters\n",
    "# num non-decayed parameter tensors: 19, with 2,186 parameters\n",
    "# using fused AdamW: False\n",
    "# step 0: train loss 2.8087, val loss 2.8088\n",
    "# iter 0/49/488: loss 2.8099, time 11225.20ms\n",
    "# iter 100/147/488: loss 2.6065, time 596.91ms\n",
    "# iter 200/245/488: loss 2.6075, time 618.00ms\n",
    "# iter 300/343/488: loss 2.6080, time 613.63ms\n",
    "# iter 400/441/488: loss 2.6051, time 616.39ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rerun in range(10):\n",
    "#     print(f\"Re-running training for {fake_gen_name} {rerun+1} of 10\")\n",
    "#     fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n",
    "#     save_model(fake_model, fake_trainer, fake_gen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [td for td in td_array]\n",
    "fake_td_array = [TrajectoryDataset(DATA_DIR, split, block_size=n_max_context) for split in training_splits]\n",
    "fake_unrolled = [(generation+1, d) for generation, td in enumerate(fake_td_array) for d in td]\n",
    "\n",
    "# gen, d = unrolled[0], \n",
    "# d.action[:2]\n",
    "# d.value[0]\n",
    "\n",
    "# Inspect training data\n",
    "fake_dd = defaultdict(lambda: defaultdict(lambda: torch.tensor([0., 0.])))\n",
    "\n",
    "for gen, d in fake_unrolled:\n",
    "    for g in ['*', gen]:    \n",
    "        fake_dd[tuple(tuple(d.action[:0].tolist()))][g] += d.value[0]\n",
    "        fake_dd[tuple(tuple(d.action[:1].tolist()))][g] += d.value[0]\n",
    "        fake_dd[tuple(tuple(d.action[:2].tolist()))][g] += d.value[0]\n",
    "        # fake_dd[tuple(tuple(d.action[:3].tolist()))][g] += d.value[0]\n",
    "\n",
    "print(f\"len(fake_dd) = {len(fake_dd)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_model = load_model(fake_gen_name)\n",
    "compare_model_vs_data(fake_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
