{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step run of alphazero self-play & training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_config_fields: {'n_max_context', 'dropout', 'n_head', 'n_layer', 'n_embd', 'bias'}\n",
      "train_config_fields: {'wandb_log', 'beta1', 'min_lr', 'eval_iters', 'decay_lr', 'max_iters', 'max_epochs', 'warmup_iters', 'batch_size', 'eval_only', 'patience', 'device', 'model_version', 'learning_rate', 'eval_interval', 'weight_decay', 'lr_decay_iters', 'compile', 'always_save_checkpoint', 'beta2', 'gradient_accumulation_steps', 'model_name', 'dtype', 'grad_clip', 'log_interval'}\n",
      "Detected device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Game and players\n",
    "from rgi.rgizero.experiment import ExperimentRunner, ExperimentConfig\n",
    "from rgi.rgizero.data.trajectory_dataset import Vocab, print_dataset_stats, TrajectoryDataset\n",
    "from rgi.rgizero.evaluators import ActionHistoryTransformerEvaluator, AsyncNetworkEvaluator\n",
    "from rgi.rgizero.models.tuner import create_random_model\n",
    "\n",
    "import notebook_utils\n",
    "from notebook_utils import reload_local_modules\n",
    "\n",
    "device = notebook_utils.detect_device()\n",
    "\n",
    "## Disable for debugger stability?\n",
    "# # Allow asyncio to work with jupyter notebook\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# Increase numpy print width\n",
    "np.set_printoptions(linewidth=300)\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_GENERATIONS = True\n",
    "\n",
    "\n",
    "# Create Experiment Config\n",
    "experiment_config = ExperimentConfig(\n",
    "    experiment_name='smoketest-e2e-v3',   # Use sliding window.\n",
    "    # experiment_name='smoketest-e2e-v2',\n",
    "    # parent_experiment_name='smoketest-e2e',\n",
    "    game_name='connect4',\n",
    "    num_generations=40,\n",
    "    num_games_per_gen=10_000,\n",
    "    num_simulations=200,\n",
    "    # model_size=\"tiny\",\n",
    "    # train_batch_size=10,\n",
    "    # max_training_epochs=2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Tuned params from connect4 with 23k training games.\n",
    "tuned_params = {\n",
    "    'batch_size': 512,\n",
    "    'beta1': 0.9,\n",
    "    'beta2': 0.99,\n",
    "    'bias': False,\n",
    "    'decay_lr': True,\n",
    "    'dropout': 0.0,\n",
    "    'dtype': 'float16',\n",
    "    'grad_clip': 1.0,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'learning_rate': 0.001,\n",
    "    'lr_decay_iters': 5000,\n",
    "    'max_epochs': 1000000,\n",
    "    'max_iters': 30_000,  # 30_000\n",
    "    'min_lr': 0.0001,\n",
    "    'n_embd': 64,\n",
    "    'n_head': 2,\n",
    "    'n_layer': 4,\n",
    "    'n_max_context': 44,\n",
    "    'warmup_iters': 1000,\n",
    "    'weight_decay': 0.2,\n",
    "    'eval_iters': 100,\n",
    "    'log_interval': 200,\n",
    "    'eval_interval': 1000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up game and experiment runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Runner initialized\n",
      "Game: connect4, Players: 2, Actions: [1, 2, 3, 4, 5, 6, 7]\n",
      "Data dir:  /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data\n",
      "Model dir:  /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models\n"
     ]
    }
   ],
   "source": [
    "from rgi.rgizero.data.trajectory_dataset import Vocab\n",
    "from rgi.rgizero.common import TOKENS\n",
    "\n",
    "# Initialize Experiment Runner\n",
    "experiment_base_dir = Path.cwd().parent / 'experiments'\n",
    "experiment_runner = ExperimentRunner(experiment_config, experiment_base_dir, training_args=tuned_params)\n",
    "game = experiment_runner.game\n",
    "action_vocab = experiment_runner.action_vocab\n",
    "n_max_context = experiment_runner.n_max_context\n",
    "\n",
    "DATA_DIR = experiment_runner.data_dir\n",
    "MODEL_DIR = experiment_runner.models_dir\n",
    "\n",
    "print('✅ Runner initialized')\n",
    "print(f'Game: {experiment_runner.config.game_name}, Players: {experiment_runner.num_players}, Actions: {list(game.base_game.all_actions())}')\n",
    "print('Data dir: ', DATA_DIR)\n",
    "print('Model dir: ', MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create random generation_0 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiment: smoketest-e2e-v3\n",
      "Initializing Random Gen 0 model.\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-0.pt\n"
     ]
    }
   ],
   "source": [
    "# Initialize (creates Random Gen 0 if needed)\n",
    "model_0 = experiment_runner.initialize()\n",
    "current_model = model_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generation 1 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:   1%|▏         | 149/10000 [00:44<27:02,  6.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.010 seconds, size=1000, eval-per-second=101165.07, total-batches=1000, mean-eval-per-second=101727.88, mean-time-per-batch=0.010, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:   7%|▋         | 657/10000 [01:36<10:34, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=88967.93, total-batches=2000, mean-eval-per-second=93760.01, mean-time-per-batch=0.011, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  12%|█▏        | 1209/10000 [02:30<15:45,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.010 seconds, size=1000, eval-per-second=98617.57, total-batches=3000, mean-eval-per-second=90231.78, mean-time-per-batch=0.011, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  18%|█▊        | 1756/10000 [03:25<20:59,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.017 seconds, size=1000, eval-per-second=59182.23, total-batches=4000, mean-eval-per-second=85528.89, mean-time-per-batch=0.012, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  23%|██▎       | 2274/10000 [04:24<15:44,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.016 seconds, size=1000, eval-per-second=60683.24, total-batches=5000, mean-eval-per-second=78077.08, mean-time-per-batch=0.013, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  28%|██▊       | 2832/10000 [05:19<07:55, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=89032.14, total-batches=6000, mean-eval-per-second=78474.36, mean-time-per-batch=0.013, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  34%|███▍      | 3375/10000 [06:17<08:11, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.017 seconds, size=1000, eval-per-second=59290.15, total-batches=7000, mean-eval-per-second=76111.98, mean-time-per-batch=0.013, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  39%|███▉      | 3879/10000 [07:14<09:44, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=92184.53, total-batches=8000, mean-eval-per-second=75266.89, mean-time-per-batch=0.013, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  44%|████▍     | 4419/10000 [08:10<21:57,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.022 seconds, size=1000, eval-per-second=45126.73, total-batches=9000, mean-eval-per-second=75465.56, mean-time-per-batch=0.013, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  50%|████▉     | 4975/10000 [09:12<08:44,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.018 seconds, size=1000, eval-per-second=56156.92, total-batches=10000, mean-eval-per-second=72496.36, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  55%|█████▌    | 5517/10000 [10:12<07:40,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.020 seconds, size=1000, eval-per-second=49667.30, total-batches=11000, mean-eval-per-second=71098.26, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  60%|██████    | 6050/10000 [11:09<08:08,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=88323.45, total-batches=12000, mean-eval-per-second=71172.65, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  66%|██████▌   | 6597/10000 [12:05<05:51,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=88386.73, total-batches=13000, mean-eval-per-second=70770.35, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  71%|███████▏  | 7143/10000 [13:01<03:01, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=89174.10, total-batches=14000, mean-eval-per-second=70879.95, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  76%|███████▋  | 7648/10000 [14:00<04:49,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=92860.08, total-batches=15000, mean-eval-per-second=70520.77, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  82%|████████▏ | 8180/10000 [14:58<06:32,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.018 seconds, size=1000, eval-per-second=54590.59, total-batches=16000, mean-eval-per-second=70220.14, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  87%|████████▋ | 8729/10000 [15:56<02:24,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.019 seconds, size=1000, eval-per-second=51671.81, total-batches=17000, mean-eval-per-second=69744.20, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  93%|█████████▎| 9282/10000 [16:54<01:25,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.010 seconds, size=719, eval-per-second=69162.78, total-batches=18000, mean-eval-per-second=68400.25, mean-time-per-batch=0.015, mean-batch-size=995.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  97%|█████████▋| 9738/10000 [17:30<00:23, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.005 seconds, size=262, eval-per-second=56644.72, total-batches=19000, mean-eval-per-second=65679.34, mean-time-per-batch=0.015, mean-batch-size=968.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  99%|█████████▉| 9940/10000 [17:46<00:04, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.023 seconds, size=61, eval-per-second=2680.52, total-batches=20000, mean-eval-per-second=63712.86, mean-time-per-batch=0.015, mean-batch-size=927.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9997/10000 [17:53<00:00,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.021 seconds, size=6, eval-per-second=281.72, total-batches=21000, mean-eval-per-second=62611.78, mean-time-per-batch=0.014, mean-batch-size=884.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [17:53<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 1...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using fused AdamW: False\n",
      "step 0: losses: train:2.7692, train_policy_loss:2.0635, train_value_loss:0.7057, val:2.7680, val_policy_loss:2.0628, val_value_loss:0.7052\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1/best.pt\n",
      "iter 0/18/30000: loss 2.7641, policy_loss:2.0632, value_loss:0.7009, time 1.88s, iter_time: 0.00ms\n",
      "iter 200/216/30000: loss 2.5468, policy_loss:1.8915, value_loss:0.6553, time 0.12s, iter_time: 58.97ms\n",
      "iter 400/414/30000: loss 2.5205, policy_loss:1.8687, value_loss:0.6518, time 0.42s, iter_time: 104.37ms\n",
      "iter 600/612/30000: loss 2.4910, policy_loss:1.8666, value_loss:0.6244, time 0.50s, iter_time: 83.88ms\n",
      "iter 800/810/30000: loss 2.4833, policy_loss:1.8592, value_loss:0.6241, time 0.63s, iter_time: 78.59ms\n",
      "step 1000: losses: train:2.4615, train_policy_loss:1.8532, train_value_loss:0.6083, val:2.5309, val_policy_loss:1.8584, val_value_loss:0.6724\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1\n",
      "iter 1000/1008/30000: loss 2.4803, policy_loss:1.8529, value_loss:0.6274, time 2.11s, iter_time: 211.11ms\n",
      "iter 1200/1206/30000: loss 2.4424, policy_loss:1.8534, value_loss:0.5890, time 1.14s, iter_time: 94.73ms\n",
      "iter 1400/1404/30000: loss 2.4103, policy_loss:1.8385, value_loss:0.5718, time 0.86s, iter_time: 61.22ms\n",
      "iter 1600/1602/30000: loss 2.3832, policy_loss:1.8468, value_loss:0.5364, time 1.19s, iter_time: 74.53ms\n",
      "iter 1800/1818/30000: loss 2.3330, policy_loss:1.8368, value_loss:0.4962, time 0.05s, iter_time: 0.00ms\n",
      "step 2000: losses: train:2.2985, train_policy_loss:1.8362, train_value_loss:0.4623, val:2.7724, val_policy_loss:1.8532, val_value_loss:0.9192\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1\n",
      "iter 2000/2016/30000: loss 2.3277, policy_loss:1.8353, value_loss:0.4923, time 1.62s, iter_time: 810.48ms\n",
      "iter 2200/2214/30000: loss 2.2521, policy_loss:1.8377, value_loss:0.4144, time 0.21s, iter_time: 52.54ms\n",
      "iter 2400/2412/30000: loss 2.2143, policy_loss:1.8242, value_loss:0.3901, time 0.52s, iter_time: 86.79ms\n",
      "iter 2600/2610/30000: loss 2.2158, policy_loss:1.8273, value_loss:0.3885, time 0.56s, iter_time: 70.57ms\n",
      "iter 2800/2808/30000: loss 2.2109, policy_loss:1.8256, value_loss:0.3853, time 0.49s, iter_time: 48.83ms\n",
      "step 3000: losses: train:2.1689, train_policy_loss:1.8196, train_value_loss:0.3493, val:3.1894, val_policy_loss:1.8500, val_value_loss:1.3394\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1\n",
      "iter 3000/3006/30000: loss 2.1841, policy_loss:1.8180, value_loss:0.3661, time 2.20s, iter_time: 183.60ms\n",
      "iter 3200/3204/30000: loss 2.1694, policy_loss:1.8163, value_loss:0.3531, time 0.63s, iter_time: 45.36ms\n",
      "iter 3400/3402/30000: loss 2.1413, policy_loss:1.8165, value_loss:0.3248, time 0.97s, iter_time: 60.52ms\n",
      "iter 3600/3618/30000: loss 2.1389, policy_loss:1.8117, value_loss:0.3272, time 0.04s, iter_time: 0.00ms\n",
      "iter 3800/3816/30000: loss 2.0990, policy_loss:1.8043, value_loss:0.2946, time 0.12s, iter_time: 57.58ms\n",
      "step 4000: losses: train:2.0911, train_policy_loss:1.8019, train_value_loss:0.2892, val:3.7444, val_policy_loss:1.8542, val_value_loss:1.8903\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1\n",
      "iter 4000/4014/30000: loss 2.0985, policy_loss:1.8061, value_loss:0.2924, time 1.38s, iter_time: 344.83ms\n",
      "iter 4200/4212/30000: loss 2.0752, policy_loss:1.7994, value_loss:0.2758, time 0.28s, iter_time: 46.63ms\n",
      "iter 4400/4410/30000: loss 2.0791, policy_loss:1.7974, value_loss:0.2817, time 0.35s, iter_time: 44.37ms\n",
      "iter 4600/4608/30000: loss 2.0807, policy_loss:1.7907, value_loss:0.2900, time 0.71s, iter_time: 70.81ms\n",
      "iter 4800/4806/30000: loss 2.0641, policy_loss:1.7947, value_loss:0.2694, time 0.56s, iter_time: 46.94ms\n",
      "step 5000: losses: train:2.0582, train_policy_loss:1.7895, train_value_loss:0.2688, val:4.2020, val_policy_loss:1.8616, val_value_loss:2.3404\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1\n",
      "iter 5000/5004/30000: loss 2.0654, policy_loss:1.7870, value_loss:0.2784, time 1.07s, iter_time: 76.38ms\n",
      "iter 5200/5202/30000: loss 2.0678, policy_loss:1.7900, value_loss:0.2778, time 0.70s, iter_time: 43.47ms\n",
      "iter 5400/5418/30000: loss 2.0486, policy_loss:1.7856, value_loss:0.2629, time 0.04s, iter_time: 0.00ms\n",
      "iter 5600/5616/30000: loss 2.0480, policy_loss:1.7875, value_loss:0.2605, time 0.12s, iter_time: 60.35ms\n",
      "iter 5800/5814/30000: loss 2.0427, policy_loss:1.7851, value_loss:0.2576, time 0.19s, iter_time: 48.68ms\n",
      "step 6000: losses: train:2.0467, train_policy_loss:1.7827, train_value_loss:0.2639, val:4.3974, val_policy_loss:1.8681, val_value_loss:2.5293\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-1/best.pt (val_loss=2.5309)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-1.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 10000\n",
      "  Total actions: 138424\n",
      "  Avg trajectory length: 13.84\n",
      "Prefix Stats:\n",
      "actions=(): 10000 win=6186 loss=3811 draw=3 win1%=61.86 model-win1%=61.15\n",
      "actions=(1,): 495 win=214 loss=281 draw=0 win1%=43.23 model-win1%=38.30\n",
      "actions=(2,): 396 win=221 loss=175 draw=0 win1%=55.81 model-win1%=55.48\n",
      "actions=(3,): 501 win=291 loss=210 draw=0 win1%=58.08 model-win1%=62.21\n",
      "actions=(4,): 4057 win=2884 loss=1171 draw=2 win1%=71.09 model-win1%=71.29\n",
      "actions=(4, 1): 1920 win=1414 loss=505 draw=1 win1%=73.65 model-win1%=69.70\n",
      "actions=(5,): 1304 win=816 loss=488 draw=0 win1%=62.58 model-win1%=61.25\n",
      "actions=(5, 1): 691 win=460 loss=231 draw=0 win1%=66.57 model-win1%=63.24\n",
      "actions=(6,): 2267 win=1275 loss=991 draw=1 win1%=56.24 model-win1%=57.32\n",
      "actions=(6, 1): 1151 win=657 loss=493 draw=1 win1%=57.08 model-win1%=57.09\n",
      "actions=(7,): 980 win=485 loss=495 draw=0 win1%=49.49 model-win1%=52.91\n",
      "\n",
      "=== Generation 2 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  10%|█         | 1006/10000 [00:55<09:22, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=88543.47, total-batches=1000, mean-eval-per-second=91289.03, mean-time-per-batch=0.011, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  22%|██▏       | 2204/10000 [01:57<13:57,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.012 seconds, size=1000, eval-per-second=83857.57, total-batches=2000, mean-eval-per-second=85318.68, mean-time-per-batch=0.012, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  34%|███▎      | 3356/10000 [02:59<05:04, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.012 seconds, size=1000, eval-per-second=85516.02, total-batches=3000, mean-eval-per-second=81578.95, mean-time-per-batch=0.012, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  45%|████▌     | 4542/10000 [04:02<03:40, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.015 seconds, size=1000, eval-per-second=66334.08, total-batches=4000, mean-eval-per-second=81374.73, mean-time-per-batch=0.012, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  57%|█████▋    | 5728/10000 [05:06<02:48, 25.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.016 seconds, size=1000, eval-per-second=62386.46, total-batches=5000, mean-eval-per-second=80334.04, mean-time-per-batch=0.012, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  69%|██████▉   | 6888/10000 [06:08<01:56, 26.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.013 seconds, size=1000, eval-per-second=79275.42, total-batches=6000, mean-eval-per-second=80407.81, mean-time-per-batch=0.012, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  81%|████████  | 8088/10000 [07:14<02:27, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.010 seconds, size=1000, eval-per-second=96003.66, total-batches=7000, mean-eval-per-second=79264.21, mean-time-per-batch=0.013, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  92%|█████████▏| 9243/10000 [08:20<00:56, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.033 seconds, size=758, eval-per-second=23107.77, total-batches=8000, mean-eval-per-second=75658.59, mean-time-per-batch=0.013, mean-batch-size=996.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  98%|█████████▊| 9846/10000 [08:59<00:09, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.027 seconds, size=155, eval-per-second=5767.23, total-batches=9000, mean-eval-per-second=65332.01, mean-time-per-batch=0.014, mean-batch-size=928.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9987/10000 [09:11<00:02,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=14, eval-per-second=7454.65, total-batches=10000, mean-eval-per-second=61305.61, mean-time-per-batch=0.014, mean-batch-size=841.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [09:13<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 2...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.4074, train_policy_loss:1.8335, train_value_loss:0.5739, val:2.4091, val_policy_loss:1.8365, val_value_loss:0.5726\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2/best.pt\n",
      "iter 0/36/30000: loss 2.4120, policy_loss:1.8372, value_loss:0.5748, time 12.18s, iter_time: 0.00ms\n",
      "iter 200/216/30000: loss 2.2299, policy_loss:1.6950, value_loss:0.5349, time 6.66s, iter_time: 333.12ms\n",
      "iter 400/432/30000: loss 2.1864, policy_loss:1.6818, value_loss:0.5046, time 0.20s, iter_time: 49.29ms\n",
      "iter 600/612/30000: loss 2.2156, policy_loss:1.6824, value_loss:0.5332, time 4.27s, iter_time: 177.87ms\n",
      "iter 800/828/30000: loss 2.1400, policy_loss:1.6481, value_loss:0.4919, time 0.79s, iter_time: 98.28ms\n",
      "step 1000: losses: train:2.1753, train_policy_loss:1.6690, train_value_loss:0.5063, val:2.2458, val_policy_loss:1.6856, val_value_loss:0.5602\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2\n",
      "iter 1000/1008/30000: loss 2.1924, policy_loss:1.6805, value_loss:0.5119, time 7.92s, iter_time: 282.87ms\n",
      "iter 1200/1224/30000: loss 2.1561, policy_loss:1.6681, value_loss:0.4880, time 1.05s, iter_time: 87.44ms\n",
      "iter 1400/1404/30000: loss 2.1908, policy_loss:1.6780, value_loss:0.5128, time 1.66s, iter_time: 51.93ms\n",
      "iter 1600/1620/30000: loss 2.1360, policy_loss:1.6608, value_loss:0.4752, time 2.41s, iter_time: 150.74ms\n",
      "iter 1800/1836/30000: loss 2.1057, policy_loss:1.6583, value_loss:0.4474, time 0.04s, iter_time: 0.00ms\n",
      "step 2000: losses: train:2.0968, train_policy_loss:1.6516, train_value_loss:0.4453, val:2.3204, val_policy_loss:1.6751, val_value_loss:0.6453\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2\n",
      "iter 2000/2016/30000: loss 2.1232, policy_loss:1.6621, value_loss:0.4611, time 3.86s, iter_time: 193.21ms\n",
      "iter 2200/2232/30000: loss 2.1364, policy_loss:1.6627, value_loss:0.4736, time 0.19s, iter_time: 47.37ms\n",
      "iter 2400/2412/30000: loss 2.1087, policy_loss:1.6638, value_loss:0.4449, time 1.42s, iter_time: 59.07ms\n",
      "iter 2600/2628/30000: loss 2.0184, policy_loss:1.6352, value_loss:0.3832, time 0.85s, iter_time: 106.65ms\n",
      "iter 2800/2808/30000: loss 2.0436, policy_loss:1.6497, value_loss:0.3939, time 1.75s, iter_time: 62.55ms\n",
      "step 3000: losses: train:2.0163, train_policy_loss:1.6398, train_value_loss:0.3764, val:2.5070, val_policy_loss:1.6690, val_value_loss:0.8380\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2\n",
      "iter 3000/3024/30000: loss 2.0173, policy_loss:1.6320, value_loss:0.3853, time 4.04s, iter_time: 336.88ms\n",
      "iter 3200/3204/30000: loss 1.9999, policy_loss:1.6291, value_loss:0.3708, time 1.83s, iter_time: 57.28ms\n",
      "iter 3400/3420/30000: loss 2.0129, policy_loss:1.6317, value_loss:0.3811, time 1.43s, iter_time: 89.08ms\n",
      "iter 3600/3636/30000: loss 1.9593, policy_loss:1.6206, value_loss:0.3387, time 0.05s, iter_time: 0.00ms\n",
      "iter 3800/3816/30000: loss 1.9632, policy_loss:1.6337, value_loss:0.3296, time 0.80s, iter_time: 40.07ms\n",
      "step 4000: losses: train:1.9470, train_policy_loss:1.6292, train_value_loss:0.3179, val:2.8221, val_policy_loss:1.6683, val_value_loss:1.1538\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2\n",
      "iter 4000/4032/30000: loss 1.9579, policy_loss:1.6425, value_loss:0.3154, time 2.74s, iter_time: 685.16ms\n",
      "iter 4200/4212/30000: loss 1.9514, policy_loss:1.6392, value_loss:0.3122, time 1.03s, iter_time: 42.88ms\n",
      "iter 4400/4428/30000: loss 1.9369, policy_loss:1.6452, value_loss:0.2917, time 0.42s, iter_time: 52.39ms\n",
      "iter 4600/4608/30000: loss 1.9236, policy_loss:1.6154, value_loss:0.3083, time 1.13s, iter_time: 40.25ms\n",
      "iter 4800/4824/30000: loss 1.9403, policy_loss:1.6274, value_loss:0.3129, time 0.50s, iter_time: 41.82ms\n",
      "step 5000: losses: train:1.9171, train_policy_loss:1.6225, train_value_loss:0.2946, val:3.0259, val_policy_loss:1.6676, val_value_loss:1.3583\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2\n",
      "iter 5000/5004/30000: loss 1.9118, policy_loss:1.6152, value_loss:0.2967, time 4.90s, iter_time: 153.03ms\n",
      "iter 5200/5220/30000: loss 1.9363, policy_loss:1.6349, value_loss:0.3013, time 0.75s, iter_time: 47.02ms\n",
      "iter 5400/5436/30000: loss 1.8796, policy_loss:1.5970, value_loss:0.2826, time 0.05s, iter_time: 0.00ms\n",
      "iter 5600/5616/30000: loss 1.9331, policy_loss:1.6348, value_loss:0.2983, time 0.85s, iter_time: 42.66ms\n",
      "iter 5800/5832/30000: loss 1.8989, policy_loss:1.6122, value_loss:0.2868, time 0.19s, iter_time: 48.72ms\n",
      "step 6000: losses: train:1.9089, train_policy_loss:1.6205, train_value_loss:0.2884, val:3.1429, val_policy_loss:1.6695, val_value_loss:1.4734\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-2/best.pt (val_loss=2.2458)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-2.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 20000\n",
      "  Total actions: 239798\n",
      "  Avg trajectory length: 11.99\n",
      "Prefix Stats:\n",
      "actions=(): 20000 win=14324 loss=5673 draw=3 win1%=71.62 model-win1%=73.09\n",
      "actions=(1,): 571 win=242 loss=329 draw=0 win1%=42.38 model-win1%=39.78\n",
      "actions=(2,): 505 win=250 loss=255 draw=0 win1%=49.50 model-win1%=51.85\n",
      "actions=(3,): 697 win=381 loss=316 draw=0 win1%=54.66 model-win1%=54.06\n",
      "actions=(4,): 12564 win=10465 loss=2097 draw=2 win1%=83.29 model-win1%=85.53\n",
      "actions=(4, 1): 3305 win=2692 loss=612 draw=1 win1%=81.45 model-win1%=86.24\n",
      "actions=(4, 3): 1088 win=876 loss=212 draw=0 win1%=80.51 model-win1%=82.75\n",
      "actions=(4, 4): 1447 win=1106 loss=341 draw=0 win1%=76.43 model-win1%=80.55\n",
      "actions=(4, 5): 4681 win=4117 loss=564 draw=0 win1%=87.95 model-win1%=92.15\n",
      "actions=(5,): 1743 win=1009 loss=734 draw=0 win1%=57.89 model-win1%=54.34\n",
      "actions=(6,): 2784 win=1451 loss=1332 draw=1 win1%=52.12 model-win1%=54.65\n",
      "actions=(6, 1): 1188 win=680 loss=507 draw=1 win1%=57.24 model-win1%=60.07\n",
      "actions=(7,): 1136 win=526 loss=610 draw=0 win1%=46.30 model-win1%=49.51\n",
      "\n",
      "=== Generation 3 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  13%|█▎        | 1343/10000 [01:05<06:01, 23.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.016 seconds, size=1000, eval-per-second=63718.04, total-batches=1000, mean-eval-per-second=76436.45, mean-time-per-batch=0.013, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  30%|███       | 3020/10000 [02:17<05:11, 22.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.011 seconds, size=1000, eval-per-second=87844.35, total-batches=2000, mean-eval-per-second=72644.10, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  47%|████▋     | 4705/10000 [03:29<02:53, 30.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.038 seconds, size=1000, eval-per-second=26446.47, total-batches=3000, mean-eval-per-second=72705.77, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  64%|██████▍   | 6409/10000 [04:40<04:29, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.021 seconds, size=1000, eval-per-second=46757.16, total-batches=4000, mean-eval-per-second=73270.03, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  81%|████████  | 8085/10000 [05:52<01:27, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.015 seconds, size=1000, eval-per-second=65329.80, total-batches=5000, mean-eval-per-second=73093.17, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  97%|█████████▋| 9703/10000 [07:07<00:10, 28.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.045 seconds, size=303, eval-per-second=6663.14, total-batches=6000, mean-eval-per-second=62099.11, mean-time-per-batch=0.016, mean-batch-size=973.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9990/10000 [07:31<00:01,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=11, eval-per-second=6245.75, total-batches=7000, mean-eval-per-second=52408.52, mean-time-per-batch=0.016, mean-batch-size=848.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [07:33<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 3...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.0173, train_policy_loss:1.5521, train_value_loss:0.4652, val:2.0110, val_policy_loss:1.5544, val_value_loss:0.4566\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3/best.pt\n",
      "iter 0/53/30000: loss 2.0464, policy_loss:1.5600, value_loss:0.4864, time 5.13s, iter_time: 0.00ms\n",
      "iter 200/212/30000: loss 1.8488, policy_loss:1.4365, value_loss:0.4123, time 3.89s, iter_time: 94.91ms\n",
      "iter 400/424/30000: loss 1.8588, policy_loss:1.4470, value_loss:0.4118, time 1.84s, iter_time: 63.56ms\n",
      "iter 600/636/30000: loss 1.8889, policy_loss:1.4320, value_loss:0.4569, time 1.92s, iter_time: 112.88ms\n",
      "iter 800/848/30000: loss 1.8908, policy_loss:1.4522, value_loss:0.4386, time 0.38s, iter_time: 76.83ms\n",
      "step 1000: losses: train:1.8747, train_policy_loss:1.4412, train_value_loss:0.4336, val:1.9165, val_policy_loss:1.4535, val_value_loss:0.4630\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3\n",
      "iter 1000/1007/30000: loss 1.9018, policy_loss:1.4539, value_loss:0.4479, time 5.49s, iter_time: 119.33ms\n",
      "iter 1200/1219/30000: loss 1.8380, policy_loss:1.4237, value_loss:0.4143, time 2.15s, iter_time: 63.33ms\n",
      "iter 1400/1431/30000: loss 1.9397, policy_loss:1.4807, value_loss:0.4590, time 0.99s, iter_time: 44.89ms\n",
      "iter 1600/1643/30000: loss 1.8428, policy_loss:1.4354, value_loss:0.4074, time 0.75s, iter_time: 75.21ms\n",
      "iter 1800/1802/30000: loss 1.8224, policy_loss:1.4268, value_loss:0.3957, time 3.53s, iter_time: 69.27ms\n",
      "step 2000: losses: train:1.8277, train_policy_loss:1.4286, train_value_loss:0.3991, val:1.9375, val_policy_loss:1.4451, val_value_loss:0.4924\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3\n",
      "iter 2000/2014/30000: loss 1.8421, policy_loss:1.4298, value_loss:0.4123, time 6.31s, iter_time: 161.69ms\n",
      "iter 2200/2226/30000: loss 1.8122, policy_loss:1.4246, value_loss:0.3876, time 1.03s, iter_time: 38.28ms\n",
      "iter 2400/2438/30000: loss 1.8079, policy_loss:1.4488, value_loss:0.3591, time 0.86s, iter_time: 57.63ms\n",
      "iter 2600/2650/30000: loss 1.8347, policy_loss:1.4575, value_loss:0.3773, time 0.15s, iter_time: 51.49ms\n",
      "iter 2800/2809/30000: loss 1.8091, policy_loss:1.4304, value_loss:0.3788, time 2.39s, iter_time: 54.43ms\n",
      "step 3000: losses: train:1.7643, train_policy_loss:1.4177, train_value_loss:0.3466, val:2.0298, val_policy_loss:1.4378, val_value_loss:0.5920\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3\n",
      "iter 3000/3021/30000: loss 1.7713, policy_loss:1.4132, value_loss:0.3582, time 3.77s, iter_time: 117.80ms\n",
      "iter 3200/3233/30000: loss 1.7015, policy_loss:1.3788, value_loss:0.3226, time 1.44s, iter_time: 71.81ms\n",
      "iter 3400/3445/30000: loss 1.6773, policy_loss:1.3816, value_loss:0.2957, time 0.39s, iter_time: 48.33ms\n",
      "iter 3600/3604/30000: loss 1.7536, policy_loss:1.4049, value_loss:0.3488, time 2.25s, iter_time: 45.82ms\n",
      "iter 3800/3816/30000: loss 1.7542, policy_loss:1.4206, value_loss:0.3336, time 1.41s, iter_time: 38.15ms\n",
      "step 4000: losses: train:1.7114, train_policy_loss:1.4090, train_value_loss:0.3024, val:2.2084, val_policy_loss:1.4358, val_value_loss:0.7726\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3\n",
      "iter 4000/4028/30000: loss 1.7218, policy_loss:1.3969, value_loss:0.3249, time 4.05s, iter_time: 161.99ms\n",
      "iter 4200/4240/30000: loss 1.7049, policy_loss:1.4267, value_loss:0.2782, time 0.60s, iter_time: 46.19ms\n",
      "iter 4400/4452/30000: loss 1.6848, policy_loss:1.3978, value_loss:0.2870, time 0.09s, iter_time: 86.68ms\n",
      "iter 4600/4611/30000: loss 1.7205, policy_loss:1.4211, value_loss:0.2994, time 2.27s, iter_time: 54.03ms\n",
      "iter 4800/4823/30000: loss 1.7214, policy_loss:1.4403, value_loss:0.2811, time 1.30s, iter_time: 43.26ms\n",
      "step 5000: losses: train:1.6889, train_policy_loss:1.4047, train_value_loss:0.2842, val:2.3529, val_policy_loss:1.4340, val_value_loss:0.9188\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3\n",
      "iter 5000/5035/30000: loss 1.7395, policy_loss:1.4185, value_loss:0.3210, time 4.57s, iter_time: 253.81ms\n",
      "iter 5200/5247/30000: loss 1.6768, policy_loss:1.3994, value_loss:0.2774, time 0.37s, iter_time: 61.38ms\n",
      "iter 5400/5406/30000: loss 1.6730, policy_loss:1.3910, value_loss:0.2820, time 2.65s, iter_time: 56.42ms\n",
      "iter 5600/5618/30000: loss 1.6934, policy_loss:1.3742, value_loss:0.3192, time 1.39s, iter_time: 39.67ms\n",
      "iter 5800/5830/30000: loss 1.6872, policy_loss:1.4084, value_loss:0.2787, time 0.93s, iter_time: 40.31ms\n",
      "step 6000: losses: train:1.6807, train_policy_loss:1.4032, train_value_loss:0.2776, val:2.4430, val_policy_loss:1.4337, val_value_loss:1.0093\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-3/best.pt (val_loss=1.9165)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-3.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 30000\n",
      "  Total actions: 352936\n",
      "  Avg trajectory length: 11.76\n",
      "Prefix Stats:\n",
      "actions=(): 30000 win=23394 loss=6603 draw=3 win1%=77.98 model-win1%=78.16\n",
      "actions=(1,): 593 win=247 loss=346 draw=0 win1%=41.65 model-win1%=44.57\n",
      "actions=(2,): 539 win=264 loss=275 draw=0 win1%=48.98 model-win1%=54.52\n",
      "actions=(3,): 734 win=401 loss=333 draw=0 win1%=54.63 model-win1%=56.30\n",
      "actions=(4,): 22226 win=19384 loss=2840 draw=2 win1%=87.21 model-win1%=88.38\n",
      "actions=(4, 1): 4029 win=3398 loss=630 draw=1 win1%=84.34 model-win1%=85.51\n",
      "actions=(4, 4): 8527 win=7526 loss=1001 draw=0 win1%=88.26 model-win1%=89.79\n",
      "actions=(4, 5): 5601 win=5004 loss=597 draw=0 win1%=89.34 model-win1%=87.61\n",
      "actions=(5,): 1833 win=1064 loss=769 draw=0 win1%=58.05 model-win1%=59.42\n",
      "actions=(6,): 2905 win=1501 loss=1403 draw=1 win1%=51.67 model-win1%=56.36\n",
      "actions=(7,): 1170 win=533 loss=637 draw=0 win1%=45.56 model-win1%=53.56\n",
      "\n",
      "=== Generation 4 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  29%|██▊       | 2867/10000 [01:14<02:59, 39.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.021 seconds, size=1000, eval-per-second=47796.70, total-batches=1000, mean-eval-per-second=69487.44, mean-time-per-batch=0.014, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  58%|█████▊    | 5791/10000 [02:33<02:47, 25.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.013 seconds, size=1000, eval-per-second=78914.47, total-batches=2000, mean-eval-per-second=63675.54, mean-time-per-batch=0.016, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  87%|████████▋ | 8728/10000 [03:54<00:38, 32.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.030 seconds, size=1000, eval-per-second=33429.27, total-batches=3000, mean-eval-per-second=60010.67, mean-time-per-batch=0.017, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  99%|█████████▉| 9929/10000 [04:48<00:03, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.004 seconds, size=73, eval-per-second=20499.75, total-batches=4000, mean-eval-per-second=41725.93, mean-time-per-batch=0.020, mean-batch-size=850.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9999/10000 [04:55<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.001 seconds, size=1, eval-per-second=727.80, total-batches=5000, mean-eval-per-second=39229.26, mean-time-per-batch=0.017, mean-batch-size=684.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [04:56<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 4...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:1.7611, train_policy_loss:1.3333, train_value_loss:0.4278, val:1.7582, val_policy_loss:1.3262, val_value_loss:0.4320\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4/best.pt\n",
      "iter 0/71/30000: loss 1.7479, policy_loss:1.3377, value_loss:0.4102, time 28.13s, iter_time: 0.00ms\n",
      "iter 200/213/30000: loss 1.7632, policy_loss:1.3263, value_loss:0.4369, time 12.81s, iter_time: 220.80ms\n",
      "iter 400/426/30000: loss 1.7125, policy_loss:1.3002, value_loss:0.4124, time 8.21s, iter_time: 182.52ms\n",
      "iter 600/639/30000: loss 1.6863, policy_loss:1.2962, value_loss:0.3901, time 2.13s, iter_time: 66.62ms\n",
      "iter 800/852/30000: loss 1.7477, policy_loss:1.3333, value_loss:0.4144, time 3.03s, iter_time: 159.50ms\n",
      "step 1000: losses: train:1.7116, train_policy_loss:1.3010, train_value_loss:0.4106, val:1.7355, val_policy_loss:1.2961, val_value_loss:0.4394\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4\n",
      "iter 1000/1065/30000: loss 1.7369, policy_loss:1.3110, value_loss:0.4259, time 5.14s, iter_time: 856.54ms\n",
      "iter 1200/1207/30000: loss 1.7082, policy_loss:1.3048, value_loss:0.4034, time 4.51s, iter_time: 70.43ms\n",
      "iter 1400/1420/30000: loss 1.7517, policy_loss:1.3181, value_loss:0.4337, time 4.27s, iter_time: 83.66ms\n",
      "iter 1600/1633/30000: loss 1.6197, policy_loss:1.2732, value_loss:0.3465, time 1.79s, iter_time: 47.12ms\n",
      "iter 1800/1846/30000: loss 1.7214, policy_loss:1.3094, value_loss:0.4120, time 1.73s, iter_time: 69.21ms\n",
      "step 2000: losses: train:1.6892, train_policy_loss:1.2923, train_value_loss:0.3969, val:1.7498, val_policy_loss:1.2886, val_value_loss:0.4612\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4\n",
      "iter 2000/2059/30000: loss 1.6679, policy_loss:1.2720, value_loss:0.3959, time 6.02s, iter_time: 501.31ms\n",
      "iter 2200/2201/30000: loss 1.7274, policy_loss:1.3385, value_loss:0.3888, time 7.26s, iter_time: 103.73ms\n",
      "iter 2400/2414/30000: loss 1.6906, policy_loss:1.2936, value_loss:0.3970, time 2.67s, iter_time: 46.79ms\n",
      "iter 2600/2627/30000: loss 1.6815, policy_loss:1.2939, value_loss:0.3877, time 1.76s, iter_time: 40.04ms\n",
      "iter 2800/2840/30000: loss 1.6187, policy_loss:1.2724, value_loss:0.3463, time 1.36s, iter_time: 44.00ms\n",
      "step 3000: losses: train:1.6356, train_policy_loss:1.2816, train_value_loss:0.3540, val:1.7684, val_policy_loss:1.2829, val_value_loss:0.4855\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4\n",
      "iter 3000/3053/30000: loss 1.6234, policy_loss:1.2742, value_loss:0.3492, time 6.28s, iter_time: 348.99ms\n",
      "iter 3200/3266/30000: loss 1.6814, policy_loss:1.3273, value_loss:0.3541, time 0.24s, iter_time: 48.37ms\n",
      "iter 3400/3408/30000: loss 1.6501, policy_loss:1.3057, value_loss:0.3443, time 3.21s, iter_time: 51.03ms\n",
      "iter 3600/3621/30000: loss 1.6541, policy_loss:1.3064, value_loss:0.3477, time 2.18s, iter_time: 43.55ms\n",
      "iter 3800/3834/30000: loss 1.6124, policy_loss:1.2686, value_loss:0.3437, time 1.85s, iter_time: 49.91ms\n",
      "step 4000: losses: train:1.5897, train_policy_loss:1.2729, train_value_loss:0.3168, val:1.8405, val_policy_loss:1.2780, val_value_loss:0.5625\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4\n",
      "iter 4000/4047/30000: loss 1.5892, policy_loss:1.2751, value_loss:0.3141, time 6.41s, iter_time: 267.14ms\n",
      "iter 4200/4260/30000: loss 1.5591, policy_loss:1.2644, value_loss:0.2946, time 0.52s, iter_time: 47.25ms\n",
      "iter 4400/4402/30000: loss 1.5596, policy_loss:1.2417, value_loss:0.3179, time 3.18s, iter_time: 46.07ms\n",
      "iter 4600/4615/30000: loss 1.6028, policy_loss:1.2877, value_loss:0.3151, time 2.77s, iter_time: 49.41ms\n",
      "iter 4800/4828/30000: loss 1.5895, policy_loss:1.2793, value_loss:0.3102, time 2.01s, iter_time: 46.78ms\n",
      "step 5000: losses: train:1.5685, train_policy_loss:1.2682, train_value_loss:0.3003, val:1.9199, val_policy_loss:1.2779, val_value_loss:0.6420\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4\n",
      "iter 5000/5041/30000: loss 1.5202, policy_loss:1.2313, value_loss:0.2889, time 5.57s, iter_time: 185.55ms\n",
      "iter 5200/5254/30000: loss 1.5586, policy_loss:1.2593, value_loss:0.2992, time 0.72s, iter_time: 42.41ms\n",
      "iter 5400/5467/30000: loss 1.5576, policy_loss:1.2721, value_loss:0.2855, time 0.19s, iter_time: 47.94ms\n",
      "iter 5600/5609/30000: loss 1.5577, policy_loss:1.2540, value_loss:0.3037, time 4.72s, iter_time: 76.20ms\n",
      "iter 5800/5822/30000: loss 1.5833, policy_loss:1.2702, value_loss:0.3130, time 2.19s, iter_time: 44.70ms\n",
      "step 6000: losses: train:1.5622, train_policy_loss:1.2672, train_value_loss:0.2950, val:1.9905, val_policy_loss:1.2778, val_value_loss:0.7127\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-4/best.pt (val_loss=1.7355)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-4.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 40000\n",
      "  Total actions: 447381\n",
      "  Avg trajectory length: 11.18\n",
      "Prefix Stats:\n",
      "actions=(): 40000 win=32105 loss=7892 draw=3 win1%=80.26 model-win1%=76.11\n",
      "actions=(1,): 611 win=250 loss=361 draw=0 win1%=40.92 model-win1%=36.71\n",
      "actions=(2,): 565 win=271 loss=294 draw=0 win1%=47.96 model-win1%=43.68\n",
      "actions=(3,): 754 win=409 loss=345 draw=0 win1%=54.24 model-win1%=48.87\n",
      "actions=(4,): 32026 win=28042 loss=3982 draw=2 win1%=87.56 model-win1%=86.22\n",
      "actions=(4, 1): 4568 win=3918 loss=649 draw=1 win1%=85.77 model-win1%=82.87\n",
      "actions=(4, 4): 9676 win=8551 loss=1125 draw=0 win1%=88.37 model-win1%=86.84\n",
      "actions=(4, 5): 12949 win=11376 loss=1573 draw=0 win1%=87.85 model-win1%=87.42\n",
      "actions=(5,): 1869 win=1086 loss=783 draw=0 win1%=58.11 model-win1%=54.38\n",
      "actions=(6,): 2964 win=1508 loss=1455 draw=1 win1%=50.88 model-win1%=48.29\n",
      "actions=(7,): 1211 win=539 loss=672 draw=0 win1%=44.51 model-win1%=38.65\n",
      "\n",
      "=== Generation 5 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  68%|██████▊   | 6830/10000 [01:36<00:44, 70.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.019 seconds, size=1000, eval-per-second=52186.13, total-batches=1000, mean-eval-per-second=60206.65, mean-time-per-batch=0.017, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  99%|█████████▉| 9935/10000 [02:37<00:04, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.003 seconds, size=67, eval-per-second=20272.57, total-batches=2000, mean-eval-per-second=36997.13, mean-time-per-batch=0.020, mean-batch-size=748.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9998/10000 [02:43<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=4, eval-per-second=1954.02, total-batches=3000, mean-eval-per-second=33404.02, mean-time-per-batch=0.015, mean-batch-size=506.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [02:44<00:00, 60.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 5...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:1.5704, train_policy_loss:1.1858, train_value_loss:0.3846, val:1.5758, val_policy_loss:1.1903, val_value_loss:0.3854\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-5/best.pt\n",
      "iter 0/88/30000: loss 1.5517, policy_loss:1.1690, value_loss:0.3827, time 46.63s, iter_time: 0.00ms\n",
      "iter 200/264/30000: loss 1.4586, policy_loss:1.0957, value_loss:0.3629, time 7.85s, iter_time: 327.01ms\n",
      "iter 400/440/30000: loss 1.5356, policy_loss:1.1519, value_loss:0.3837, time 6.03s, iter_time: 125.60ms\n",
      "iter 600/616/30000: loss 1.5469, policy_loss:1.1644, value_loss:0.3826, time 11.19s, iter_time: 155.46ms\n",
      "iter 800/880/30000: loss 1.5313, policy_loss:1.1506, value_loss:0.3808, time 0.39s, iter_time: 48.69ms\n",
      "step 1000: losses: train:1.5494, train_policy_loss:1.1736, train_value_loss:0.3758, val:1.5809, val_policy_loss:1.1825, val_value_loss:0.3984\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-5\n",
      "iter 1000/1056/30000: loss 1.5397, policy_loss:1.1630, value_loss:0.3767, time 10.41s, iter_time: 325.30ms\n",
      "iter 1200/1232/30000: loss 1.5900, policy_loss:1.1837, value_loss:0.4064, time 4.15s, iter_time: 74.05ms\n",
      "iter 1400/1408/30000: loss 1.5684, policy_loss:1.1876, value_loss:0.3808, time 6.76s, iter_time: 84.48ms\n",
      "iter 1600/1672/30000: loss 1.5278, policy_loss:1.1595, value_loss:0.3683, time 2.41s, iter_time: 150.37ms\n",
      "iter 1800/1848/30000: loss 1.5616, policy_loss:1.1970, value_loss:0.3646, time 3.85s, iter_time: 96.25ms\n",
      "step 2000: losses: train:1.5247, train_policy_loss:1.1644, train_value_loss:0.3603, val:1.5889, val_policy_loss:1.1738, val_value_loss:0.4151\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-5\n",
      "iter 2000/2024/30000: loss 1.5729, policy_loss:1.1880, value_loss:0.3849, time 6.35s, iter_time: 99.14ms\n",
      "iter 2200/2288/30000: loss 1.5305, policy_loss:1.1611, value_loss:0.3694, time 0.04s, iter_time: 0.00ms\n",
      "iter 2400/2464/30000: loss 1.5210, policy_loss:1.1908, value_loss:0.3302, time 2.13s, iter_time: 88.62ms\n",
      "iter 2600/2640/30000: loss 1.5022, policy_loss:1.1490, value_loss:0.3533, time 2.93s, iter_time: 60.97ms\n",
      "iter 2800/2816/30000: loss 1.5386, policy_loss:1.1954, value_loss:0.3432, time 4.29s, iter_time: 59.58ms\n",
      "step 3000: losses: train:1.4901, train_policy_loss:1.1567, train_value_loss:0.3334, val:1.5984, val_policy_loss:1.1702, val_value_loss:0.4282\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-5\n",
      "iter 3000/3080/30000: loss 1.5367, policy_loss:1.1885, value_loss:0.3482, time 7.33s, iter_time: 916.43ms\n",
      "iter 3200/3256/30000: loss 1.4827, policy_loss:1.1472, value_loss:0.3354, time 1.48s, iter_time: 46.39ms\n",
      "iter 3400/3432/30000: loss 1.4994, policy_loss:1.1542, value_loss:0.3452, time 2.40s, iter_time: 42.87ms\n",
      "iter 3600/3608/30000: loss 1.4974, policy_loss:1.1606, value_loss:0.3368, time 5.64s, iter_time: 70.53ms\n",
      "iter 3800/3872/30000: loss 1.4900, policy_loss:1.1660, value_loss:0.3241, time 1.63s, iter_time: 101.86ms\n",
      "step 4000: losses: train:1.4488, train_policy_loss:1.1489, train_value_loss:0.3000, val:1.6766, val_policy_loss:1.1661, val_value_loss:0.5105\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-5\n",
      "iter 4000/4048/30000: loss 1.4894, policy_loss:1.1685, value_loss:0.3209, time 6.86s, iter_time: 171.61ms\n",
      "iter 4200/4224/30000: loss 1.4979, policy_loss:1.1999, value_loss:0.2980, time 3.89s, iter_time: 60.80ms\n",
      "iter 4400/4488/30000: loss 1.4369, policy_loss:1.1607, value_loss:0.2762, time 0.07s, iter_time: 0.00ms\n",
      "iter 4600/4664/30000: loss 1.4687, policy_loss:1.1887, value_loss:0.2800, time 1.94s, iter_time: 80.79ms\n",
      "iter 4800/4840/30000: loss 1.4117, policy_loss:1.1316, value_loss:0.2801, time 2.25s, iter_time: 46.94ms\n",
      "step 5000: losses: train:1.4304, train_policy_loss:1.1455, train_value_loss:0.2848, val:1.7237, val_policy_loss:1.1650, val_value_loss:0.5586\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-5/best.pt (val_loss=1.5758)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-5.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 50000\n",
      "  Total actions: 530915\n",
      "  Avg trajectory length: 10.62\n",
      "Prefix Stats:\n",
      "actions=(): 50000 win=41647 loss=8350 draw=3 win1%=83.29 model-win1%=76.11\n",
      "actions=(1,): 633 win=253 loss=380 draw=0 win1%=39.97 model-win1%=36.71\n",
      "actions=(2,): 581 win=279 loss=302 draw=0 win1%=48.02 model-win1%=43.68\n",
      "actions=(3,): 771 win=417 loss=354 draw=0 win1%=54.09 model-win1%=48.87\n",
      "actions=(4,): 41899 win=37536 loss=4361 draw=2 win1%=89.59 model-win1%=86.22\n",
      "actions=(4, 1): 4805 win=4150 loss=654 draw=1 win1%=86.37 model-win1%=82.87\n",
      "actions=(4, 4): 10239 win=9051 loss=1188 draw=0 win1%=88.40 model-win1%=86.84\n",
      "actions=(4, 5): 21643 win=19765 loss=1878 draw=0 win1%=91.32 model-win1%=87.42\n",
      "actions=(5,): 1898 win=1096 loss=802 draw=0 win1%=57.74 model-win1%=54.38\n",
      "actions=(6,): 2998 win=1525 loss=1472 draw=1 win1%=50.87 model-win1%=48.29\n",
      "actions=(7,): 1220 win=541 loss=679 draw=0 win1%=44.34 model-win1%=38.65\n",
      "\n",
      "=== Generation 6 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  69%|██████▉   | 6908/10000 [01:36<00:40, 75.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.019 seconds, size=1000, eval-per-second=53242.75, total-batches=1000, mean-eval-per-second=59929.76, mean-time-per-batch=0.017, mean-batch-size=1000.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  99%|█████████▉| 9925/10000 [02:38<00:08,  8.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.005 seconds, size=77, eval-per-second=14162.49, total-batches=2000, mean-eval-per-second=35721.93, mean-time-per-batch=0.021, mean-batch-size=743.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9997/10000 [02:47<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=2, eval-per-second=895.26, total-batches=3000, mean-eval-per-second=30366.65, mean-time-per-batch=0.017, mean-batch-size=503.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [02:48<00:00, 59.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 6...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:1.4653, train_policy_loss:1.1018, train_value_loss:0.3635, val:1.4676, val_policy_loss:1.1061, val_value_loss:0.3615\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6/best.pt\n",
      "iter 0/106/30000: loss 1.4900, policy_loss:1.1195, value_loss:0.3705, time 34.11s, iter_time: 0.00ms\n",
      "iter 200/212/30000: loss 1.4497, policy_loss:1.0892, value_loss:0.3605, time 17.15s, iter_time: 182.41ms\n",
      "iter 400/424/30000: loss 1.4576, policy_loss:1.1014, value_loss:0.3562, time 14.28s, iter_time: 174.13ms\n",
      "iter 600/636/30000: loss 1.4353, policy_loss:1.0860, value_loss:0.3493, time 11.43s, iter_time: 163.32ms\n",
      "iter 800/848/30000: loss 1.4835, policy_loss:1.0991, value_loss:0.3843, time 5.65s, iter_time: 97.37ms\n",
      "step 1000: losses: train:1.4362, train_policy_loss:1.0774, train_value_loss:0.3587, val:1.4531, val_policy_loss:1.0855, val_value_loss:0.3675\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6\n",
      "iter 1000/1060/30000: loss 1.4735, policy_loss:1.1112, value_loss:0.3623, time 13.23s, iter_time: 287.68ms\n",
      "iter 1200/1272/30000: loss 1.4030, policy_loss:1.0645, value_loss:0.3385, time 2.51s, iter_time: 73.73ms\n",
      "iter 1400/1484/30000: loss 1.4949, policy_loss:1.1265, value_loss:0.3684, time 4.27s, iter_time: 194.22ms\n",
      "iter 1600/1696/30000: loss 1.3954, policy_loss:1.0560, value_loss:0.3394, time 0.48s, iter_time: 47.79ms\n",
      "iter 1800/1802/30000: loss 1.4555, policy_loss:1.0638, value_loss:0.3917, time 4.59s, iter_time: 44.16ms\n",
      "step 2000: losses: train:1.4082, train_policy_loss:1.0678, train_value_loss:0.3404, val:1.4482, val_policy_loss:1.0792, val_value_loss:0.3690\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6\n",
      "iter 2000/2014/30000: loss 1.4219, policy_loss:1.0625, value_loss:0.3593, time 12.35s, iter_time: 134.22ms\n",
      "iter 2200/2226/30000: loss 1.4774, policy_loss:1.1316, value_loss:0.3458, time 3.69s, iter_time: 46.13ms\n",
      "iter 2400/2438/30000: loss 1.3480, policy_loss:1.0560, value_loss:0.2920, time 3.85s, iter_time: 56.60ms\n",
      "iter 2600/2650/30000: loss 1.4447, policy_loss:1.0818, value_loss:0.3628, time 5.45s, iter_time: 97.35ms\n",
      "iter 2800/2862/30000: loss 1.4178, policy_loss:1.0442, value_loss:0.3736, time 2.14s, iter_time: 48.63ms\n",
      "step 3000: losses: train:1.3809, train_policy_loss:1.0620, train_value_loss:0.3190, val:1.4591, val_policy_loss:1.0724, val_value_loss:0.3867\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6\n",
      "iter 3000/3074/30000: loss 1.3990, policy_loss:1.0833, value_loss:0.3157, time 7.39s, iter_time: 230.83ms\n",
      "iter 3200/3286/30000: loss 1.3320, policy_loss:1.0178, value_loss:0.3142, time 0.80s, iter_time: 40.07ms\n",
      "iter 3400/3498/30000: loss 1.4270, policy_loss:1.1044, value_loss:0.3226, time 1.20s, iter_time: 150.02ms\n",
      "iter 3600/3604/30000: loss 1.4222, policy_loss:1.1281, value_loss:0.2941, time 5.14s, iter_time: 50.35ms\n",
      "iter 3800/3816/30000: loss 1.4213, policy_loss:1.0992, value_loss:0.3220, time 5.22s, iter_time: 58.02ms\n",
      "step 4000: losses: train:1.3462, train_policy_loss:1.0543, train_value_loss:0.2919, val:1.5036, val_policy_loss:1.0702, val_value_loss:0.4334\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6\n",
      "iter 4000/4028/30000: loss 1.2980, policy_loss:1.0155, value_loss:0.2825, time 9.54s, iter_time: 122.34ms\n",
      "iter 4200/4240/30000: loss 1.3056, policy_loss:1.0258, value_loss:0.2798, time 3.72s, iter_time: 56.32ms\n",
      "iter 4400/4452/30000: loss 1.3459, policy_loss:1.0253, value_loss:0.3206, time 3.66s, iter_time: 67.72ms\n",
      "iter 4600/4664/30000: loss 1.3502, policy_loss:1.0549, value_loss:0.2954, time 2.31s, iter_time: 54.99ms\n",
      "iter 4800/4876/30000: loss 1.3849, policy_loss:1.0933, value_loss:0.2917, time 2.18s, iter_time: 72.64ms\n",
      "step 5000: losses: train:1.3296, train_policy_loss:1.0517, train_value_loss:0.2779, val:1.5608, val_policy_loss:1.0688, val_value_loss:0.4920\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6\n",
      "iter 5000/5088/30000: loss 1.3267, policy_loss:1.0391, value_loss:0.2876, time 5.60s, iter_time: 311.36ms\n",
      "iter 5200/5300/30000: loss 1.3008, policy_loss:1.0258, value_loss:0.2750, time 0.31s, iter_time: 52.23ms\n",
      "iter 5400/5406/30000: loss 1.3397, policy_loss:1.0400, value_loss:0.2997, time 5.75s, iter_time: 57.49ms\n",
      "iter 5600/5618/30000: loss 1.3015, policy_loss:1.0354, value_loss:0.2661, time 6.02s, iter_time: 68.39ms\n",
      "iter 5800/5830/30000: loss 1.2957, policy_loss:1.0322, value_loss:0.2635, time 3.48s, iter_time: 45.82ms\n",
      "step 6000: losses: train:1.3265, train_policy_loss:1.0531, train_value_loss:0.2734, val:1.5890, val_policy_loss:1.0698, val_value_loss:0.5192\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6\n",
      "iter 6000/6042/30000: loss 1.3216, policy_loss:1.0455, value_loss:0.2761, time 7.90s, iter_time: 123.48ms\n",
      "iter 6200/6254/30000: loss 1.2842, policy_loss:1.0181, value_loss:0.2661, time 2.87s, iter_time: 55.20ms\n",
      "iter 6400/6466/30000: loss 1.3325, policy_loss:1.0591, value_loss:0.2734, time 1.62s, iter_time: 40.60ms\n",
      "iter 6600/6678/30000: loss 1.3633, policy_loss:1.0635, value_loss:0.2998, time 1.30s, iter_time: 46.28ms\n",
      "iter 6800/6890/30000: loss 1.3510, policy_loss:1.0781, value_loss:0.2728, time 0.65s, iter_time: 40.41ms\n",
      "step 7000: losses: train:1.3185, train_policy_loss:1.0495, train_value_loss:0.2690, val:1.6114, val_policy_loss:1.0691, val_value_loss:0.5423\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-6/best.pt (val_loss=1.4482)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-6.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 60000\n",
      "  Total actions: 614398\n",
      "  Avg trajectory length: 10.24\n",
      "Prefix Stats:\n",
      "actions=(): 60000 win=51174 loss=8823 draw=3 win1%=85.29 model-win1%=86.65\n",
      "actions=(1,): 651 win=256 loss=395 draw=0 win1%=39.32 model-win1%=42.57\n",
      "actions=(2,): 591 win=282 loss=309 draw=0 win1%=47.72 model-win1%=48.64\n",
      "actions=(3,): 791 win=426 loss=365 draw=0 win1%=53.86 model-win1%=58.28\n",
      "actions=(4,): 51784 win=47023 loss=4759 draw=2 win1%=90.81 model-win1%=91.00\n",
      "actions=(4, 1): 5050 win=4391 loss=658 draw=1 win1%=86.95 model-win1%=87.31\n",
      "actions=(4, 4): 10796 win=9538 loss=1258 draw=0 win1%=88.35 model-win1%=86.52\n",
      "actions=(4, 5): 30348 win=28156 loss=2192 draw=0 win1%=92.78 model-win1%=93.28\n",
      "actions=(5,): 1922 win=1104 loss=818 draw=0 win1%=57.44 model-win1%=59.09\n",
      "actions=(6,): 3030 win=1542 loss=1487 draw=1 win1%=50.89 model-win1%=53.25\n",
      "actions=(7,): 1231 win=541 loss=690 draw=0 win1%=43.95 model-win1%=47.60\n",
      "\n",
      "=== Generation 7 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  98%|█████████▊| 9829/10000 [01:43<00:09, 17.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.091 seconds, size=170, eval-per-second=1870.83, total-batches=1000, mean-eval-per-second=39793.91, mean-time-per-batch=0.022, mean-batch-size=859.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9993/10000 [01:55<00:00,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=7, eval-per-second=3573.53, total-batches=2000, mean-eval-per-second=29620.12, mean-time-per-batch=0.016, mean-batch-size=460.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:57<00:00, 85.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 7...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:1.3078, train_policy_loss:0.9894, train_value_loss:0.3184, val:1.3352, val_policy_loss:1.0067, val_value_loss:0.3286\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-7/best.pt\n",
      "iter 0/124/30000: loss 1.3879, policy_loss:1.0467, value_loss:0.3413, time 30.49s, iter_time: 0.00ms\n",
      "iter 200/248/30000: loss 1.2663, policy_loss:0.9559, value_loss:0.3103, time 15.85s, iter_time: 208.55ms\n",
      "iter 400/496/30000: loss 1.2851, policy_loss:0.9772, value_loss:0.3080, time 3.75s, iter_time: 134.09ms\n",
      "iter 600/620/30000: loss 1.2954, policy_loss:0.9788, value_loss:0.3166, time 8.11s, iter_time: 78.03ms\n",
      "iter 800/868/30000: loss 1.3323, policy_loss:1.0153, value_loss:0.3170, time 2.36s, iter_time: 42.17ms\n",
      "step 1000: losses: train:1.2993, train_policy_loss:0.9869, train_value_loss:0.3124, val:1.3577, val_policy_loss:1.0102, val_value_loss:0.3475\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-7\n",
      "iter 1000/1116/30000: loss 1.2367, policy_loss:0.9498, value_loss:0.2869, time 8.81s, iter_time: 1100.73ms\n",
      "iter 1200/1240/30000: loss 1.3397, policy_loss:0.9800, value_loss:0.3597, time 5.40s, iter_time: 64.34ms\n",
      "iter 1400/1488/30000: loss 1.3418, policy_loss:1.0149, value_loss:0.3269, time 3.15s, iter_time: 87.41ms\n",
      "iter 1600/1612/30000: loss 1.2684, policy_loss:0.9688, value_loss:0.2996, time 9.55s, iter_time: 85.24ms\n",
      "iter 1800/1860/30000: loss 1.3610, policy_loss:1.0239, value_loss:0.3372, time 3.86s, iter_time: 60.35ms\n",
      "step 2000: losses: train:1.2965, train_policy_loss:0.9892, train_value_loss:0.3073, val:1.3682, val_policy_loss:1.0112, val_value_loss:0.3571\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-7\n",
      "iter 2000/2108/30000: loss 1.2706, policy_loss:0.9716, value_loss:0.2990, time 6.02s, iter_time: 375.96ms\n",
      "iter 2200/2232/30000: loss 1.3580, policy_loss:1.0375, value_loss:0.3206, time 4.10s, iter_time: 44.52ms\n",
      "iter 2400/2480/30000: loss 1.3053, policy_loss:0.9893, value_loss:0.3160, time 3.21s, iter_time: 72.95ms\n",
      "iter 2600/2604/30000: loss 1.2828, policy_loss:0.9941, value_loss:0.2887, time 4.98s, iter_time: 41.50ms\n",
      "iter 2800/2852/30000: loss 1.2460, policy_loss:0.9617, value_loss:0.2842, time 3.50s, iter_time: 48.61ms\n",
      "step 3000: losses: train:1.2674, train_policy_loss:0.9796, train_value_loss:0.2877, val:1.3796, val_policy_loss:1.0067, val_value_loss:0.3729\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-7\n",
      "iter 3000/3100/30000: loss 1.3213, policy_loss:1.0211, value_loss:0.3002, time 7.23s, iter_time: 301.28ms\n",
      "iter 3200/3224/30000: loss 1.2597, policy_loss:0.9953, value_loss:0.2644, time 5.73s, iter_time: 57.28ms\n",
      "iter 3400/3472/30000: loss 1.2389, policy_loss:0.9651, value_loss:0.2739, time 3.57s, iter_time: 68.56ms\n",
      "iter 3600/3720/30000: loss 1.3384, policy_loss:1.0085, value_loss:0.3299, time 0.44s, iter_time: 111.12ms\n",
      "iter 3800/3844/30000: loss 1.2818, policy_loss:1.0144, value_loss:0.2674, time 4.94s, iter_time: 61.75ms\n",
      "step 4000: losses: train:1.2344, train_policy_loss:0.9719, train_value_loss:0.2625, val:1.4044, val_policy_loss:1.0015, val_value_loss:0.4030\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-7\n",
      "iter 4000/4092/30000: loss 1.2685, policy_loss:0.9976, value_loss:0.2709, time 7.50s, iter_time: 234.48ms\n",
      "iter 4200/4216/30000: loss 1.1731, policy_loss:0.9270, value_loss:0.2460, time 5.56s, iter_time: 51.45ms\n",
      "iter 4400/4464/30000: loss 1.1948, policy_loss:0.9557, value_loss:0.2391, time 2.88s, iter_time: 47.93ms\n",
      "iter 4600/4712/30000: loss 1.2499, policy_loss:1.0020, value_loss:0.2479, time 0.50s, iter_time: 41.77ms\n",
      "iter 4800/4836/30000: loss 1.1743, policy_loss:0.9485, value_loss:0.2258, time 3.59s, iter_time: 40.76ms\n",
      "step 5000: losses: train:1.2221, train_policy_loss:0.9696, train_value_loss:0.2525, val:1.4476, val_policy_loss:1.0019, val_value_loss:0.4457\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-7/best.pt (val_loss=1.3352)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-7.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 70000\n",
      "  Total actions: 691340\n",
      "  Avg trajectory length: 9.88\n",
      "Prefix Stats:\n",
      "actions=(): 70000 win=60960 loss=9037 draw=3 win1%=87.09 model-win1%=86.65\n",
      "actions=(1,): 664 win=256 loss=408 draw=0 win1%=38.55 model-win1%=42.57\n",
      "actions=(2,): 601 win=283 loss=318 draw=0 win1%=47.09 model-win1%=48.64\n",
      "actions=(3,): 805 win=434 loss=371 draw=0 win1%=53.91 model-win1%=58.28\n",
      "actions=(4,): 61693 win=56772 loss=4919 draw=2 win1%=92.02 model-win1%=91.00\n",
      "actions=(4, 1): 5234 win=4574 loss=659 draw=1 win1%=87.39 model-win1%=87.31\n",
      "actions=(4, 4): 11237 win=9922 loss=1315 draw=0 win1%=88.30 model-win1%=86.52\n",
      "actions=(4, 5): 39251 win=36961 loss=2290 draw=0 win1%=94.17 model-win1%=93.28\n",
      "actions=(5,): 1947 win=1127 loss=820 draw=0 win1%=57.88 model-win1%=59.09\n",
      "actions=(6,): 3050 win=1546 loss=1503 draw=1 win1%=50.69 model-win1%=53.25\n",
      "actions=(7,): 1240 win=542 loss=698 draw=0 win1%=43.71 model-win1%=47.60\n",
      "\n",
      "=== Generation 8 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  98%|█████████▊| 9830/10000 [01:44<00:09, 17.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.051 seconds, size=172, eval-per-second=3341.44, total-batches=1000, mean-eval-per-second=39076.43, mean-time-per-batch=0.022, mean-batch-size=865.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9989/10000 [01:54<00:01, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=11, eval-per-second=4680.67, total-batches=2000, mean-eval-per-second=30972.35, mean-time-per-batch=0.015, mean-batch-size=462.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:56<00:00, 85.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 8...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:1.2331, train_policy_loss:0.9299, train_value_loss:0.3031, val:1.1994, val_policy_loss:0.9128, val_value_loss:0.2866\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-8/best.pt\n",
      "iter 0/141/30000: loss 1.2620, policy_loss:0.9502, value_loss:0.3119, time 13.84s, iter_time: 0.00ms\n",
      "iter 200/282/30000: loss 1.2535, policy_loss:0.9433, value_loss:0.3101, time 4.35s, iter_time: 73.78ms\n",
      "iter 400/423/30000: loss 1.2093, policy_loss:0.9381, value_loss:0.2713, time 11.83s, iter_time: 100.24ms\n",
      "iter 600/705/30000: loss 1.2806, policy_loss:0.9599, value_loss:0.3208, time 4.33s, iter_time: 120.25ms\n",
      "iter 800/846/30000: loss 1.1975, policy_loss:0.9272, value_loss:0.2703, time 15.78s, iter_time: 166.13ms\n",
      "step 1000: losses: train:1.2221, train_policy_loss:0.9280, train_value_loss:0.2941, val:1.2150, val_policy_loss:0.9139, val_value_loss:0.3010\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-8\n",
      "iter 1000/1128/30000: loss 1.2094, policy_loss:0.9237, value_loss:0.2857, time 8.96s, iter_time: 689.10ms\n",
      "iter 1200/1269/30000: loss 1.2767, policy_loss:0.9502, value_loss:0.3264, time 3.06s, iter_time: 42.45ms\n",
      "iter 1400/1410/30000: loss 1.2634, policy_loss:0.9765, value_loss:0.2869, time 8.63s, iter_time: 65.85ms\n",
      "iter 1600/1692/30000: loss 1.1867, policy_loss:0.9057, value_loss:0.2810, time 3.05s, iter_time: 62.26ms\n",
      "iter 1800/1833/30000: loss 1.2437, policy_loss:0.9463, value_loss:0.2974, time 5.73s, iter_time: 53.03ms\n",
      "step 2000: losses: train:1.2193, train_policy_loss:0.9253, train_value_loss:0.2940, val:1.2270, val_policy_loss:0.9132, val_value_loss:0.3138\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-8\n",
      "iter 2000/2115/30000: loss 1.2239, policy_loss:0.9384, value_loss:0.2855, time 8.69s, iter_time: 334.18ms\n",
      "iter 2200/2256/30000: loss 1.2848, policy_loss:0.9460, value_loss:0.3389, time 3.48s, iter_time: 40.98ms\n",
      "iter 2400/2538/30000: loss 1.1838, policy_loss:0.9271, value_loss:0.2567, time 0.32s, iter_time: 107.99ms\n",
      "iter 2600/2679/30000: loss 1.1973, policy_loss:0.9157, value_loss:0.2815, time 3.61s, iter_time: 58.28ms\n",
      "iter 2800/2820/30000: loss 1.2152, policy_loss:0.9176, value_loss:0.2976, time 7.58s, iter_time: 62.62ms\n",
      "step 3000: losses: train:1.1895, train_policy_loss:0.9183, train_value_loss:0.2712, val:1.2222, val_policy_loss:0.9076, val_value_loss:0.3146\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-8\n",
      "iter 3000/3102/30000: loss 1.2327, policy_loss:0.9491, value_loss:0.2836, time 7.13s, iter_time: 182.80ms\n",
      "iter 3200/3243/30000: loss 1.1670, policy_loss:0.9037, value_loss:0.2633, time 4.38s, iter_time: 44.74ms\n",
      "iter 3400/3525/30000: loss 1.2595, policy_loss:0.9637, value_loss:0.2958, time 0.72s, iter_time: 45.11ms\n",
      "iter 3600/3666/30000: loss 1.2251, policy_loss:0.9221, value_loss:0.3030, time 4.10s, iter_time: 54.68ms\n",
      "iter 3800/3807/30000: loss 1.1245, policy_loss:0.8585, value_loss:0.2660, time 9.00s, iter_time: 67.16ms\n",
      "step 4000: losses: train:1.1639, train_policy_loss:0.9116, train_value_loss:0.2523, val:1.2369, val_policy_loss:0.9039, val_value_loss:0.3330\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-8\n",
      "iter 4000/4089/30000: loss 1.1734, policy_loss:0.9225, value_loss:0.2509, time 12.01s, iter_time: 230.96ms\n",
      "iter 4200/4230/30000: loss 1.1237, policy_loss:0.8539, value_loss:0.2699, time 5.23s, iter_time: 47.12ms\n",
      "iter 4400/4512/30000: loss 1.1206, policy_loss:0.8781, value_loss:0.2425, time 1.42s, iter_time: 49.02ms\n",
      "iter 4600/4653/30000: loss 1.1871, policy_loss:0.9356, value_loss:0.2515, time 4.02s, iter_time: 45.70ms\n",
      "iter 4800/4935/30000: loss 1.0448, policy_loss:0.8344, value_loss:0.2104, time 0.27s, iter_time: 44.49ms\n",
      "step 5000: losses: train:1.1515, train_policy_loss:0.9098, train_value_loss:0.2417, val:1.2731, val_policy_loss:0.9060, val_value_loss:0.3671\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-8/best.pt (val_loss=1.1994)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-8.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 80000\n",
      "  Total actions: 768517\n",
      "  Avg trajectory length: 9.61\n",
      "Prefix Stats:\n",
      "actions=(): 80000 win=70755 loss=9242 draw=3 win1%=88.44 model-win1%=86.65\n",
      "actions=(1,): 677 win=259 loss=418 draw=0 win1%=38.26 model-win1%=42.57\n",
      "actions=(2,): 616 win=287 loss=329 draw=0 win1%=46.59 model-win1%=48.64\n",
      "actions=(3,): 820 win=439 loss=381 draw=0 win1%=53.54 model-win1%=58.28\n",
      "actions=(4,): 71590 win=66532 loss=5056 draw=2 win1%=92.93 model-win1%=91.00\n",
      "actions=(4, 1): 5419 win=4758 loss=660 draw=1 win1%=87.80 model-win1%=87.31\n",
      "actions=(4, 4): 11715 win=10351 loss=1364 draw=0 win1%=88.36 model-win1%=86.52\n",
      "actions=(4, 5): 48090 win=45720 loss=2370 draw=0 win1%=95.07 model-win1%=93.28\n",
      "actions=(5,): 1964 win=1143 loss=821 draw=0 win1%=58.20 model-win1%=59.09\n",
      "actions=(6,): 3077 win=1551 loss=1525 draw=1 win1%=50.41 model-win1%=53.25\n",
      "actions=(7,): 1256 win=544 loss=712 draw=0 win1%=43.31 model-win1%=47.60\n",
      "\n",
      "=== Generation 9 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  98%|█████████▊| 9821/10000 [01:44<00:12, 14.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.007 seconds, size=183, eval-per-second=26413.77, total-batches=1000, mean-eval-per-second=40129.21, mean-time-per-batch=0.022, mean-batch-size=869.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9981/10000 [01:54<00:01, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=18, eval-per-second=8963.25, total-batches=2000, mean-eval-per-second=31895.91, mean-time-per-batch=0.015, mean-batch-size=467.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:56<00:00, 85.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:1.1575, train_policy_loss:0.8734, train_value_loss:0.2841, val:1.1542, val_policy_loss:0.8779, val_value_loss:0.2763\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-9/best.pt\n",
      "iter 0/159/30000: loss 1.1571, policy_loss:0.8757, value_loss:0.2814, time 20.24s, iter_time: 0.00ms\n",
      "iter 200/318/30000: loss 1.1733, policy_loss:0.8884, value_loss:0.2849, time 3.83s, iter_time: 93.32ms\n",
      "iter 400/477/30000: loss 1.1601, policy_loss:0.8816, value_loss:0.2785, time 9.24s, iter_time: 112.68ms\n",
      "iter 600/636/30000: loss 1.1891, policy_loss:0.8976, value_loss:0.2915, time 10.32s, iter_time: 83.88ms\n",
      "iter 800/954/30000: loss 1.1114, policy_loss:0.8589, value_loss:0.2525, time 0.22s, iter_time: 44.29ms\n",
      "step 1000: losses: train:1.1564, train_policy_loss:0.8747, train_value_loss:0.2818, val:1.1680, val_policy_loss:0.8785, val_value_loss:0.2895\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-9\n",
      "iter 1000/1113/30000: loss 1.1686, policy_loss:0.8823, value_loss:0.2863, time 12.33s, iter_time: 268.12ms\n",
      "iter 1200/1272/30000: loss 1.1383, policy_loss:0.8646, value_loss:0.2737, time 3.85s, iter_time: 44.25ms\n",
      "iter 1400/1431/30000: loss 1.2005, policy_loss:0.8953, value_loss:0.3052, time 8.37s, iter_time: 65.37ms\n",
      "iter 1600/1749/30000: loss 1.1979, policy_loss:0.8827, value_loss:0.3153, time 0.47s, iter_time: 47.39ms\n",
      "iter 1800/1908/30000: loss 1.1582, policy_loss:0.8367, value_loss:0.3215, time 2.26s, iter_time: 44.30ms\n",
      "step 2000: losses: train:1.1503, train_policy_loss:0.8694, train_value_loss:0.2809, val:1.1650, val_policy_loss:0.8740, val_value_loss:0.2910\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-9\n",
      "iter 2000/2067/30000: loss 1.1605, policy_loss:0.8742, value_loss:0.2862, time 11.02s, iter_time: 119.74ms\n",
      "iter 2200/2226/30000: loss 1.0517, policy_loss:0.7809, value_loss:0.2707, time 9.01s, iter_time: 67.73ms\n",
      "iter 2400/2544/30000: loss 1.0898, policy_loss:0.8383, value_loss:0.2515, time 1.00s, iter_time: 66.38ms\n",
      "iter 2600/2703/30000: loss 1.1617, policy_loss:0.8327, value_loss:0.3290, time 2.41s, iter_time: 43.09ms\n",
      "iter 2800/2862/30000: loss 1.0779, policy_loss:0.8402, value_loss:0.2377, time 6.85s, iter_time: 70.59ms\n",
      "step 3000: losses: train:1.1232, train_policy_loss:0.8634, train_value_loss:0.2598, val:1.1620, val_policy_loss:0.8697, val_value_loss:0.2923\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-9\n",
      "iter 3000/3021/30000: loss 1.1957, policy_loss:0.9076, value_loss:0.2882, time 12.08s, iter_time: 87.54ms\n",
      "iter 3200/3339/30000: loss 1.1293, policy_loss:0.8430, value_loss:0.2863, time 0.94s, iter_time: 47.02ms\n",
      "iter 3400/3498/30000: loss 1.0584, policy_loss:0.8227, value_loss:0.2357, time 2.82s, iter_time: 46.20ms\n",
      "iter 3600/3657/30000: loss 1.0538, policy_loss:0.8265, value_loss:0.2273, time 5.00s, iter_time: 49.01ms\n",
      "iter 3800/3816/30000: loss 1.1419, policy_loss:0.9029, value_loss:0.2390, time 5.83s, iter_time: 40.76ms\n",
      "step 4000: losses: train:1.1091, train_policy_loss:0.8643, train_value_loss:0.2448, val:1.1740, val_policy_loss:0.8656, val_value_loss:0.3084\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-9\n",
      "iter 4000/4134/30000: loss 1.1240, policy_loss:0.8789, value_loss:0.2451, time 5.46s, iter_time: 218.30ms\n",
      "iter 4200/4293/30000: loss 1.1347, policy_loss:0.8665, value_loss:0.2682, time 3.18s, iter_time: 48.26ms\n",
      "iter 4400/4452/30000: loss 1.0750, policy_loss:0.8585, value_loss:0.2164, time 7.90s, iter_time: 73.85ms\n",
      "iter 4600/4611/30000: loss 1.1487, policy_loss:0.8802, value_loss:0.2685, time 8.41s, iter_time: 56.82ms\n",
      "iter 4800/4929/30000: loss 1.0949, policy_loss:0.8532, value_loss:0.2417, time 1.39s, iter_time: 46.42ms\n",
      "step 5000: losses: train:1.0915, train_policy_loss:0.8583, train_value_loss:0.2332, val:1.2010, val_policy_loss:0.8650, val_value_loss:0.3360\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-9/best.pt (val_loss=1.1542)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-9.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 90000\n",
      "  Total actions: 845633\n",
      "  Avg trajectory length: 9.40\n",
      "Prefix Stats:\n",
      "actions=(): 90000 win=80545 loss=9452 draw=3 win1%=89.49 model-win1%=86.65\n",
      "actions=(1,): 683 win=259 loss=424 draw=0 win1%=37.92 model-win1%=42.57\n",
      "actions=(2,): 630 win=292 loss=338 draw=0 win1%=46.35 model-win1%=48.64\n",
      "actions=(3,): 838 win=451 loss=387 draw=0 win1%=53.82 model-win1%=58.28\n",
      "actions=(4,): 81471 win=76275 loss=5194 draw=2 win1%=93.62 model-win1%=91.00\n",
      "actions=(4, 1): 5618 win=4952 loss=665 draw=1 win1%=88.15 model-win1%=87.31\n",
      "actions=(4, 4): 12127 win=10724 loss=1403 draw=0 win1%=88.43 model-win1%=86.52\n",
      "actions=(4, 5): 57009 win=54548 loss=2461 draw=0 win1%=95.68 model-win1%=93.28\n",
      "actions=(5,): 1995 win=1167 loss=828 draw=0 win1%=58.50 model-win1%=59.09\n",
      "actions=(6,): 3109 win=1554 loss=1554 draw=1 win1%=49.98 model-win1%=53.25\n",
      "actions=(7,): 1274 win=547 loss=727 draw=0 win1%=42.94 model-win1%=47.60\n",
      "\n",
      "=== Generation 10 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  98%|█████████▊| 9823/10000 [01:44<00:08, 20.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.017 seconds, size=182, eval-per-second=10667.61, total-batches=1000, mean-eval-per-second=41301.79, mean-time-per-batch=0.021, mean-batch-size=873.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9988/10000 [01:53<00:00, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=12, eval-per-second=6051.66, total-batches=2000, mean-eval-per-second=33358.43, mean-time-per-batch=0.014, mean-batch-size=468.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:55<00:00, 86.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:1.1058, train_policy_loss:0.8362, train_value_loss:0.2696, val:1.1031, val_policy_loss:0.8375, val_value_loss:0.2657\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-10/best.pt\n",
      "iter 0/176/30000: loss 1.0749, policy_loss:0.8171, value_loss:0.2578, time 16.18s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 1.0123, policy_loss:0.8076, value_loss:0.2048, time 2.15s, iter_time: 89.78ms\n",
      "iter 400/528/30000: loss 1.1320, policy_loss:0.8387, value_loss:0.2933, time 3.00s, iter_time: 62.50ms\n",
      "iter 600/704/30000: loss 1.1109, policy_loss:0.8415, value_loss:0.2695, time 5.43s, iter_time: 75.38ms\n",
      "iter 800/880/30000: loss 1.0945, policy_loss:0.8332, value_loss:0.2612, time 6.11s, iter_time: 63.65ms\n",
      "step 1000: losses: train:1.1006, train_policy_loss:0.8324, train_value_loss:0.2682, val:1.1059, val_policy_loss:0.8320, val_value_loss:0.2739\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-10\n",
      "iter 1000/1056/30000: loss 1.1768, policy_loss:0.8788, value_loss:0.2981, time 14.41s, iter_time: 120.08ms\n",
      "iter 1200/1232/30000: loss 1.0373, policy_loss:0.7816, value_loss:0.2557, time 10.24s, iter_time: 71.11ms\n",
      "iter 1400/1408/30000: loss 1.0647, policy_loss:0.8008, value_loss:0.2640, time 10.67s, iter_time: 63.51ms\n",
      "iter 1600/1760/30000: loss 1.0468, policy_loss:0.7831, value_loss:0.2638, time 0.85s, iter_time: 53.31ms\n",
      "iter 1800/1936/30000: loss 1.0697, policy_loss:0.8257, value_loss:0.2440, time 1.65s, iter_time: 41.37ms\n",
      "step 2000: losses: train:1.0917, train_policy_loss:0.8228, train_value_loss:0.2689, val:1.1116, val_policy_loss:0.8286, val_value_loss:0.2829\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-10\n",
      "iter 2000/2112/30000: loss 1.0884, policy_loss:0.8480, value_loss:0.2404, time 8.33s, iter_time: 130.12ms\n",
      "iter 2200/2288/30000: loss 1.0644, policy_loss:0.7984, value_loss:0.2660, time 5.19s, iter_time: 59.01ms\n",
      "iter 2400/2464/30000: loss 1.0797, policy_loss:0.8377, value_loss:0.2419, time 5.78s, iter_time: 51.63ms\n",
      "iter 2600/2640/30000: loss 1.1612, policy_loss:0.8900, value_loss:0.2713, time 7.48s, iter_time: 54.98ms\n",
      "iter 2800/2816/30000: loss 1.0669, policy_loss:0.8191, value_loss:0.2479, time 7.09s, iter_time: 44.30ms\n",
      "step 3000: losses: train:1.0713, train_policy_loss:0.8221, train_value_loss:0.2492, val:1.1100, val_policy_loss:0.8261, val_value_loss:0.2839\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-10\n",
      "iter 3000/3168/30000: loss 1.0340, policy_loss:0.7890, value_loss:0.2451, time 7.75s, iter_time: 968.35ms\n",
      "iter 3200/3344/30000: loss 1.0553, policy_loss:0.8227, value_loss:0.2326, time 1.33s, iter_time: 41.65ms\n",
      "iter 3400/3520/30000: loss 1.0831, policy_loss:0.8256, value_loss:0.2575, time 2.39s, iter_time: 42.60ms\n",
      "iter 3600/3696/30000: loss 1.0198, policy_loss:0.7769, value_loss:0.2429, time 3.49s, iter_time: 43.62ms\n",
      "iter 3800/3872/30000: loss 1.1446, policy_loss:0.8848, value_loss:0.2598, time 5.39s, iter_time: 51.83ms\n",
      "step 4000: losses: train:1.0467, train_policy_loss:0.8153, train_value_loss:0.2314, val:1.1217, val_policy_loss:0.8225, val_value_loss:0.2991\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-10\n",
      "iter 4000/4048/30000: loss 1.0382, policy_loss:0.8098, value_loss:0.2284, time 13.52s, iter_time: 105.66ms\n",
      "iter 4200/4224/30000: loss 1.1299, policy_loss:0.8691, value_loss:0.2608, time 6.81s, iter_time: 44.79ms\n",
      "iter 4400/4576/30000: loss 1.0777, policy_loss:0.8355, value_loss:0.2423, time 0.10s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.9679, policy_loss:0.7668, value_loss:0.2011, time 1.08s, iter_time: 44.91ms\n",
      "iter 4800/4928/30000: loss 1.0426, policy_loss:0.8185, value_loss:0.2241, time 2.15s, iter_time: 44.89ms\n",
      "step 5000: losses: train:1.0343, train_policy_loss:0.8118, train_value_loss:0.2225, val:1.1510, val_policy_loss:0.8236, val_value_loss:0.3274\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-10/best.pt (val_loss=1.1031)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-10.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 922975\n",
      "  Avg trajectory length: 9.23\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=90341 loss=9656 draw=3 win1%=90.34 model-win1%=86.65\n",
      "actions=(1,): 690 win=259 loss=431 draw=0 win1%=37.54 model-win1%=42.57\n",
      "actions=(2,): 644 win=297 loss=347 draw=0 win1%=46.12 model-win1%=48.64\n",
      "actions=(3,): 857 win=461 loss=396 draw=0 win1%=53.79 model-win1%=58.28\n",
      "actions=(4,): 91358 win=86025 loss=5331 draw=2 win1%=94.16 model-win1%=91.00\n",
      "actions=(4, 1): 5803 win=5135 loss=667 draw=1 win1%=88.49 model-win1%=87.31\n",
      "actions=(4, 4): 12601 win=11153 loss=1448 draw=0 win1%=88.51 model-win1%=86.52\n",
      "actions=(4, 5): 65869 win=63319 loss=2550 draw=0 win1%=96.13 model-win1%=93.28\n",
      "actions=(5,): 2020 win=1190 loss=830 draw=0 win1%=58.91 model-win1%=59.09\n",
      "actions=(6,): 3140 win=1559 loss=1580 draw=1 win1%=49.65 model-win1%=53.25\n",
      "actions=(7,): 1291 win=550 loss=741 draw=0 win1%=42.60 model-win1%=47.60\n",
      "\n",
      "=== Generation 11 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  98%|█████████▊| 9840/10000 [01:44<00:05, 26.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.010 seconds, size=162, eval-per-second=16666.52, total-batches=1000, mean-eval-per-second=41275.76, mean-time-per-batch=0.021, mean-batch-size=865.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9994/10000 [01:52<00:00, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=6, eval-per-second=3848.57, total-batches=2000, mean-eval-per-second=33291.82, mean-time-per-batch=0.014, mean-batch-size=458.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:55<00:00, 86.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.8201, train_policy_loss:0.6137, train_value_loss:0.2064, val:0.8353, val_policy_loss:0.6213, val_value_loss:0.2140\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11/best.pt\n",
      "iter 0/176/30000: loss 0.8229, policy_loss:0.6036, value_loss:0.2193, time 67.63s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.7998, policy_loss:0.5953, value_loss:0.2045, time 7.35s, iter_time: 306.20ms\n",
      "iter 400/528/30000: loss 0.7289, policy_loss:0.5630, value_loss:0.1659, time 4.99s, iter_time: 103.95ms\n",
      "iter 600/704/30000: loss 0.7958, policy_loss:0.6036, value_loss:0.1922, time 14.00s, iter_time: 194.38ms\n",
      "iter 800/880/30000: loss 0.7229, policy_loss:0.5587, value_loss:0.1641, time 11.61s, iter_time: 120.99ms\n",
      "step 1000: losses: train:0.7814, train_policy_loss:0.5864, train_value_loss:0.1950, val:0.7988, val_policy_loss:0.5920, val_value_loss:0.2068\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11\n",
      "iter 1000/1056/30000: loss 0.8482, policy_loss:0.6071, value_loss:0.2412, time 22.13s, iter_time: 184.44ms\n",
      "iter 1200/1232/30000: loss 0.7719, policy_loss:0.5539, value_loss:0.2180, time 11.50s, iter_time: 79.90ms\n",
      "iter 1400/1408/30000: loss 0.6972, policy_loss:0.5630, value_loss:0.1343, time 12.67s, iter_time: 75.40ms\n",
      "iter 1600/1760/30000: loss 0.7830, policy_loss:0.5811, value_loss:0.2019, time 0.90s, iter_time: 55.99ms\n",
      "iter 1800/1936/30000: loss 0.7679, policy_loss:0.5914, value_loss:0.1765, time 3.29s, iter_time: 82.20ms\n",
      "step 2000: losses: train:0.7661, train_policy_loss:0.5762, train_value_loss:0.1899, val:0.7984, val_policy_loss:0.5883, val_value_loss:0.2101\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11\n",
      "iter 2000/2112/30000: loss 0.7756, policy_loss:0.6017, value_loss:0.1738, time 9.35s, iter_time: 146.05ms\n",
      "iter 2200/2288/30000: loss 0.7818, policy_loss:0.5662, value_loss:0.2155, time 3.98s, iter_time: 45.25ms\n",
      "iter 2400/2464/30000: loss 0.7363, policy_loss:0.5725, value_loss:0.1639, time 7.36s, iter_time: 65.67ms\n",
      "iter 2600/2640/30000: loss 0.8485, policy_loss:0.6223, value_loss:0.2261, time 10.31s, iter_time: 75.83ms\n",
      "iter 2800/2816/30000: loss 0.7584, policy_loss:0.5744, value_loss:0.1840, time 11.05s, iter_time: 69.07ms\n",
      "step 3000: losses: train:0.7587, train_policy_loss:0.5754, train_value_loss:0.1833, val:0.7961, val_policy_loss:0.5841, val_value_loss:0.2120\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11\n",
      "iter 3000/3168/30000: loss 0.7431, policy_loss:0.5714, value_loss:0.1716, time 6.69s, iter_time: 836.19ms\n",
      "iter 3200/3344/30000: loss 0.7231, policy_loss:0.5771, value_loss:0.1460, time 1.40s, iter_time: 43.75ms\n",
      "iter 3400/3520/30000: loss 0.7395, policy_loss:0.5773, value_loss:0.1622, time 2.30s, iter_time: 41.16ms\n",
      "iter 3600/3696/30000: loss 0.6760, policy_loss:0.5376, value_loss:0.1384, time 4.07s, iter_time: 50.84ms\n",
      "iter 3800/3872/30000: loss 0.7353, policy_loss:0.5906, value_loss:0.1447, time 6.85s, iter_time: 65.84ms\n",
      "step 4000: losses: train:0.7397, train_policy_loss:0.5690, train_value_loss:0.1707, val:0.8058, val_policy_loss:0.5816, val_value_loss:0.2242\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11\n",
      "iter 4000/4048/30000: loss 0.7801, policy_loss:0.5773, value_loss:0.2028, time 10.76s, iter_time: 84.06ms\n",
      "iter 4200/4224/30000: loss 0.7654, policy_loss:0.5895, value_loss:0.1759, time 9.56s, iter_time: 62.90ms\n",
      "iter 4400/4576/30000: loss 0.7597, policy_loss:0.5780, value_loss:0.1817, time 0.17s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.7337, policy_loss:0.5653, value_loss:0.1684, time 1.06s, iter_time: 44.26ms\n",
      "iter 4800/4928/30000: loss 0.7267, policy_loss:0.5579, value_loss:0.1688, time 1.98s, iter_time: 41.34ms\n",
      "step 5000: losses: train:0.7354, train_policy_loss:0.5649, train_value_loss:0.1705, val:0.8140, val_policy_loss:0.5814, val_value_loss:0.2326\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11\n",
      "iter 5000/5104/30000: loss 0.8302, policy_loss:0.6264, value_loss:0.2038, time 9.03s, iter_time: 125.35ms\n",
      "iter 5200/5280/30000: loss 0.7339, policy_loss:0.5589, value_loss:0.1750, time 4.04s, iter_time: 42.08ms\n",
      "iter 5400/5456/30000: loss 0.7446, policy_loss:0.5796, value_loss:0.1650, time 5.18s, iter_time: 43.15ms\n",
      "iter 5600/5632/30000: loss 0.7042, policy_loss:0.5400, value_loss:0.1643, time 7.22s, iter_time: 50.17ms\n",
      "iter 5800/5808/30000: loss 0.7846, policy_loss:0.6065, value_loss:0.1780, time 9.15s, iter_time: 54.49ms\n",
      "step 6000: losses: train:0.7306, train_policy_loss:0.5648, train_value_loss:0.1658, val:0.8219, val_policy_loss:0.5798, val_value_loss:0.2422\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11\n",
      "iter 6000/6160/30000: loss 0.7143, policy_loss:0.5597, value_loss:0.1546, time 4.86s, iter_time: 303.98ms\n",
      "iter 6200/6336/30000: loss 0.7885, policy_loss:0.5759, value_loss:0.2126, time 2.08s, iter_time: 52.09ms\n",
      "iter 6400/6512/30000: loss 0.7502, policy_loss:0.5790, value_loss:0.1712, time 6.19s, iter_time: 96.74ms\n",
      "iter 6600/6688/30000: loss 0.6923, policy_loss:0.5471, value_loss:0.1452, time 3.66s, iter_time: 41.59ms\n",
      "iter 6800/6864/30000: loss 0.7802, policy_loss:0.5808, value_loss:0.1994, time 5.07s, iter_time: 45.30ms\n",
      "step 7000: losses: train:0.7296, train_policy_loss:0.5641, train_value_loss:0.1655, val:0.8281, val_policy_loss:0.5815, val_value_loss:0.2466\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11\n",
      "iter 7000/7040/30000: loss 0.7167, policy_loss:0.5682, value_loss:0.1484, time 9.20s, iter_time: 67.64ms\n",
      "iter 7200/7216/30000: loss 0.7530, policy_loss:0.5457, value_loss:0.2073, time 7.44s, iter_time: 46.50ms\n",
      "iter 7400/7568/30000: loss 0.7344, policy_loss:0.5705, value_loss:0.1638, time 0.34s, iter_time: 42.93ms\n",
      "iter 7600/7744/30000: loss 0.7401, policy_loss:0.5782, value_loss:0.1619, time 1.40s, iter_time: 43.84ms\n",
      "iter 7800/7920/30000: loss 0.7082, policy_loss:0.5631, value_loss:0.1450, time 2.47s, iter_time: 44.02ms\n",
      "step 8000: losses: train:0.7278, train_policy_loss:0.5637, train_value_loss:0.1641, val:0.8338, val_policy_loss:0.5816, val_value_loss:0.2522\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-11/best.pt (val_loss=0.7961)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-11.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 861572\n",
      "  Avg trajectory length: 8.62\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=93950 loss=6050 draw=0 win1%=93.95 model-win1%=94.10\n",
      "actions=(1,): 213 win=47 loss=166 draw=0 win1%=22.07 model-win1%=21.07\n",
      "actions=(2,): 262 win=81 loss=181 draw=0 win1%=30.92 model-win1%=28.82\n",
      "actions=(3,): 376 win=181 loss=195 draw=0 win1%=48.14 model-win1%=46.50\n",
      "actions=(4,): 97199 win=92900 loss=4299 draw=0 win1%=95.58 model-win1%=95.11\n",
      "actions=(4, 4): 12664 win=11284 loss=1380 draw=0 win1%=89.10 model-win1%=90.22\n",
      "actions=(4, 5): 74483 win=71962 loss=2521 draw=0 win1%=96.62 model-win1%=96.58\n",
      "actions=(5,): 736 win=390 loss=346 draw=0 win1%=52.99 model-win1%=46.51\n",
      "actions=(6,): 889 win=285 loss=604 draw=0 win1%=32.06 model-win1%=30.51\n",
      "actions=(7,): 325 win=66 loss=259 draw=0 win1%=20.31 model-win1%=21.76\n",
      "\n",
      "=== Generation 12 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  99%|█████████▉| 9942/10000 [01:32<00:02, 21.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.005 seconds, size=61, eval-per-second=12767.09, total-batches=1000, mean-eval-per-second=33894.79, mean-time-per-batch=0.019, mean-batch-size=658.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9997/10000 [01:36<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=4, eval-per-second=2461.81, total-batches=2000, mean-eval-per-second=30042.38, mean-time-per-batch=0.011, mean-batch-size=337.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9999/10000 [01:36<00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.001 seconds, size=1, eval-per-second=742.35, total-batches=3000, mean-eval-per-second=27683.59, mean-time-per-batch=0.008, mean-batch-size=225.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:38<00:00, 101.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 12...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.5948, train_policy_loss:0.4410, train_value_loss:0.1538, val:0.6005, val_policy_loss:0.4410, val_value_loss:0.1595\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-12/best.pt\n",
      "iter 0/176/30000: loss 0.5886, policy_loss:0.4182, value_loss:0.1704, time 12.41s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.5833, policy_loss:0.4416, value_loss:0.1417, time 1.11s, iter_time: 46.22ms\n",
      "iter 400/528/30000: loss 0.6092, policy_loss:0.4443, value_loss:0.1649, time 4.86s, iter_time: 101.25ms\n",
      "iter 600/704/30000: loss 0.5588, policy_loss:0.4277, value_loss:0.1311, time 5.81s, iter_time: 80.63ms\n",
      "iter 800/880/30000: loss 0.5575, policy_loss:0.4294, value_loss:0.1280, time 6.04s, iter_time: 62.90ms\n",
      "step 1000: losses: train:0.5952, train_policy_loss:0.4382, train_value_loss:0.1570, val:0.6084, val_policy_loss:0.4401, val_value_loss:0.1683\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-12\n",
      "iter 1000/1056/30000: loss 0.6703, policy_loss:0.4735, value_loss:0.1968, time 19.29s, iter_time: 160.79ms\n",
      "iter 1200/1232/30000: loss 0.6069, policy_loss:0.4442, value_loss:0.1627, time 9.71s, iter_time: 67.44ms\n",
      "iter 1400/1408/30000: loss 0.5868, policy_loss:0.4366, value_loss:0.1503, time 9.25s, iter_time: 55.04ms\n",
      "iter 1600/1760/30000: loss 0.5685, policy_loss:0.4211, value_loss:0.1474, time 1.48s, iter_time: 92.67ms\n",
      "iter 1800/1936/30000: loss 0.5976, policy_loss:0.4375, value_loss:0.1600, time 1.79s, iter_time: 44.76ms\n",
      "step 2000: losses: train:0.5880, train_policy_loss:0.4355, train_value_loss:0.1525, val:0.6127, val_policy_loss:0.4410, val_value_loss:0.1718\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-12\n",
      "iter 2000/2112/30000: loss 0.6625, policy_loss:0.4692, value_loss:0.1933, time 9.53s, iter_time: 148.87ms\n",
      "iter 2200/2288/30000: loss 0.5411, policy_loss:0.4132, value_loss:0.1279, time 4.19s, iter_time: 47.67ms\n",
      "iter 2400/2464/30000: loss 0.5531, policy_loss:0.4329, value_loss:0.1202, time 8.48s, iter_time: 75.67ms\n",
      "iter 2600/2640/30000: loss 0.6164, policy_loss:0.4679, value_loss:0.1485, time 6.82s, iter_time: 50.12ms\n",
      "iter 2800/2816/30000: loss 0.5907, policy_loss:0.4313, value_loss:0.1594, time 8.03s, iter_time: 50.20ms\n",
      "step 3000: losses: train:0.5800, train_policy_loss:0.4329, train_value_loss:0.1471, val:0.6090, val_policy_loss:0.4379, val_value_loss:0.1711\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-12\n",
      "iter 3000/3168/30000: loss 0.5698, policy_loss:0.4126, value_loss:0.1572, time 6.79s, iter_time: 849.18ms\n",
      "iter 3200/3344/30000: loss 0.5789, policy_loss:0.4177, value_loss:0.1612, time 1.35s, iter_time: 42.21ms\n",
      "iter 3400/3520/30000: loss 0.6078, policy_loss:0.4417, value_loss:0.1661, time 2.56s, iter_time: 45.80ms\n",
      "iter 3600/3696/30000: loss 0.5741, policy_loss:0.4273, value_loss:0.1468, time 3.67s, iter_time: 45.87ms\n",
      "iter 3800/3872/30000: loss 0.5979, policy_loss:0.4395, value_loss:0.1584, time 4.16s, iter_time: 40.00ms\n",
      "step 4000: losses: train:0.5706, train_policy_loss:0.4281, train_value_loss:0.1425, val:0.6131, val_policy_loss:0.4371, val_value_loss:0.1760\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-12\n",
      "iter 4000/4048/30000: loss 0.5404, policy_loss:0.4229, value_loss:0.1175, time 10.11s, iter_time: 78.96ms\n",
      "iter 4200/4224/30000: loss 0.5613, policy_loss:0.4406, value_loss:0.1207, time 6.65s, iter_time: 43.74ms\n",
      "iter 4400/4576/30000: loss 0.6190, policy_loss:0.4369, value_loss:0.1821, time 0.05s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.5865, policy_loss:0.4392, value_loss:0.1473, time 1.28s, iter_time: 53.42ms\n",
      "iter 4800/4928/30000: loss 0.6174, policy_loss:0.4448, value_loss:0.1725, time 2.16s, iter_time: 45.08ms\n",
      "step 5000: losses: train:0.5605, train_policy_loss:0.4235, train_value_loss:0.1369, val:0.6196, val_policy_loss:0.4370, val_value_loss:0.1826\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-12/best.pt (val_loss=0.6005)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-12.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 835461\n",
      "  Avg trajectory length: 8.35\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=95675 loss=4325 draw=0 win1%=95.67 model-win1%=94.10\n",
      "actions=(1,): 153 win=20 loss=133 draw=0 win1%=13.07 model-win1%=21.07\n",
      "actions=(2,): 167 win=58 loss=109 draw=0 win1%=34.73 model-win1%=28.82\n",
      "actions=(3,): 186 win=96 loss=90 draw=0 win1%=51.61 model-win1%=46.50\n",
      "actions=(4,): 98615 win=95149 loss=3466 draw=0 win1%=96.49 model-win1%=95.11\n",
      "actions=(4, 4): 11829 win=10663 loss=1166 draw=0 win1%=90.14 model-win1%=90.22\n",
      "actions=(4, 5): 79525 win=77371 loss=2154 draw=0 win1%=97.29 model-win1%=96.58\n",
      "actions=(5,): 314 win=206 loss=108 draw=0 win1%=65.61 model-win1%=46.51\n",
      "actions=(6,): 386 win=119 loss=267 draw=0 win1%=30.83 model-win1%=30.51\n",
      "actions=(7,): 179 win=27 loss=152 draw=0 win1%=15.08 model-win1%=21.76\n",
      "\n",
      "=== Generation 13 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play:  99%|█████████▉| 9949/10000 [01:32<00:02, 21.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=56, eval-per-second=31783.63, total-batches=1000, mean-eval-per-second=31930.60, mean-time-per-batch=0.021, mean-batch-size=656.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9996/10000 [01:37<00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=4, eval-per-second=2467.60, total-batches=2000, mean-eval-per-second=27328.69, mean-time-per-batch=0.012, mean-batch-size=337.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:39<00:00, 100.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 13...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.4860, train_policy_loss:0.3536, train_value_loss:0.1324, val:0.4778, val_policy_loss:0.3492, val_value_loss:0.1286\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13/best.pt\n",
      "iter 0/176/30000: loss 0.4792, policy_loss:0.3533, value_loss:0.1259, time 32.93s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.5415, policy_loss:0.3773, value_loss:0.1642, time 4.23s, iter_time: 176.26ms\n",
      "iter 400/528/30000: loss 0.4464, policy_loss:0.3291, value_loss:0.1173, time 2.84s, iter_time: 59.19ms\n",
      "iter 600/704/30000: loss 0.4484, policy_loss:0.3394, value_loss:0.1090, time 3.36s, iter_time: 46.63ms\n",
      "iter 800/880/30000: loss 0.5049, policy_loss:0.3328, value_loss:0.1721, time 4.34s, iter_time: 45.24ms\n",
      "step 1000: losses: train:0.4729, train_policy_loss:0.3411, train_value_loss:0.1318, val:0.4741, val_policy_loss:0.3396, val_value_loss:0.1345\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13\n",
      "iter 1000/1056/30000: loss 0.4675, policy_loss:0.3347, value_loss:0.1328, time 14.65s, iter_time: 122.08ms\n",
      "iter 1200/1232/30000: loss 0.5178, policy_loss:0.3598, value_loss:0.1580, time 12.26s, iter_time: 85.17ms\n",
      "iter 1400/1408/30000: loss 0.4114, policy_loss:0.3106, value_loss:0.1008, time 10.12s, iter_time: 60.26ms\n",
      "iter 1600/1760/30000: loss 0.4199, policy_loss:0.3262, value_loss:0.0937, time 0.70s, iter_time: 43.53ms\n",
      "iter 1800/1936/30000: loss 0.5134, policy_loss:0.3649, value_loss:0.1485, time 1.58s, iter_time: 39.46ms\n",
      "step 2000: losses: train:0.4654, train_policy_loss:0.3369, train_value_loss:0.1285, val:0.4708, val_policy_loss:0.3367, val_value_loss:0.1341\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13\n",
      "iter 2000/2112/30000: loss 0.5188, policy_loss:0.3654, value_loss:0.1534, time 8.92s, iter_time: 139.41ms\n",
      "iter 2200/2288/30000: loss 0.4739, policy_loss:0.3207, value_loss:0.1532, time 5.99s, iter_time: 68.04ms\n",
      "iter 2400/2464/30000: loss 0.4358, policy_loss:0.3489, value_loss:0.0869, time 4.98s, iter_time: 44.45ms\n",
      "iter 2600/2640/30000: loss 0.4816, policy_loss:0.3327, value_loss:0.1490, time 6.25s, iter_time: 45.95ms\n",
      "iter 2800/2816/30000: loss 0.4784, policy_loss:0.3453, value_loss:0.1331, time 8.61s, iter_time: 53.80ms\n",
      "step 3000: losses: train:0.4607, train_policy_loss:0.3355, train_value_loss:0.1252, val:0.4718, val_policy_loss:0.3358, val_value_loss:0.1360\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13\n",
      "iter 3000/3168/30000: loss 0.3976, policy_loss:0.3073, value_loss:0.0903, time 5.88s, iter_time: 734.85ms\n",
      "iter 3200/3344/30000: loss 0.4460, policy_loss:0.3237, value_loss:0.1223, time 1.30s, iter_time: 40.57ms\n",
      "iter 3400/3520/30000: loss 0.4103, policy_loss:0.3173, value_loss:0.0929, time 3.25s, iter_time: 58.04ms\n",
      "iter 3600/3696/30000: loss 0.4004, policy_loss:0.3098, value_loss:0.0905, time 3.83s, iter_time: 47.93ms\n",
      "iter 3800/3872/30000: loss 0.4967, policy_loss:0.3477, value_loss:0.1490, time 4.62s, iter_time: 44.45ms\n",
      "step 4000: losses: train:0.4527, train_policy_loss:0.3312, train_value_loss:0.1216, val:0.4750, val_policy_loss:0.3337, val_value_loss:0.1413\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13\n",
      "iter 4000/4048/30000: loss 0.4437, policy_loss:0.3196, value_loss:0.1241, time 13.23s, iter_time: 103.39ms\n",
      "iter 4200/4224/30000: loss 0.4578, policy_loss:0.3362, value_loss:0.1215, time 8.67s, iter_time: 57.04ms\n",
      "iter 4400/4576/30000: loss 0.4354, policy_loss:0.3288, value_loss:0.1066, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.4491, policy_loss:0.3312, value_loss:0.1179, time 0.95s, iter_time: 39.75ms\n",
      "iter 4800/4928/30000: loss 0.4210, policy_loss:0.3144, value_loss:0.1066, time 2.96s, iter_time: 61.74ms\n",
      "step 5000: losses: train:0.4457, train_policy_loss:0.3282, train_value_loss:0.1175, val:0.4786, val_policy_loss:0.3350, val_value_loss:0.1436\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13\n",
      "iter 5000/5104/30000: loss 0.4441, policy_loss:0.3220, value_loss:0.1221, time 8.44s, iter_time: 117.23ms\n",
      "iter 5200/5280/30000: loss 0.4665, policy_loss:0.3265, value_loss:0.1400, time 4.33s, iter_time: 45.12ms\n",
      "iter 5400/5456/30000: loss 0.4480, policy_loss:0.3303, value_loss:0.1177, time 5.67s, iter_time: 47.25ms\n",
      "iter 5600/5632/30000: loss 0.4552, policy_loss:0.3334, value_loss:0.1219, time 6.92s, iter_time: 48.08ms\n",
      "iter 5800/5808/30000: loss 0.4325, policy_loss:0.3269, value_loss:0.1056, time 7.23s, iter_time: 43.05ms\n",
      "step 6000: losses: train:0.4425, train_policy_loss:0.3265, train_value_loss:0.1160, val:0.4776, val_policy_loss:0.3344, val_value_loss:0.1432\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13\n",
      "iter 6000/6160/30000: loss 0.4561, policy_loss:0.3460, value_loss:0.1101, time 9.09s, iter_time: 568.01ms\n",
      "iter 6200/6336/30000: loss 0.4111, policy_loss:0.3106, value_loss:0.1006, time 1.72s, iter_time: 42.88ms\n",
      "iter 6400/6512/30000: loss 0.4711, policy_loss:0.3284, value_loss:0.1427, time 2.60s, iter_time: 40.55ms\n",
      "iter 6600/6688/30000: loss 0.4713, policy_loss:0.3447, value_loss:0.1266, time 3.94s, iter_time: 44.79ms\n",
      "iter 6800/6864/30000: loss 0.4453, policy_loss:0.3314, value_loss:0.1139, time 5.77s, iter_time: 51.55ms\n",
      "step 7000: losses: train:0.4436, train_policy_loss:0.3260, train_value_loss:0.1177, val:0.4842, val_policy_loss:0.3357, val_value_loss:0.1485\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-13/best.pt (val_loss=0.4708)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-13.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 797558\n",
      "  Avg trajectory length: 7.98\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=96492 loss=3508 draw=0 win1%=96.49 model-win1%=96.69\n",
      "actions=(1,): 139 win=16 loss=123 draw=0 win1%=11.51 model-win1%=14.26\n",
      "actions=(2,): 143 win=49 loss=94 draw=0 win1%=34.27 model-win1%=39.40\n",
      "actions=(3,): 160 win=80 loss=80 draw=0 win1%=50.00 model-win1%=39.82\n",
      "actions=(4,): 98892 win=96091 loss=2801 draw=0 win1%=97.17 model-win1%=96.85\n",
      "actions=(4, 5): 88053 win=85872 loss=2181 draw=0 win1%=97.52 model-win1%=97.61\n",
      "actions=(5,): 233 win=156 loss=77 draw=0 win1%=66.95 model-win1%=72.54\n",
      "actions=(6,): 278 win=78 loss=200 draw=0 win1%=28.06 model-win1%=24.58\n",
      "actions=(7,): 155 win=22 loss=133 draw=0 win1%=14.19 model-win1%=13.16\n",
      "\n",
      "=== Generation 14 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9979/10000 [01:30<00:02,  8.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.003 seconds, size=22, eval-per-second=8517.93, total-batches=1000, mean-eval-per-second=31525.32, mean-time-per-batch=0.020, mean-batch-size=623.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9999/10000 [01:33<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.001 seconds, size=1, eval-per-second=687.70, total-batches=2000, mean-eval-per-second=28367.02, mean-time-per-batch=0.011, mean-batch-size=315.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:34<00:00, 106.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.3812, train_policy_loss:0.2882, train_value_loss:0.0930, val:0.3772, val_policy_loss:0.2865, val_value_loss:0.0907\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14/best.pt\n",
      "iter 0/176/30000: loss 0.3653, policy_loss:0.2805, value_loss:0.0848, time 29.85s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.4282, policy_loss:0.3038, value_loss:0.1243, time 4.02s, iter_time: 167.35ms\n",
      "iter 400/528/30000: loss 0.3681, policy_loss:0.2933, value_loss:0.0748, time 5.59s, iter_time: 116.56ms\n",
      "iter 600/704/30000: loss 0.4007, policy_loss:0.3122, value_loss:0.0885, time 3.85s, iter_time: 53.52ms\n",
      "iter 800/880/30000: loss 0.4228, policy_loss:0.3016, value_loss:0.1212, time 6.83s, iter_time: 71.17ms\n",
      "step 1000: losses: train:0.3772, train_policy_loss:0.2851, train_value_loss:0.0922, val:0.3793, val_policy_loss:0.2852, val_value_loss:0.0941\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 1000/1056/30000: loss 0.3455, policy_loss:0.2692, value_loss:0.0763, time 16.50s, iter_time: 137.54ms\n",
      "iter 1200/1232/30000: loss 0.3911, policy_loss:0.2850, value_loss:0.1061, time 9.67s, iter_time: 67.16ms\n",
      "iter 1400/1408/30000: loss 0.3935, policy_loss:0.2855, value_loss:0.1080, time 9.74s, iter_time: 57.96ms\n",
      "iter 1600/1760/30000: loss 0.3627, policy_loss:0.2864, value_loss:0.0764, time 0.97s, iter_time: 60.82ms\n",
      "iter 1800/1936/30000: loss 0.4042, policy_loss:0.3143, value_loss:0.0899, time 4.60s, iter_time: 114.95ms\n",
      "step 2000: losses: train:0.3676, train_policy_loss:0.2815, train_value_loss:0.0861, val:0.3781, val_policy_loss:0.2842, val_value_loss:0.0939\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 2000/2112/30000: loss 0.3672, policy_loss:0.2825, value_loss:0.0847, time 10.08s, iter_time: 157.58ms\n",
      "iter 2200/2288/30000: loss 0.3313, policy_loss:0.2728, value_loss:0.0585, time 3.68s, iter_time: 41.86ms\n",
      "iter 2400/2464/30000: loss 0.4072, policy_loss:0.2871, value_loss:0.1201, time 6.82s, iter_time: 60.92ms\n",
      "iter 2600/2640/30000: loss 0.3273, policy_loss:0.2688, value_loss:0.0584, time 6.02s, iter_time: 44.28ms\n",
      "iter 2800/2816/30000: loss 0.3473, policy_loss:0.2826, value_loss:0.0646, time 15.51s, iter_time: 96.96ms\n",
      "step 3000: losses: train:0.3687, train_policy_loss:0.2805, train_value_loss:0.0882, val:0.3785, val_policy_loss:0.2835, val_value_loss:0.0950\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 3000/3168/30000: loss 0.3199, policy_loss:0.2632, value_loss:0.0567, time 8.74s, iter_time: 1092.39ms\n",
      "iter 3200/3344/30000: loss 0.3550, policy_loss:0.2679, value_loss:0.0871, time 1.35s, iter_time: 42.34ms\n",
      "iter 3400/3520/30000: loss 0.3567, policy_loss:0.2689, value_loss:0.0878, time 3.25s, iter_time: 58.11ms\n",
      "iter 3600/3696/30000: loss 0.3682, policy_loss:0.2823, value_loss:0.0858, time 3.19s, iter_time: 39.82ms\n",
      "iter 3800/3872/30000: loss 0.3940, policy_loss:0.2942, value_loss:0.0998, time 6.39s, iter_time: 61.46ms\n",
      "step 4000: losses: train:0.3545, train_policy_loss:0.2741, train_value_loss:0.0804, val:0.3759, val_policy_loss:0.2818, val_value_loss:0.0941\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 4000/4048/30000: loss 0.3180, policy_loss:0.2587, value_loss:0.0593, time 14.15s, iter_time: 110.53ms\n",
      "iter 4200/4224/30000: loss 0.3633, policy_loss:0.2778, value_loss:0.0855, time 10.11s, iter_time: 66.51ms\n",
      "iter 4400/4576/30000: loss 0.3771, policy_loss:0.2740, value_loss:0.1031, time 0.05s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.3297, policy_loss:0.2671, value_loss:0.0626, time 0.99s, iter_time: 41.33ms\n",
      "iter 4800/4928/30000: loss 0.3108, policy_loss:0.2627, value_loss:0.0482, time 1.97s, iter_time: 40.97ms\n",
      "step 5000: losses: train:0.3544, train_policy_loss:0.2738, train_value_loss:0.0806, val:0.3800, val_policy_loss:0.2828, val_value_loss:0.0972\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 5000/5104/30000: loss 0.3221, policy_loss:0.2602, value_loss:0.0620, time 8.42s, iter_time: 116.98ms\n",
      "iter 5200/5280/30000: loss 0.3782, policy_loss:0.2856, value_loss:0.0926, time 4.18s, iter_time: 43.57ms\n",
      "iter 5400/5456/30000: loss 0.3210, policy_loss:0.2746, value_loss:0.0464, time 8.10s, iter_time: 67.53ms\n",
      "iter 5600/5632/30000: loss 0.3790, policy_loss:0.2731, value_loss:0.1060, time 9.58s, iter_time: 66.50ms\n",
      "iter 5800/5808/30000: loss 0.3715, policy_loss:0.2856, value_loss:0.0859, time 7.75s, iter_time: 46.10ms\n",
      "step 6000: losses: train:0.3526, train_policy_loss:0.2734, train_value_loss:0.0792, val:0.3803, val_policy_loss:0.2835, val_value_loss:0.0969\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 6000/6160/30000: loss 0.3271, policy_loss:0.2678, value_loss:0.0593, time 6.10s, iter_time: 381.02ms\n",
      "iter 6200/6336/30000: loss 0.3278, policy_loss:0.2670, value_loss:0.0608, time 1.69s, iter_time: 42.32ms\n",
      "iter 6400/6512/30000: loss 0.3572, policy_loss:0.2879, value_loss:0.0693, time 2.63s, iter_time: 41.10ms\n",
      "iter 6600/6688/30000: loss 0.3193, policy_loss:0.2588, value_loss:0.0605, time 3.73s, iter_time: 42.36ms\n",
      "iter 6800/6864/30000: loss 0.3530, policy_loss:0.2872, value_loss:0.0658, time 5.18s, iter_time: 46.24ms\n",
      "step 7000: losses: train:0.3514, train_policy_loss:0.2725, train_value_loss:0.0789, val:0.3800, val_policy_loss:0.2831, val_value_loss:0.0969\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 7000/7040/30000: loss 0.3269, policy_loss:0.2623, value_loss:0.0647, time 10.49s, iter_time: 77.14ms\n",
      "iter 7200/7216/30000: loss 0.3880, policy_loss:0.2925, value_loss:0.0955, time 7.42s, iter_time: 46.39ms\n",
      "iter 7400/7568/30000: loss 0.3575, policy_loss:0.2595, value_loss:0.0981, time 0.55s, iter_time: 69.29ms\n",
      "iter 7600/7744/30000: loss 0.3449, policy_loss:0.2789, value_loss:0.0660, time 1.23s, iter_time: 38.48ms\n",
      "iter 7800/7920/30000: loss 0.4071, policy_loss:0.2783, value_loss:0.1288, time 2.24s, iter_time: 39.95ms\n",
      "step 8000: losses: train:0.3536, train_policy_loss:0.2725, train_value_loss:0.0811, val:0.3855, val_policy_loss:0.2848, val_value_loss:0.1007\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14\n",
      "iter 8000/8096/30000: loss 0.3789, policy_loss:0.2795, value_loss:0.0994, time 8.36s, iter_time: 104.48ms\n",
      "iter 8200/8272/30000: loss 0.3722, policy_loss:0.2833, value_loss:0.0889, time 4.39s, iter_time: 42.18ms\n",
      "iter 8400/8448/30000: loss 0.3785, policy_loss:0.2726, value_loss:0.1059, time 5.31s, iter_time: 41.45ms\n",
      "iter 8600/8624/30000: loss 0.3269, policy_loss:0.2687, value_loss:0.0582, time 6.73s, iter_time: 44.28ms\n",
      "iter 8800/8976/30000: loss 0.3586, policy_loss:0.2687, value_loss:0.0899, time 0.04s, iter_time: 0.00ms\n",
      "step 9000: losses: train:0.3523, train_policy_loss:0.2720, train_value_loss:0.0803, val:0.3839, val_policy_loss:0.2841, val_value_loss:0.0998\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-14/best.pt (val_loss=0.3759)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-14.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 778009\n",
      "  Avg trajectory length: 7.78\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=97655 loss=2345 draw=0 win1%=97.66 model-win1%=97.84\n",
      "actions=(1,): 129 win=14 loss=115 draw=0 win1%=10.85 model-win1%=11.31\n",
      "actions=(2,): 122 win=42 loss=80 draw=0 win1%=34.43 model-win1%=34.46\n",
      "actions=(3,): 150 win=77 loss=73 draw=0 win1%=51.33 model-win1%=55.73\n",
      "actions=(4,): 99018 win=97270 loss=1748 draw=0 win1%=98.23 model-win1%=98.23\n",
      "actions=(4, 5): 90181 win=88890 loss=1291 draw=0 win1%=98.57 model-win1%=98.75\n",
      "actions=(5,): 227 win=157 loss=70 draw=0 win1%=69.16 model-win1%=74.13\n",
      "actions=(6,): 229 win=78 loss=151 draw=0 win1%=34.06 model-win1%=38.61\n",
      "actions=(7,): 125 win=17 loss=108 draw=0 win1%=13.60 model-win1%=14.38\n",
      "\n",
      "=== Generation 15 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9983/10000 [01:24<00:01, 14.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=21, eval-per-second=11152.24, total-batches=1000, mean-eval-per-second=31734.33, mean-time-per-batch=0.017, mean-batch-size=541.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:26<00:00, 116.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.001 seconds, size=1, eval-per-second=782.52, total-batches=2000, mean-eval-per-second=28828.29, mean-time-per-batch=0.009, mean-batch-size=272.87\n",
      "Writing 10000 trajectories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for gen 15...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.3298, train_policy_loss:0.2581, train_value_loss:0.0717, val:0.3388, val_policy_loss:0.2622, val_value_loss:0.0766\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-15/best.pt\n",
      "iter 0/176/30000: loss 0.3781, policy_loss:0.2572, value_loss:0.1210, time 16.12s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.3333, policy_loss:0.2536, value_loss:0.0797, time 2.68s, iter_time: 111.74ms\n",
      "iter 400/528/30000: loss 0.3274, policy_loss:0.2744, value_loss:0.0530, time 3.82s, iter_time: 79.54ms\n",
      "iter 600/704/30000: loss 0.3637, policy_loss:0.2583, value_loss:0.1053, time 5.68s, iter_time: 78.90ms\n",
      "iter 800/880/30000: loss 0.3432, policy_loss:0.2672, value_loss:0.0760, time 3.88s, iter_time: 40.38ms\n",
      "step 1000: losses: train:0.3385, train_policy_loss:0.2635, train_value_loss:0.0750, val:0.3521, val_policy_loss:0.2688, val_value_loss:0.0833\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-15\n",
      "iter 1000/1056/30000: loss 0.3262, policy_loss:0.2659, value_loss:0.0603, time 13.34s, iter_time: 111.19ms\n",
      "iter 1200/1232/30000: loss 0.3352, policy_loss:0.2584, value_loss:0.0767, time 6.67s, iter_time: 46.33ms\n",
      "iter 1400/1408/30000: loss 0.3018, policy_loss:0.2528, value_loss:0.0489, time 9.28s, iter_time: 55.24ms\n",
      "iter 1600/1760/30000: loss 0.3381, policy_loss:0.2749, value_loss:0.0632, time 0.66s, iter_time: 41.12ms\n",
      "iter 1800/1936/30000: loss 0.3053, policy_loss:0.2580, value_loss:0.0473, time 2.04s, iter_time: 50.90ms\n",
      "step 2000: losses: train:0.3368, train_policy_loss:0.2621, train_value_loss:0.0747, val:0.3510, val_policy_loss:0.2677, val_value_loss:0.0833\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-15\n",
      "iter 2000/2112/30000: loss 0.2961, policy_loss:0.2555, value_loss:0.0406, time 8.50s, iter_time: 132.88ms\n",
      "iter 2200/2288/30000: loss 0.3289, policy_loss:0.2470, value_loss:0.0819, time 4.20s, iter_time: 47.77ms\n",
      "iter 2400/2464/30000: loss 0.3256, policy_loss:0.2632, value_loss:0.0624, time 5.07s, iter_time: 45.27ms\n",
      "iter 2600/2640/30000: loss 0.3897, policy_loss:0.2688, value_loss:0.1209, time 6.12s, iter_time: 44.99ms\n",
      "iter 2800/2816/30000: loss 0.3310, policy_loss:0.2543, value_loss:0.0767, time 9.02s, iter_time: 56.35ms\n",
      "step 3000: losses: train:0.3293, train_policy_loss:0.2584, train_value_loss:0.0710, val:0.3502, val_policy_loss:0.2672, val_value_loss:0.0830\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-15\n",
      "iter 3000/3168/30000: loss 0.3279, policy_loss:0.2637, value_loss:0.0642, time 5.09s, iter_time: 636.14ms\n",
      "iter 3200/3344/30000: loss 0.4178, policy_loss:0.3059, value_loss:0.1119, time 1.41s, iter_time: 44.17ms\n",
      "iter 3400/3520/30000: loss 0.3182, policy_loss:0.2436, value_loss:0.0746, time 2.28s, iter_time: 40.78ms\n",
      "iter 3600/3696/30000: loss 0.3499, policy_loss:0.2603, value_loss:0.0896, time 3.81s, iter_time: 47.60ms\n",
      "iter 3800/3872/30000: loss 0.3290, policy_loss:0.2660, value_loss:0.0630, time 4.39s, iter_time: 42.24ms\n",
      "step 4000: losses: train:0.3254, train_policy_loss:0.2545, train_value_loss:0.0709, val:0.3497, val_policy_loss:0.2664, val_value_loss:0.0833\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-15\n",
      "iter 4000/4048/30000: loss 0.3056, policy_loss:0.2466, value_loss:0.0590, time 11.72s, iter_time: 91.53ms\n",
      "iter 4200/4224/30000: loss 0.3233, policy_loss:0.2556, value_loss:0.0677, time 6.22s, iter_time: 40.90ms\n",
      "iter 4400/4576/30000: loss 0.2967, policy_loss:0.2389, value_loss:0.0577, time 3.41s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2914, policy_loss:0.2461, value_loss:0.0453, time 0.97s, iter_time: 40.22ms\n",
      "iter 4800/4928/30000: loss 0.3404, policy_loss:0.2495, value_loss:0.0909, time 1.81s, iter_time: 37.70ms\n",
      "step 5000: losses: train:0.3209, train_policy_loss:0.2530, train_value_loss:0.0679, val:0.3529, val_policy_loss:0.2666, val_value_loss:0.0864\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-15/best.pt (val_loss=0.3388)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-15.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 768142\n",
      "  Avg trajectory length: 7.68\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98006 loss=1994 draw=0 win1%=98.01 model-win1%=97.84\n",
      "actions=(1,): 116 win=13 loss=103 draw=0 win1%=11.21 model-win1%=11.31\n",
      "actions=(2,): 111 win=38 loss=73 draw=0 win1%=34.23 model-win1%=34.46\n",
      "actions=(3,): 148 win=79 loss=69 draw=0 win1%=53.38 model-win1%=55.73\n",
      "actions=(4,): 99054 win=97619 loss=1435 draw=0 win1%=98.55 model-win1%=98.23\n",
      "actions=(4, 5): 91015 win=89965 loss=1050 draw=0 win1%=98.85 model-win1%=98.75\n",
      "actions=(5,): 234 win=171 loss=63 draw=0 win1%=73.08 model-win1%=74.13\n",
      "actions=(6,): 205 win=67 loss=138 draw=0 win1%=32.68 model-win1%=38.61\n",
      "actions=(7,): 132 win=19 loss=113 draw=0 win1%=14.39 model-win1%=14.38\n",
      "\n",
      "=== Generation 16 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9985/10000 [01:25<00:00, 22.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=17, eval-per-second=7780.79, total-batches=1000, mean-eval-per-second=31224.13, mean-time-per-batch=0.017, mean-batch-size=542.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9997/10000 [01:26<00:00,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=2, eval-per-second=1164.92, total-batches=2000, mean-eval-per-second=28475.94, mean-time-per-batch=0.010, mean-batch-size=274.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:27<00:00, 113.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.3009, train_policy_loss:0.2415, train_value_loss:0.0593, val:0.3039, val_policy_loss:0.2421, val_value_loss:0.0618\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-16/best.pt\n",
      "iter 0/176/30000: loss 0.2767, policy_loss:0.2361, value_loss:0.0405, time 11.92s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2653, policy_loss:0.2138, value_loss:0.0515, time 4.01s, iter_time: 166.93ms\n",
      "iter 400/528/30000: loss 0.3005, policy_loss:0.2400, value_loss:0.0605, time 3.61s, iter_time: 75.30ms\n",
      "iter 600/704/30000: loss 0.3210, policy_loss:0.2481, value_loss:0.0730, time 5.27s, iter_time: 73.13ms\n",
      "iter 800/880/30000: loss 0.3231, policy_loss:0.2468, value_loss:0.0763, time 5.79s, iter_time: 60.33ms\n",
      "step 1000: losses: train:0.3051, train_policy_loss:0.2429, train_value_loss:0.0622, val:0.3092, val_policy_loss:0.2453, val_value_loss:0.0640\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-16\n",
      "iter 1000/1056/30000: loss 0.3007, policy_loss:0.2461, value_loss:0.0546, time 15.03s, iter_time: 125.28ms\n",
      "iter 1200/1232/30000: loss 0.2951, policy_loss:0.2317, value_loss:0.0633, time 6.41s, iter_time: 44.52ms\n",
      "iter 1400/1408/30000: loss 0.3205, policy_loss:0.2294, value_loss:0.0911, time 11.47s, iter_time: 68.28ms\n",
      "iter 1600/1760/30000: loss 0.2682, policy_loss:0.2325, value_loss:0.0357, time 0.97s, iter_time: 60.88ms\n",
      "iter 1800/1936/30000: loss 0.2947, policy_loss:0.2376, value_loss:0.0571, time 3.78s, iter_time: 94.58ms\n",
      "step 2000: losses: train:0.2999, train_policy_loss:0.2405, train_value_loss:0.0593, val:0.3101, val_policy_loss:0.2439, val_value_loss:0.0661\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-16\n",
      "iter 2000/2112/30000: loss 0.3029, policy_loss:0.2426, value_loss:0.0603, time 9.89s, iter_time: 154.47ms\n",
      "iter 2200/2288/30000: loss 0.3131, policy_loss:0.2439, value_loss:0.0692, time 3.74s, iter_time: 42.54ms\n",
      "iter 2400/2464/30000: loss 0.2990, policy_loss:0.2581, value_loss:0.0409, time 11.24s, iter_time: 100.36ms\n",
      "iter 2600/2640/30000: loss 0.2868, policy_loss:0.2247, value_loss:0.0622, time 6.48s, iter_time: 47.62ms\n",
      "iter 2800/2816/30000: loss 0.3429, policy_loss:0.2699, value_loss:0.0731, time 7.59s, iter_time: 47.47ms\n",
      "step 3000: losses: train:0.2933, train_policy_loss:0.2376, train_value_loss:0.0557, val:0.3097, val_policy_loss:0.2430, val_value_loss:0.0668\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-16\n",
      "iter 3000/3168/30000: loss 0.3202, policy_loss:0.2403, value_loss:0.0799, time 6.09s, iter_time: 761.23ms\n",
      "iter 3200/3344/30000: loss 0.2765, policy_loss:0.2413, value_loss:0.0352, time 1.38s, iter_time: 43.20ms\n",
      "iter 3400/3520/30000: loss 0.2680, policy_loss:0.2276, value_loss:0.0404, time 2.36s, iter_time: 42.06ms\n",
      "iter 3600/3696/30000: loss 0.3083, policy_loss:0.2397, value_loss:0.0686, time 3.53s, iter_time: 44.13ms\n",
      "iter 3800/3872/30000: loss 0.2955, policy_loss:0.2434, value_loss:0.0521, time 4.10s, iter_time: 39.42ms\n",
      "step 4000: losses: train:0.2925, train_policy_loss:0.2352, train_value_loss:0.0573, val:0.3109, val_policy_loss:0.2421, val_value_loss:0.0687\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-16\n",
      "iter 4000/4048/30000: loss 0.3036, policy_loss:0.2319, value_loss:0.0717, time 10.55s, iter_time: 82.40ms\n",
      "iter 4200/4224/30000: loss 0.3010, policy_loss:0.2359, value_loss:0.0651, time 6.68s, iter_time: 43.94ms\n",
      "iter 4400/4576/30000: loss 0.3077, policy_loss:0.2512, value_loss:0.0564, time 0.20s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.3050, policy_loss:0.2334, value_loss:0.0716, time 1.29s, iter_time: 53.64ms\n",
      "iter 4800/4928/30000: loss 0.3081, policy_loss:0.2461, value_loss:0.0620, time 2.09s, iter_time: 43.54ms\n",
      "step 5000: losses: train:0.2879, train_policy_loss:0.2338, train_value_loss:0.0541, val:0.3125, val_policy_loss:0.2426, val_value_loss:0.0699\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-16/best.pt (val_loss=0.3039)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-16.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 758388\n",
      "  Avg trajectory length: 7.58\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98346 loss=1654 draw=0 win1%=98.35 model-win1%=97.84\n",
      "actions=(1,): 107 win=12 loss=95 draw=0 win1%=11.21 model-win1%=11.31\n",
      "actions=(2,): 110 win=40 loss=70 draw=0 win1%=36.36 model-win1%=34.46\n",
      "actions=(3,): 140 win=76 loss=64 draw=0 win1%=54.29 model-win1%=55.73\n",
      "actions=(4,): 99083 win=97959 loss=1124 draw=0 win1%=98.87 model-win1%=98.23\n",
      "actions=(4, 5): 91826 win=91007 loss=819 draw=0 win1%=99.11 model-win1%=98.75\n",
      "actions=(5,): 244 win=183 loss=61 draw=0 win1%=75.00 model-win1%=74.13\n",
      "actions=(6,): 184 win=56 loss=128 draw=0 win1%=30.43 model-win1%=38.61\n",
      "actions=(7,): 132 win=20 loss=112 draw=0 win1%=15.15 model-win1%=14.38\n",
      "\n",
      "=== Generation 17 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9965/10000 [01:27<00:03, 10.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.003 seconds, size=36, eval-per-second=12507.86, total-batches=1000, mean-eval-per-second=28165.04, mean-time-per-batch=0.020, mean-batch-size=554.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:30<00:00, 111.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2974, train_policy_loss:0.2368, train_value_loss:0.0606, val:0.3073, val_policy_loss:0.2456, val_value_loss:0.0618\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-17/best.pt\n",
      "iter 0/176/30000: loss 0.2705, policy_loss:0.2398, value_loss:0.0307, time 4.25s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2905, policy_loss:0.2304, value_loss:0.0601, time 0.97s, iter_time: 40.60ms\n",
      "iter 400/528/30000: loss 0.2624, policy_loss:0.2214, value_loss:0.0410, time 2.07s, iter_time: 43.03ms\n",
      "iter 600/704/30000: loss 0.3071, policy_loss:0.2465, value_loss:0.0606, time 4.77s, iter_time: 66.27ms\n",
      "iter 800/880/30000: loss 0.2710, policy_loss:0.2198, value_loss:0.0511, time 4.32s, iter_time: 45.03ms\n",
      "step 1000: losses: train:0.2942, train_policy_loss:0.2354, train_value_loss:0.0588, val:0.3145, val_policy_loss:0.2470, val_value_loss:0.0676\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-17\n",
      "iter 1000/1056/30000: loss 0.3327, policy_loss:0.2594, value_loss:0.0733, time 9.83s, iter_time: 81.95ms\n",
      "iter 1200/1232/30000: loss 0.3242, policy_loss:0.2440, value_loss:0.0802, time 7.62s, iter_time: 52.93ms\n",
      "iter 1400/1408/30000: loss 0.2918, policy_loss:0.2484, value_loss:0.0434, time 7.57s, iter_time: 45.08ms\n",
      "iter 1600/1760/30000: loss 0.2894, policy_loss:0.2315, value_loss:0.0579, time 0.69s, iter_time: 42.95ms\n",
      "iter 1800/1936/30000: loss 0.2811, policy_loss:0.2265, value_loss:0.0546, time 2.07s, iter_time: 51.63ms\n",
      "step 2000: losses: train:0.2895, train_policy_loss:0.2325, train_value_loss:0.0570, val:0.3148, val_policy_loss:0.2457, val_value_loss:0.0691\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-17\n",
      "iter 2000/2112/30000: loss 0.2597, policy_loss:0.2200, value_loss:0.0397, time 7.98s, iter_time: 124.74ms\n",
      "iter 2200/2288/30000: loss 0.2954, policy_loss:0.2287, value_loss:0.0668, time 5.36s, iter_time: 60.91ms\n",
      "iter 2400/2464/30000: loss 0.3108, policy_loss:0.2351, value_loss:0.0757, time 5.04s, iter_time: 45.03ms\n",
      "iter 2600/2640/30000: loss 0.3089, policy_loss:0.2469, value_loss:0.0620, time 8.89s, iter_time: 65.39ms\n",
      "iter 2800/2816/30000: loss 0.3066, policy_loss:0.2388, value_loss:0.0679, time 6.63s, iter_time: 41.43ms\n",
      "step 3000: losses: train:0.2906, train_policy_loss:0.2313, train_value_loss:0.0593, val:0.3124, val_policy_loss:0.2443, val_value_loss:0.0681\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-17\n",
      "iter 3000/3168/30000: loss 0.2644, policy_loss:0.2277, value_loss:0.0367, time 4.73s, iter_time: 591.54ms\n",
      "iter 3200/3344/30000: loss 0.2567, policy_loss:0.2234, value_loss:0.0333, time 1.23s, iter_time: 38.36ms\n",
      "iter 3400/3520/30000: loss 0.2569, policy_loss:0.2190, value_loss:0.0379, time 3.20s, iter_time: 57.22ms\n",
      "iter 3600/3696/30000: loss 0.2947, policy_loss:0.2343, value_loss:0.0604, time 3.52s, iter_time: 44.02ms\n",
      "iter 3800/3872/30000: loss 0.2754, policy_loss:0.2179, value_loss:0.0574, time 4.35s, iter_time: 41.87ms\n",
      "step 4000: losses: train:0.2789, train_policy_loss:0.2257, train_value_loss:0.0532, val:0.3144, val_policy_loss:0.2450, val_value_loss:0.0694\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-17\n",
      "iter 4000/4048/30000: loss 0.2468, policy_loss:0.2237, value_loss:0.0232, time 14.57s, iter_time: 113.83ms\n",
      "iter 4200/4224/30000: loss 0.2693, policy_loss:0.2209, value_loss:0.0483, time 6.11s, iter_time: 40.20ms\n",
      "iter 4400/4576/30000: loss 0.2922, policy_loss:0.2363, value_loss:0.0559, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2962, policy_loss:0.2230, value_loss:0.0732, time 1.09s, iter_time: 45.24ms\n",
      "iter 4800/4928/30000: loss 0.2971, policy_loss:0.2300, value_loss:0.0671, time 1.86s, iter_time: 38.71ms\n",
      "step 5000: losses: train:0.2791, train_policy_loss:0.2258, train_value_loss:0.0533, val:0.3143, val_policy_loss:0.2442, val_value_loss:0.0701\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-17/best.pt (val_loss=0.3073)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-17.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 755545\n",
      "  Avg trajectory length: 7.56\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98429 loss=1571 draw=0 win1%=98.43 model-win1%=97.84\n",
      "actions=(1,): 101 win=12 loss=89 draw=0 win1%=11.88 model-win1%=11.31\n",
      "actions=(2,): 108 win=45 loss=63 draw=0 win1%=41.67 model-win1%=34.46\n",
      "actions=(3,): 137 win=71 loss=66 draw=0 win1%=51.82 model-win1%=55.73\n",
      "actions=(4,): 99095 win=98039 loss=1056 draw=0 win1%=98.93 model-win1%=98.23\n",
      "actions=(4, 5): 92445 win=91638 loss=807 draw=0 win1%=99.13 model-win1%=98.75\n",
      "actions=(5,): 256 win=181 loss=75 draw=0 win1%=70.70 model-win1%=74.13\n",
      "actions=(6,): 173 win=58 loss=115 draw=0 win1%=33.53 model-win1%=38.61\n",
      "actions=(7,): 130 win=23 loss=107 draw=0 win1%=17.69 model-win1%=14.38\n",
      "\n",
      "=== Generation 18 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9974/10000 [01:24<00:01, 19.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.003 seconds, size=31, eval-per-second=11318.19, total-batches=1000, mean-eval-per-second=32498.63, mean-time-per-batch=0.017, mean-batch-size=551.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:26<00:00, 115.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2913, train_policy_loss:0.2329, train_value_loss:0.0584, val:0.2862, val_policy_loss:0.2319, val_value_loss:0.0544\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18/best.pt\n",
      "iter 0/176/30000: loss 0.2954, policy_loss:0.2411, value_loss:0.0543, time 7.70s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2932, policy_loss:0.2371, value_loss:0.0561, time 1.02s, iter_time: 42.59ms\n",
      "iter 400/528/30000: loss 0.2746, policy_loss:0.2101, value_loss:0.0645, time 2.17s, iter_time: 45.13ms\n",
      "iter 600/704/30000: loss 0.2320, policy_loss:0.2064, value_loss:0.0256, time 7.37s, iter_time: 102.36ms\n",
      "iter 800/880/30000: loss 0.2770, policy_loss:0.2284, value_loss:0.0486, time 5.94s, iter_time: 61.82ms\n",
      "step 1000: losses: train:0.2881, train_policy_loss:0.2285, train_value_loss:0.0596, val:0.2900, val_policy_loss:0.2310, val_value_loss:0.0591\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 1000/1056/30000: loss 0.2389, policy_loss:0.2119, value_loss:0.0270, time 7.85s, iter_time: 65.39ms\n",
      "iter 1200/1232/30000: loss 0.3017, policy_loss:0.2384, value_loss:0.0633, time 9.26s, iter_time: 64.31ms\n",
      "iter 1400/1408/30000: loss 0.2696, policy_loss:0.2252, value_loss:0.0444, time 7.25s, iter_time: 43.18ms\n",
      "iter 1600/1760/30000: loss 0.2889, policy_loss:0.2243, value_loss:0.0645, time 0.66s, iter_time: 41.00ms\n",
      "iter 1800/1936/30000: loss 0.2688, policy_loss:0.2304, value_loss:0.0384, time 2.03s, iter_time: 50.81ms\n",
      "step 2000: losses: train:0.2831, train_policy_loss:0.2259, train_value_loss:0.0572, val:0.2888, val_policy_loss:0.2295, val_value_loss:0.0593\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 2000/2112/30000: loss 0.3155, policy_loss:0.2326, value_loss:0.0829, time 7.54s, iter_time: 117.86ms\n",
      "iter 2200/2288/30000: loss 0.2596, policy_loss:0.2237, value_loss:0.0359, time 3.57s, iter_time: 40.53ms\n",
      "iter 2400/2464/30000: loss 0.2740, policy_loss:0.2320, value_loss:0.0421, time 6.19s, iter_time: 55.24ms\n",
      "iter 2600/2640/30000: loss 0.3013, policy_loss:0.2315, value_loss:0.0697, time 5.82s, iter_time: 42.80ms\n",
      "iter 2800/2816/30000: loss 0.2712, policy_loss:0.2128, value_loss:0.0584, time 9.81s, iter_time: 61.34ms\n",
      "step 3000: losses: train:0.2783, train_policy_loss:0.2242, train_value_loss:0.0542, val:0.2872, val_policy_loss:0.2276, val_value_loss:0.0596\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 3000/3168/30000: loss 0.2662, policy_loss:0.2175, value_loss:0.0487, time 6.43s, iter_time: 804.25ms\n",
      "iter 3200/3344/30000: loss 0.2842, policy_loss:0.2204, value_loss:0.0639, time 1.43s, iter_time: 44.69ms\n",
      "iter 3400/3520/30000: loss 0.2910, policy_loss:0.2184, value_loss:0.0726, time 2.52s, iter_time: 44.99ms\n",
      "iter 3600/3696/30000: loss 0.2682, policy_loss:0.2291, value_loss:0.0391, time 3.38s, iter_time: 42.30ms\n",
      "iter 3800/3872/30000: loss 0.2939, policy_loss:0.2287, value_loss:0.0652, time 4.73s, iter_time: 45.53ms\n",
      "step 4000: losses: train:0.2708, train_policy_loss:0.2192, train_value_loss:0.0516, val:0.2854, val_policy_loss:0.2274, val_value_loss:0.0580\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 4000/4048/30000: loss 0.2664, policy_loss:0.2159, value_loss:0.0505, time 8.49s, iter_time: 66.35ms\n",
      "iter 4200/4224/30000: loss 0.2316, policy_loss:0.2095, value_loss:0.0222, time 10.64s, iter_time: 69.98ms\n",
      "iter 4400/4576/30000: loss 0.2987, policy_loss:0.2254, value_loss:0.0733, time 0.17s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2579, policy_loss:0.2089, value_loss:0.0490, time 2.74s, iter_time: 114.16ms\n",
      "iter 4800/4928/30000: loss 0.2982, policy_loss:0.2362, value_loss:0.0620, time 2.14s, iter_time: 44.66ms\n",
      "step 5000: losses: train:0.2701, train_policy_loss:0.2185, train_value_loss:0.0516, val:0.2878, val_policy_loss:0.2273, val_value_loss:0.0604\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 5000/5104/30000: loss 0.2781, policy_loss:0.2271, value_loss:0.0510, time 9.95s, iter_time: 138.13ms\n",
      "iter 5200/5280/30000: loss 0.2508, policy_loss:0.2123, value_loss:0.0386, time 3.73s, iter_time: 38.88ms\n",
      "iter 5400/5456/30000: loss 0.2588, policy_loss:0.2163, value_loss:0.0425, time 4.67s, iter_time: 38.95ms\n",
      "iter 5600/5632/30000: loss 0.2869, policy_loss:0.2208, value_loss:0.0661, time 5.63s, iter_time: 39.09ms\n",
      "iter 5800/5808/30000: loss 0.2540, policy_loss:0.2217, value_loss:0.0323, time 9.54s, iter_time: 56.81ms\n",
      "step 6000: losses: train:0.2694, train_policy_loss:0.2181, train_value_loss:0.0513, val:0.2892, val_policy_loss:0.2279, val_value_loss:0.0613\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 6000/6160/30000: loss 0.2430, policy_loss:0.2126, value_loss:0.0303, time 5.51s, iter_time: 344.67ms\n",
      "iter 6200/6336/30000: loss 0.2321, policy_loss:0.2029, value_loss:0.0292, time 1.84s, iter_time: 45.98ms\n",
      "iter 6400/6512/30000: loss 0.2972, policy_loss:0.2327, value_loss:0.0645, time 2.58s, iter_time: 40.32ms\n",
      "iter 6600/6688/30000: loss 0.2520, policy_loss:0.2097, value_loss:0.0422, time 3.45s, iter_time: 39.20ms\n",
      "iter 6800/6864/30000: loss 0.2601, policy_loss:0.2200, value_loss:0.0401, time 5.40s, iter_time: 48.21ms\n",
      "step 7000: losses: train:0.2686, train_policy_loss:0.2177, train_value_loss:0.0509, val:0.2884, val_policy_loss:0.2276, val_value_loss:0.0608\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 7000/7040/30000: loss 0.2756, policy_loss:0.2242, value_loss:0.0514, time 11.94s, iter_time: 87.77ms\n",
      "iter 7200/7216/30000: loss 0.2387, policy_loss:0.2069, value_loss:0.0318, time 6.75s, iter_time: 42.22ms\n",
      "iter 7400/7568/30000: loss 0.2757, policy_loss:0.2197, value_loss:0.0559, time 0.45s, iter_time: 56.50ms\n",
      "iter 7600/7744/30000: loss 0.2697, policy_loss:0.2202, value_loss:0.0495, time 1.60s, iter_time: 49.96ms\n",
      "iter 7800/7920/30000: loss 0.2409, policy_loss:0.2088, value_loss:0.0321, time 2.37s, iter_time: 42.35ms\n",
      "step 8000: losses: train:0.2693, train_policy_loss:0.2185, train_value_loss:0.0509, val:0.2900, val_policy_loss:0.2278, val_value_loss:0.0623\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18\n",
      "iter 8000/8096/30000: loss 0.2890, policy_loss:0.2246, value_loss:0.0645, time 9.56s, iter_time: 119.53ms\n",
      "iter 8200/8272/30000: loss 0.2922, policy_loss:0.2232, value_loss:0.0690, time 5.45s, iter_time: 52.41ms\n",
      "iter 8400/8448/30000: loss 0.2432, policy_loss:0.2172, value_loss:0.0260, time 5.11s, iter_time: 39.94ms\n",
      "iter 8600/8624/30000: loss 0.2537, policy_loss:0.2193, value_loss:0.0344, time 6.75s, iter_time: 44.40ms\n",
      "iter 8800/8976/30000: loss 0.2916, policy_loss:0.2129, value_loss:0.0788, time 0.06s, iter_time: 0.00ms\n",
      "step 9000: losses: train:0.2683, train_policy_loss:0.2178, train_value_loss:0.0505, val:0.2897, val_policy_loss:0.2282, val_value_loss:0.0614\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-18/best.pt (val_loss=0.2854)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-18.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 752404\n",
      "  Avg trajectory length: 7.52\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98508 loss=1492 draw=0 win1%=98.51 model-win1%=98.70\n",
      "actions=(1,): 99 win=10 loss=89 draw=0 win1%=10.10 model-win1%=18.65\n",
      "actions=(2,): 104 win=51 loss=53 draw=0 win1%=49.04 model-win1%=56.28\n",
      "actions=(3,): 136 win=75 loss=61 draw=0 win1%=55.15 model-win1%=58.06\n",
      "actions=(4,): 99114 win=98107 loss=1007 draw=0 win1%=98.98 model-win1%=99.03\n",
      "actions=(4, 5): 93175 win=92363 loss=812 draw=0 win1%=99.13 model-win1%=99.20\n",
      "actions=(5,): 274 win=183 loss=91 draw=0 win1%=66.79 model-win1%=72.30\n",
      "actions=(6,): 158 win=61 loss=97 draw=0 win1%=38.61 model-win1%=43.53\n",
      "actions=(7,): 115 win=21 loss=94 draw=0 win1%=18.26 model-win1%=16.73\n",
      "\n",
      "=== Generation 19 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9984/10000 [01:23<00:00, 22.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=17, eval-per-second=8768.22, total-batches=1000, mean-eval-per-second=29572.44, mean-time-per-batch=0.018, mean-batch-size=523.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:25<00:00, 116.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2661, train_policy_loss:0.2140, train_value_loss:0.0521, val:0.2619, val_policy_loss:0.2133, val_value_loss:0.0486\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-19/best.pt\n",
      "iter 0/176/30000: loss 0.2811, policy_loss:0.2223, value_loss:0.0588, time 3.22s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2752, policy_loss:0.2244, value_loss:0.0509, time 0.99s, iter_time: 41.32ms\n",
      "iter 400/528/30000: loss 0.2754, policy_loss:0.2089, value_loss:0.0665, time 2.17s, iter_time: 45.18ms\n",
      "iter 600/704/30000: loss 0.2635, policy_loss:0.2131, value_loss:0.0504, time 2.86s, iter_time: 39.74ms\n",
      "iter 800/880/30000: loss 0.2376, policy_loss:0.2114, value_loss:0.0262, time 3.94s, iter_time: 41.03ms\n",
      "step 1000: losses: train:0.2729, train_policy_loss:0.2183, train_value_loss:0.0547, val:0.2738, val_policy_loss:0.2198, val_value_loss:0.0539\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-19\n",
      "iter 1000/1056/30000: loss 0.2803, policy_loss:0.2283, value_loss:0.0520, time 11.00s, iter_time: 91.63ms\n",
      "iter 1200/1232/30000: loss 0.2926, policy_loss:0.2203, value_loss:0.0723, time 5.88s, iter_time: 40.81ms\n",
      "iter 1400/1408/30000: loss 0.2323, policy_loss:0.2068, value_loss:0.0255, time 7.00s, iter_time: 41.66ms\n",
      "iter 1600/1760/30000: loss 0.2960, policy_loss:0.2291, value_loss:0.0669, time 0.68s, iter_time: 42.40ms\n",
      "iter 1800/1936/30000: loss 0.2642, policy_loss:0.2171, value_loss:0.0471, time 2.98s, iter_time: 74.47ms\n",
      "step 2000: losses: train:0.2676, train_policy_loss:0.2154, train_value_loss:0.0522, val:0.2760, val_policy_loss:0.2201, val_value_loss:0.0559\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-19\n",
      "iter 2000/2112/30000: loss 0.2843, policy_loss:0.2174, value_loss:0.0670, time 5.37s, iter_time: 83.87ms\n",
      "iter 2200/2288/30000: loss 0.2482, policy_loss:0.2131, value_loss:0.0351, time 3.46s, iter_time: 39.30ms\n",
      "iter 2400/2464/30000: loss 0.2283, policy_loss:0.2041, value_loss:0.0242, time 4.76s, iter_time: 42.51ms\n",
      "iter 2600/2640/30000: loss 0.2415, policy_loss:0.2088, value_loss:0.0327, time 6.27s, iter_time: 46.08ms\n",
      "iter 2800/2816/30000: loss 0.3261, policy_loss:0.2224, value_loss:0.1037, time 6.64s, iter_time: 41.48ms\n",
      "step 3000: losses: train:0.2641, train_policy_loss:0.2136, train_value_loss:0.0504, val:0.2745, val_policy_loss:0.2189, val_value_loss:0.0556\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-19\n",
      "iter 3000/3168/30000: loss 0.2861, policy_loss:0.2105, value_loss:0.0755, time 5.49s, iter_time: 686.05ms\n",
      "iter 3200/3344/30000: loss 0.2303, policy_loss:0.2074, value_loss:0.0229, time 1.30s, iter_time: 40.56ms\n",
      "iter 3400/3520/30000: loss 0.2708, policy_loss:0.2206, value_loss:0.0502, time 2.18s, iter_time: 38.87ms\n",
      "iter 3600/3696/30000: loss 0.2668, policy_loss:0.2188, value_loss:0.0480, time 3.34s, iter_time: 41.77ms\n",
      "iter 3800/3872/30000: loss 0.3213, policy_loss:0.2215, value_loss:0.0998, time 4.43s, iter_time: 42.59ms\n",
      "step 4000: losses: train:0.2601, train_policy_loss:0.2111, train_value_loss:0.0489, val:0.2766, val_policy_loss:0.2192, val_value_loss:0.0573\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-19\n",
      "iter 4000/4048/30000: loss 0.2674, policy_loss:0.2245, value_loss:0.0429, time 13.00s, iter_time: 101.55ms\n",
      "iter 4200/4224/30000: loss 0.2645, policy_loss:0.2160, value_loss:0.0485, time 6.66s, iter_time: 43.81ms\n",
      "iter 4400/4576/30000: loss 0.2565, policy_loss:0.2222, value_loss:0.0343, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2508, policy_loss:0.2060, value_loss:0.0448, time 0.92s, iter_time: 38.38ms\n",
      "iter 4800/4928/30000: loss 0.2674, policy_loss:0.2176, value_loss:0.0498, time 2.45s, iter_time: 51.01ms\n",
      "step 5000: losses: train:0.2567, train_policy_loss:0.2089, train_value_loss:0.0478, val:0.2778, val_policy_loss:0.2196, val_value_loss:0.0582\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-19/best.pt (val_loss=0.2619)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-19.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 748798\n",
      "  Avg trajectory length: 7.49\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98602 loss=1398 draw=0 win1%=98.60 model-win1%=98.70\n",
      "actions=(1,): 100 win=15 loss=85 draw=0 win1%=15.00 model-win1%=18.65\n",
      "actions=(2,): 104 win=60 loss=44 draw=0 win1%=57.69 model-win1%=56.28\n",
      "actions=(3,): 126 win=66 loss=60 draw=0 win1%=52.38 model-win1%=58.06\n",
      "actions=(4,): 99156 win=98198 loss=958 draw=0 win1%=99.03 model-win1%=99.03\n",
      "actions=(4, 5): 93876 win=93069 loss=807 draw=0 win1%=99.14 model-win1%=99.20\n",
      "actions=(5,): 268 win=171 loss=97 draw=0 win1%=63.81 model-win1%=72.30\n",
      "actions=(6,): 138 win=69 loss=69 draw=0 win1%=50.00 model-win1%=43.53\n",
      "actions=(7,): 108 win=23 loss=85 draw=0 win1%=21.30 model-win1%=16.73\n",
      "\n",
      "=== Generation 20 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9989/10000 [01:23<00:00, 28.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=18, eval-per-second=10453.82, total-batches=1000, mean-eval-per-second=29048.53, mean-time-per-batch=0.018, mean-batch-size=517.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:24<00:00, 117.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 20...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2544, train_policy_loss:0.2052, train_value_loss:0.0492, val:0.2599, val_policy_loss:0.2086, val_value_loss:0.0513\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-20/best.pt\n",
      "iter 0/176/30000: loss 0.2722, policy_loss:0.2013, value_loss:0.0709, time 6.62s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2376, policy_loss:0.1939, value_loss:0.0437, time 1.00s, iter_time: 41.72ms\n",
      "iter 400/528/30000: loss 0.2706, policy_loss:0.2144, value_loss:0.0562, time 2.38s, iter_time: 49.67ms\n",
      "iter 600/704/30000: loss 0.2904, policy_loss:0.2180, value_loss:0.0724, time 6.34s, iter_time: 88.05ms\n",
      "iter 800/880/30000: loss 0.2496, policy_loss:0.2052, value_loss:0.0444, time 8.45s, iter_time: 88.04ms\n",
      "step 1000: losses: train:0.2557, train_policy_loss:0.2073, train_value_loss:0.0484, val:0.2697, val_policy_loss:0.2143, val_value_loss:0.0554\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-20\n",
      "iter 1000/1056/30000: loss 0.2542, policy_loss:0.2028, value_loss:0.0514, time 8.79s, iter_time: 73.26ms\n",
      "iter 1200/1232/30000: loss 0.2530, policy_loss:0.2172, value_loss:0.0358, time 6.33s, iter_time: 43.98ms\n",
      "iter 1400/1408/30000: loss 0.2533, policy_loss:0.1976, value_loss:0.0558, time 8.88s, iter_time: 52.85ms\n",
      "iter 1600/1760/30000: loss 0.2888, policy_loss:0.2235, value_loss:0.0652, time 0.64s, iter_time: 39.82ms\n",
      "iter 1800/1936/30000: loss 0.2937, policy_loss:0.2094, value_loss:0.0843, time 2.38s, iter_time: 59.62ms\n",
      "step 2000: losses: train:0.2552, train_policy_loss:0.2066, train_value_loss:0.0486, val:0.2723, val_policy_loss:0.2139, val_value_loss:0.0584\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-20\n",
      "iter 2000/2112/30000: loss 0.2130, policy_loss:0.1908, value_loss:0.0222, time 5.36s, iter_time: 83.80ms\n",
      "iter 2200/2288/30000: loss 0.2516, policy_loss:0.2101, value_loss:0.0415, time 3.56s, iter_time: 40.42ms\n",
      "iter 2400/2464/30000: loss 0.2652, policy_loss:0.2099, value_loss:0.0553, time 5.10s, iter_time: 45.55ms\n",
      "iter 2600/2640/30000: loss 0.2662, policy_loss:0.2069, value_loss:0.0593, time 8.19s, iter_time: 60.24ms\n",
      "iter 2800/2816/30000: loss 0.2439, policy_loss:0.1990, value_loss:0.0449, time 6.88s, iter_time: 42.97ms\n",
      "step 3000: losses: train:0.2499, train_policy_loss:0.2029, train_value_loss:0.0470, val:0.2724, val_policy_loss:0.2132, val_value_loss:0.0592\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-20\n",
      "iter 3000/3168/30000: loss 0.2847, policy_loss:0.2142, value_loss:0.0705, time 5.66s, iter_time: 707.22ms\n",
      "iter 3200/3344/30000: loss 0.2455, policy_loss:0.1974, value_loss:0.0481, time 2.05s, iter_time: 64.03ms\n",
      "iter 3400/3520/30000: loss 0.2127, policy_loss:0.1911, value_loss:0.0216, time 2.34s, iter_time: 41.79ms\n",
      "iter 3600/3696/30000: loss 0.2430, policy_loss:0.1969, value_loss:0.0461, time 3.47s, iter_time: 43.36ms\n",
      "iter 3800/3872/30000: loss 0.2383, policy_loss:0.2014, value_loss:0.0368, time 4.54s, iter_time: 43.69ms\n",
      "step 4000: losses: train:0.2454, train_policy_loss:0.2005, train_value_loss:0.0449, val:0.2729, val_policy_loss:0.2126, val_value_loss:0.0604\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-20\n",
      "iter 4000/4048/30000: loss 0.2250, policy_loss:0.1958, value_loss:0.0292, time 11.93s, iter_time: 93.19ms\n",
      "iter 4200/4224/30000: loss 0.2552, policy_loss:0.2094, value_loss:0.0458, time 7.49s, iter_time: 49.28ms\n",
      "iter 4400/4576/30000: loss 0.2070, policy_loss:0.1908, value_loss:0.0162, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2544, policy_loss:0.2018, value_loss:0.0526, time 0.95s, iter_time: 39.64ms\n",
      "iter 4800/4928/30000: loss 0.2502, policy_loss:0.1962, value_loss:0.0540, time 2.46s, iter_time: 51.17ms\n",
      "step 5000: losses: train:0.2425, train_policy_loss:0.1991, train_value_loss:0.0435, val:0.2742, val_policy_loss:0.2126, val_value_loss:0.0616\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-20/best.pt (val_loss=0.2599)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-20.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 745011\n",
      "  Avg trajectory length: 7.45\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98689 loss=1311 draw=0 win1%=98.69 model-win1%=98.70\n",
      "actions=(1,): 110 win=24 loss=86 draw=0 win1%=21.82 model-win1%=18.65\n",
      "actions=(2,): 98 win=62 loss=36 draw=0 win1%=63.27 model-win1%=56.28\n",
      "actions=(3,): 116 win=58 loss=58 draw=0 win1%=50.00 model-win1%=58.06\n",
      "actions=(4,): 99192 win=98290 loss=902 draw=0 win1%=99.09 model-win1%=99.03\n",
      "actions=(4, 5): 94633 win=93838 loss=795 draw=0 win1%=99.16 model-win1%=99.20\n",
      "actions=(5,): 261 win=155 loss=106 draw=0 win1%=59.39 model-win1%=72.30\n",
      "actions=(6,): 120 win=75 loss=45 draw=0 win1%=62.50 model-win1%=43.53\n",
      "actions=(7,): 103 win=25 loss=78 draw=0 win1%=24.27 model-win1%=16.73\n",
      "\n",
      "=== Generation 21 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9972/10000 [01:22<00:01, 20.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.004 seconds, size=28, eval-per-second=7442.84, total-batches=1000, mean-eval-per-second=33605.65, mean-time-per-batch=0.016, mean-batch-size=528.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:24<00:00, 118.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 21...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2475, train_policy_loss:0.1994, train_value_loss:0.0482, val:0.2398, val_policy_loss:0.1979, val_value_loss:0.0419\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-21/best.pt\n",
      "iter 0/176/30000: loss 0.2385, policy_loss:0.1948, value_loss:0.0436, time 7.40s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2207, policy_loss:0.1876, value_loss:0.0331, time 1.12s, iter_time: 46.66ms\n",
      "iter 400/528/30000: loss 0.2176, policy_loss:0.1848, value_loss:0.0328, time 1.89s, iter_time: 39.34ms\n",
      "iter 600/704/30000: loss 0.2308, policy_loss:0.1835, value_loss:0.0472, time 2.91s, iter_time: 40.38ms\n",
      "iter 800/880/30000: loss 0.2676, policy_loss:0.1999, value_loss:0.0677, time 6.47s, iter_time: 67.42ms\n",
      "step 1000: losses: train:0.2466, train_policy_loss:0.1994, train_value_loss:0.0472, val:0.2511, val_policy_loss:0.2027, val_value_loss:0.0484\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-21\n",
      "iter 1000/1056/30000: loss 0.2294, policy_loss:0.1937, value_loss:0.0357, time 12.10s, iter_time: 100.84ms\n",
      "iter 1200/1232/30000: loss 0.2227, policy_loss:0.2012, value_loss:0.0215, time 5.74s, iter_time: 39.88ms\n",
      "iter 1400/1408/30000: loss 0.2221, policy_loss:0.1949, value_loss:0.0272, time 6.79s, iter_time: 40.42ms\n",
      "iter 1600/1760/30000: loss 0.2139, policy_loss:0.1876, value_loss:0.0263, time 0.87s, iter_time: 54.36ms\n",
      "iter 1800/1936/30000: loss 0.2316, policy_loss:0.1926, value_loss:0.0390, time 1.65s, iter_time: 41.37ms\n",
      "step 2000: losses: train:0.2405, train_policy_loss:0.1952, train_value_loss:0.0453, val:0.2466, val_policy_loss:0.2000, val_value_loss:0.0466\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-21\n",
      "iter 2000/2112/30000: loss 0.2184, policy_loss:0.1830, value_loss:0.0354, time 10.57s, iter_time: 165.14ms\n",
      "iter 2200/2288/30000: loss 0.2723, policy_loss:0.2037, value_loss:0.0686, time 4.14s, iter_time: 47.05ms\n",
      "iter 2400/2464/30000: loss 0.2488, policy_loss:0.2104, value_loss:0.0384, time 5.06s, iter_time: 45.17ms\n",
      "iter 2600/2640/30000: loss 0.2176, policy_loss:0.1887, value_loss:0.0290, time 5.54s, iter_time: 40.77ms\n",
      "iter 2800/2816/30000: loss 0.2468, policy_loss:0.1951, value_loss:0.0517, time 7.60s, iter_time: 47.49ms\n",
      "step 3000: losses: train:0.2405, train_policy_loss:0.1948, train_value_loss:0.0457, val:0.2445, val_policy_loss:0.1988, val_value_loss:0.0457\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-21\n",
      "iter 3000/3168/30000: loss 0.2385, policy_loss:0.1997, value_loss:0.0389, time 7.81s, iter_time: 975.71ms\n",
      "iter 3200/3344/30000: loss 0.2497, policy_loss:0.2072, value_loss:0.0425, time 1.24s, iter_time: 38.78ms\n",
      "iter 3400/3520/30000: loss 0.2526, policy_loss:0.1985, value_loss:0.0541, time 2.38s, iter_time: 42.48ms\n",
      "iter 3600/3696/30000: loss 0.2255, policy_loss:0.1904, value_loss:0.0351, time 3.53s, iter_time: 44.09ms\n",
      "iter 3800/3872/30000: loss 0.2135, policy_loss:0.1872, value_loss:0.0263, time 5.16s, iter_time: 49.64ms\n",
      "step 4000: losses: train:0.2356, train_policy_loss:0.1914, train_value_loss:0.0442, val:0.2434, val_policy_loss:0.1987, val_value_loss:0.0447\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-21\n",
      "iter 4000/4048/30000: loss 0.2668, policy_loss:0.1957, value_loss:0.0712, time 12.08s, iter_time: 94.37ms\n",
      "iter 4200/4224/30000: loss 0.2379, policy_loss:0.1942, value_loss:0.0437, time 6.23s, iter_time: 41.00ms\n",
      "iter 4400/4576/30000: loss 0.2423, policy_loss:0.2048, value_loss:0.0376, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2288, policy_loss:0.1848, value_loss:0.0440, time 0.93s, iter_time: 38.62ms\n",
      "iter 4800/4928/30000: loss 0.2654, policy_loss:0.1981, value_loss:0.0673, time 2.38s, iter_time: 49.57ms\n",
      "step 5000: losses: train:0.2310, train_policy_loss:0.1900, train_value_loss:0.0410, val:0.2453, val_policy_loss:0.1989, val_value_loss:0.0464\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-21/best.pt (val_loss=0.2398)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-21.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 741828\n",
      "  Avg trajectory length: 7.42\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98778 loss=1222 draw=0 win1%=98.78 model-win1%=98.70\n",
      "actions=(1,): 103 win=28 loss=75 draw=0 win1%=27.18 model-win1%=18.65\n",
      "actions=(2,): 105 win=72 loss=33 draw=0 win1%=68.57 model-win1%=56.28\n",
      "actions=(3,): 112 win=49 loss=63 draw=0 win1%=43.75 model-win1%=58.06\n",
      "actions=(4,): 99195 win=98358 loss=837 draw=0 win1%=99.16 model-win1%=99.03\n",
      "actions=(4, 5): 95296 win=94519 loss=777 draw=0 win1%=99.18 model-win1%=99.20\n",
      "actions=(5,): 271 win=160 loss=111 draw=0 win1%=59.04 model-win1%=72.30\n",
      "actions=(6,): 116 win=83 loss=33 draw=0 win1%=71.55 model-win1%=43.53\n",
      "actions=(7,): 98 win=28 loss=70 draw=0 win1%=28.57 model-win1%=16.73\n",
      "\n",
      "=== Generation 22 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9987/10000 [01:20<00:01, 10.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=12, eval-per-second=6868.40, total-batches=1000, mean-eval-per-second=34216.76, mean-time-per-batch=0.015, mean-batch-size=517.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:22<00:00, 120.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 22...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2474, train_policy_loss:0.1991, train_value_loss:0.0483, val:0.2441, val_policy_loss:0.1934, val_value_loss:0.0508\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22/best.pt\n",
      "iter 0/176/30000: loss 0.2539, policy_loss:0.2059, value_loss:0.0480, time 7.53s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2375, policy_loss:0.1990, value_loss:0.0385, time 1.53s, iter_time: 63.59ms\n",
      "iter 400/528/30000: loss 0.2325, policy_loss:0.1881, value_loss:0.0444, time 2.54s, iter_time: 52.83ms\n",
      "iter 600/704/30000: loss 0.2350, policy_loss:0.1934, value_loss:0.0416, time 3.25s, iter_time: 45.20ms\n",
      "iter 800/880/30000: loss 0.2331, policy_loss:0.1918, value_loss:0.0413, time 4.28s, iter_time: 44.59ms\n",
      "step 1000: losses: train:0.2428, train_policy_loss:0.1965, train_value_loss:0.0463, val:0.2432, val_policy_loss:0.1936, val_value_loss:0.0496\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 1000/1056/30000: loss 0.2338, policy_loss:0.2012, value_loss:0.0327, time 10.16s, iter_time: 84.63ms\n",
      "iter 1200/1232/30000: loss 0.2544, policy_loss:0.2013, value_loss:0.0530, time 7.17s, iter_time: 49.76ms\n",
      "iter 1400/1408/30000: loss 0.2489, policy_loss:0.2054, value_loss:0.0435, time 6.90s, iter_time: 41.05ms\n",
      "iter 1600/1760/30000: loss 0.2205, policy_loss:0.1920, value_loss:0.0285, time 0.79s, iter_time: 49.42ms\n",
      "iter 1800/1936/30000: loss 0.2103, policy_loss:0.1815, value_loss:0.0288, time 1.75s, iter_time: 43.85ms\n",
      "step 2000: losses: train:0.2363, train_policy_loss:0.1923, train_value_loss:0.0440, val:0.2429, val_policy_loss:0.1928, val_value_loss:0.0500\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 2000/2112/30000: loss 0.2304, policy_loss:0.1907, value_loss:0.0397, time 10.03s, iter_time: 156.79ms\n",
      "iter 2200/2288/30000: loss 0.2275, policy_loss:0.1994, value_loss:0.0281, time 4.44s, iter_time: 50.44ms\n",
      "iter 2400/2464/30000: loss 0.2413, policy_loss:0.1892, value_loss:0.0521, time 5.00s, iter_time: 44.62ms\n",
      "iter 2600/2640/30000: loss 0.2595, policy_loss:0.1979, value_loss:0.0616, time 8.18s, iter_time: 60.15ms\n",
      "iter 2800/2816/30000: loss 0.2273, policy_loss:0.1867, value_loss:0.0406, time 6.67s, iter_time: 41.69ms\n",
      "step 3000: losses: train:0.2320, train_policy_loss:0.1896, train_value_loss:0.0424, val:0.2414, val_policy_loss:0.1915, val_value_loss:0.0499\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 3000/3168/30000: loss 0.2529, policy_loss:0.1935, value_loss:0.0594, time 6.23s, iter_time: 778.21ms\n",
      "iter 3200/3344/30000: loss 0.2255, policy_loss:0.1944, value_loss:0.0311, time 1.24s, iter_time: 38.83ms\n",
      "iter 3400/3520/30000: loss 0.2609, policy_loss:0.1995, value_loss:0.0614, time 2.34s, iter_time: 41.82ms\n",
      "iter 3600/3696/30000: loss 0.2200, policy_loss:0.1784, value_loss:0.0416, time 3.62s, iter_time: 45.20ms\n",
      "iter 3800/3872/30000: loss 0.2565, policy_loss:0.1938, value_loss:0.0627, time 4.04s, iter_time: 38.86ms\n",
      "step 4000: losses: train:0.2295, train_policy_loss:0.1874, train_value_loss:0.0421, val:0.2440, val_policy_loss:0.1910, val_value_loss:0.0530\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 4000/4048/30000: loss 0.2013, policy_loss:0.1792, value_loss:0.0222, time 10.23s, iter_time: 79.94ms\n",
      "iter 4200/4224/30000: loss 0.2217, policy_loss:0.1874, value_loss:0.0342, time 6.97s, iter_time: 45.88ms\n",
      "iter 4400/4576/30000: loss 0.1959, policy_loss:0.1788, value_loss:0.0171, time 0.06s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2073, policy_loss:0.1833, value_loss:0.0240, time 1.34s, iter_time: 55.65ms\n",
      "iter 4800/4928/30000: loss 0.2290, policy_loss:0.1916, value_loss:0.0374, time 2.30s, iter_time: 47.84ms\n",
      "step 5000: losses: train:0.2274, train_policy_loss:0.1865, train_value_loss:0.0409, val:0.2409, val_policy_loss:0.1904, val_value_loss:0.0505\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 5000/5104/30000: loss 0.2301, policy_loss:0.1867, value_loss:0.0433, time 6.19s, iter_time: 85.99ms\n",
      "iter 5200/5280/30000: loss 0.2262, policy_loss:0.1814, value_loss:0.0448, time 4.26s, iter_time: 44.34ms\n",
      "iter 5400/5456/30000: loss 0.2219, policy_loss:0.1947, value_loss:0.0273, time 4.91s, iter_time: 40.93ms\n",
      "iter 5600/5632/30000: loss 0.2672, policy_loss:0.1870, value_loss:0.0802, time 6.55s, iter_time: 45.45ms\n",
      "iter 5800/5808/30000: loss 0.2212, policy_loss:0.1839, value_loss:0.0373, time 8.81s, iter_time: 52.43ms\n",
      "step 6000: losses: train:0.2278, train_policy_loss:0.1863, train_value_loss:0.0416, val:0.2420, val_policy_loss:0.1905, val_value_loss:0.0515\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 6000/6160/30000: loss 0.2341, policy_loss:0.1883, value_loss:0.0458, time 7.65s, iter_time: 477.92ms\n",
      "iter 6200/6336/30000: loss 0.2129, policy_loss:0.1846, value_loss:0.0282, time 1.72s, iter_time: 43.02ms\n",
      "iter 6400/6512/30000: loss 0.2175, policy_loss:0.1862, value_loss:0.0313, time 2.80s, iter_time: 43.78ms\n",
      "iter 6600/6688/30000: loss 0.2350, policy_loss:0.1865, value_loss:0.0484, time 6.38s, iter_time: 72.51ms\n",
      "iter 6800/6864/30000: loss 0.2008, policy_loss:0.1793, value_loss:0.0215, time 4.49s, iter_time: 40.06ms\n",
      "step 7000: losses: train:0.2288, train_policy_loss:0.1868, train_value_loss:0.0420, val:0.2415, val_policy_loss:0.1904, val_value_loss:0.0510\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 7000/7040/30000: loss 0.2422, policy_loss:0.1856, value_loss:0.0566, time 11.22s, iter_time: 82.47ms\n",
      "iter 7200/7216/30000: loss 0.2189, policy_loss:0.1838, value_loss:0.0351, time 7.00s, iter_time: 43.74ms\n",
      "iter 7400/7568/30000: loss 0.2394, policy_loss:0.1887, value_loss:0.0508, time 0.33s, iter_time: 41.75ms\n",
      "iter 7600/7744/30000: loss 0.1983, policy_loss:0.1811, value_loss:0.0172, time 1.36s, iter_time: 42.48ms\n",
      "iter 7800/7920/30000: loss 0.2179, policy_loss:0.1893, value_loss:0.0286, time 2.22s, iter_time: 39.65ms\n",
      "step 8000: losses: train:0.2255, train_policy_loss:0.1859, train_value_loss:0.0397, val:0.2436, val_policy_loss:0.1908, val_value_loss:0.0528\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 8000/8096/30000: loss 0.2157, policy_loss:0.1890, value_loss:0.0267, time 6.84s, iter_time: 85.47ms\n",
      "iter 8200/8272/30000: loss 0.2372, policy_loss:0.1971, value_loss:0.0400, time 4.77s, iter_time: 45.82ms\n",
      "iter 8400/8448/30000: loss 0.2574, policy_loss:0.1924, value_loss:0.0650, time 5.39s, iter_time: 42.07ms\n",
      "iter 8600/8624/30000: loss 0.2443, policy_loss:0.1876, value_loss:0.0567, time 6.39s, iter_time: 42.03ms\n",
      "iter 8800/8976/30000: loss 0.2388, policy_loss:0.1915, value_loss:0.0473, time 0.04s, iter_time: 0.00ms\n",
      "step 9000: losses: train:0.2283, train_policy_loss:0.1865, train_value_loss:0.0417, val:0.2423, val_policy_loss:0.1905, val_value_loss:0.0518\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22\n",
      "iter 9000/9152/30000: loss 0.2352, policy_loss:0.1821, value_loss:0.0531, time 9.97s, iter_time: 415.50ms\n",
      "iter 9200/9328/30000: loss 0.2149, policy_loss:0.1873, value_loss:0.0277, time 1.98s, iter_time: 41.31ms\n",
      "iter 9400/9504/30000: loss 0.2536, policy_loss:0.1834, value_loss:0.0702, time 3.09s, iter_time: 42.90ms\n",
      "iter 9600/9680/30000: loss 0.2450, policy_loss:0.1895, value_loss:0.0554, time 4.02s, iter_time: 41.88ms\n",
      "iter 9800/9856/30000: loss 0.1990, policy_loss:0.1769, value_loss:0.0222, time 4.88s, iter_time: 40.69ms\n",
      "step 10000: losses: train:0.2273, train_policy_loss:0.1864, train_value_loss:0.0410, val:0.2420, val_policy_loss:0.1908, val_value_loss:0.0512\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-22/best.pt (val_loss=0.2409)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-22.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 740065\n",
      "  Avg trajectory length: 7.40\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98797 loss=1203 draw=0 win1%=98.80 model-win1%=98.73\n",
      "actions=(1,): 99 win=35 loss=64 draw=0 win1%=35.35 model-win1%=30.55\n",
      "actions=(2,): 115 win=88 loss=27 draw=0 win1%=76.52 model-win1%=70.91\n",
      "actions=(3,): 118 win=45 loss=73 draw=0 win1%=38.14 model-win1%=35.25\n",
      "actions=(4,): 99180 win=98347 loss=833 draw=0 win1%=99.16 model-win1%=99.10\n",
      "actions=(4, 5): 95472 win=94692 loss=780 draw=0 win1%=99.18 model-win1%=99.13\n",
      "actions=(5,): 277 win=165 loss=112 draw=0 win1%=59.57 model-win1%=51.59\n",
      "actions=(6,): 110 win=80 loss=30 draw=0 win1%=72.73 model-win1%=67.69\n",
      "actions=(7,): 101 win=37 loss=64 draw=0 win1%=36.63 model-win1%=29.98\n",
      "\n",
      "=== Generation 23 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9993/10000 [01:20<00:00, 17.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=8, eval-per-second=5214.36, total-batches=1000, mean-eval-per-second=33764.19, mean-time-per-batch=0.015, mean-batch-size=511.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:22<00:00, 121.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 23...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2267, train_policy_loss:0.1846, train_value_loss:0.0421, val:0.2233, val_policy_loss:0.1833, val_value_loss:0.0401\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-23/best.pt\n",
      "iter 0/176/30000: loss 0.2435, policy_loss:0.1971, value_loss:0.0464, time 6.87s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2222, policy_loss:0.1909, value_loss:0.0313, time 1.70s, iter_time: 70.67ms\n",
      "iter 400/528/30000: loss 0.2156, policy_loss:0.1777, value_loss:0.0379, time 2.40s, iter_time: 49.94ms\n",
      "iter 600/704/30000: loss 0.2224, policy_loss:0.1853, value_loss:0.0371, time 7.94s, iter_time: 110.25ms\n",
      "iter 800/880/30000: loss 0.2373, policy_loss:0.1942, value_loss:0.0431, time 3.98s, iter_time: 41.43ms\n",
      "step 1000: losses: train:0.2328, train_policy_loss:0.1894, train_value_loss:0.0434, val:0.2339, val_policy_loss:0.1891, val_value_loss:0.0448\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-23\n",
      "iter 1000/1056/30000: loss 0.2267, policy_loss:0.1800, value_loss:0.0467, time 12.92s, iter_time: 107.66ms\n",
      "iter 1200/1232/30000: loss 0.2225, policy_loss:0.1946, value_loss:0.0279, time 6.20s, iter_time: 43.08ms\n",
      "iter 1400/1408/30000: loss 0.2087, policy_loss:0.1829, value_loss:0.0258, time 7.03s, iter_time: 41.84ms\n",
      "iter 1600/1760/30000: loss 0.2081, policy_loss:0.1793, value_loss:0.0288, time 0.74s, iter_time: 45.94ms\n",
      "iter 1800/1936/30000: loss 0.2034, policy_loss:0.1769, value_loss:0.0265, time 1.71s, iter_time: 42.81ms\n",
      "step 2000: losses: train:0.2321, train_policy_loss:0.1882, train_value_loss:0.0439, val:0.2357, val_policy_loss:0.1895, val_value_loss:0.0462\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-23\n",
      "iter 2000/2112/30000: loss 0.2008, policy_loss:0.1801, value_loss:0.0207, time 7.90s, iter_time: 123.49ms\n",
      "iter 2200/2288/30000: loss 0.2466, policy_loss:0.1925, value_loss:0.0541, time 3.56s, iter_time: 40.42ms\n",
      "iter 2400/2464/30000: loss 0.2418, policy_loss:0.1919, value_loss:0.0499, time 4.56s, iter_time: 40.69ms\n",
      "iter 2600/2640/30000: loss 0.2338, policy_loss:0.1803, value_loss:0.0535, time 5.55s, iter_time: 40.80ms\n",
      "iter 2800/2816/30000: loss 0.2113, policy_loss:0.1827, value_loss:0.0286, time 7.16s, iter_time: 44.75ms\n",
      "step 3000: losses: train:0.2245, train_policy_loss:0.1850, train_value_loss:0.0395, val:0.2352, val_policy_loss:0.1886, val_value_loss:0.0466\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-23\n",
      "iter 3000/3168/30000: loss 0.2096, policy_loss:0.1838, value_loss:0.0258, time 4.48s, iter_time: 559.96ms\n",
      "iter 3200/3344/30000: loss 0.2315, policy_loss:0.1897, value_loss:0.0417, time 1.23s, iter_time: 38.34ms\n",
      "iter 3400/3520/30000: loss 0.2492, policy_loss:0.1929, value_loss:0.0564, time 2.37s, iter_time: 42.32ms\n",
      "iter 3600/3696/30000: loss 0.2256, policy_loss:0.1788, value_loss:0.0467, time 3.19s, iter_time: 39.94ms\n",
      "iter 3800/3872/30000: loss 0.2903, policy_loss:0.2056, value_loss:0.0847, time 4.05s, iter_time: 38.98ms\n",
      "step 4000: losses: train:0.2223, train_policy_loss:0.1828, train_value_loss:0.0395, val:0.2318, val_policy_loss:0.1867, val_value_loss:0.0451\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-23\n",
      "iter 4000/4048/30000: loss 0.1951, policy_loss:0.1791, value_loss:0.0159, time 10.51s, iter_time: 82.14ms\n",
      "iter 4200/4224/30000: loss 0.2386, policy_loss:0.1866, value_loss:0.0521, time 6.35s, iter_time: 41.78ms\n",
      "iter 4400/4576/30000: loss 0.2225, policy_loss:0.1893, value_loss:0.0332, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2377, policy_loss:0.1805, value_loss:0.0572, time 1.01s, iter_time: 42.06ms\n",
      "iter 4800/4928/30000: loss 0.2146, policy_loss:0.1798, value_loss:0.0349, time 1.83s, iter_time: 38.20ms\n",
      "step 5000: losses: train:0.2240, train_policy_loss:0.1830, train_value_loss:0.0410, val:0.2328, val_policy_loss:0.1873, val_value_loss:0.0455\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-23/best.pt (val_loss=0.2233)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-23.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 738163\n",
      "  Avg trajectory length: 7.38\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98827 loss=1173 draw=0 win1%=98.83 model-win1%=98.73\n",
      "actions=(1,): 104 win=36 loss=68 draw=0 win1%=34.62 model-win1%=30.55\n",
      "actions=(2,): 132 win=91 loss=41 draw=0 win1%=68.94 model-win1%=70.91\n",
      "actions=(3,): 115 win=43 loss=72 draw=0 win1%=37.39 model-win1%=35.25\n",
      "actions=(4,): 99158 win=98374 loss=784 draw=0 win1%=99.21 model-win1%=99.10\n",
      "actions=(4, 5): 95624 win=94880 loss=744 draw=0 win1%=99.22 model-win1%=99.13\n",
      "actions=(5,): 276 win=165 loss=111 draw=0 win1%=59.78 model-win1%=51.59\n",
      "actions=(6,): 112 win=77 loss=35 draw=0 win1%=68.75 model-win1%=67.69\n",
      "actions=(7,): 103 win=41 loss=62 draw=0 win1%=39.81 model-win1%=29.98\n",
      "\n",
      "=== Generation 24 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9995/10000 [01:20<00:00, 36.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=4, eval-per-second=2576.75, total-batches=1000, mean-eval-per-second=35900.47, mean-time-per-batch=0.014, mean-batch-size=518.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:21<00:00, 122.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 24...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2274, train_policy_loss:0.1847, train_value_loss:0.0427, val:0.2148, val_policy_loss:0.1805, val_value_loss:0.0343\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-24/best.pt\n",
      "iter 0/176/30000: loss 0.1957, policy_loss:0.1795, value_loss:0.0162, time 7.84s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2367, policy_loss:0.1850, value_loss:0.0517, time 1.28s, iter_time: 53.42ms\n",
      "iter 400/528/30000: loss 0.2213, policy_loss:0.1793, value_loss:0.0420, time 2.01s, iter_time: 41.97ms\n",
      "iter 600/704/30000: loss 0.2291, policy_loss:0.1918, value_loss:0.0373, time 3.19s, iter_time: 44.27ms\n",
      "iter 800/880/30000: loss 0.2406, policy_loss:0.1778, value_loss:0.0628, time 4.64s, iter_time: 48.31ms\n",
      "step 1000: losses: train:0.2312, train_policy_loss:0.1867, train_value_loss:0.0445, val:0.2240, val_policy_loss:0.1848, val_value_loss:0.0392\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-24\n",
      "iter 1000/1056/30000: loss 0.2374, policy_loss:0.1848, value_loss:0.0527, time 11.74s, iter_time: 97.85ms\n",
      "iter 1200/1232/30000: loss 0.2412, policy_loss:0.1884, value_loss:0.0528, time 5.78s, iter_time: 40.12ms\n",
      "iter 1400/1408/30000: loss 0.2058, policy_loss:0.1869, value_loss:0.0189, time 6.62s, iter_time: 39.39ms\n",
      "iter 1600/1760/30000: loss 0.2121, policy_loss:0.1777, value_loss:0.0343, time 0.89s, iter_time: 55.64ms\n",
      "iter 1800/1936/30000: loss 0.2116, policy_loss:0.1815, value_loss:0.0300, time 1.93s, iter_time: 48.32ms\n",
      "step 2000: losses: train:0.2269, train_policy_loss:0.1845, train_value_loss:0.0423, val:0.2240, val_policy_loss:0.1851, val_value_loss:0.0389\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-24\n",
      "iter 2000/2112/30000: loss 0.2288, policy_loss:0.1895, value_loss:0.0393, time 5.38s, iter_time: 84.01ms\n",
      "iter 2200/2288/30000: loss 0.2243, policy_loss:0.1831, value_loss:0.0412, time 4.61s, iter_time: 52.41ms\n",
      "iter 2400/2464/30000: loss 0.2354, policy_loss:0.1846, value_loss:0.0508, time 4.71s, iter_time: 42.04ms\n",
      "iter 2600/2640/30000: loss 0.2525, policy_loss:0.1957, value_loss:0.0568, time 5.43s, iter_time: 39.90ms\n",
      "iter 2800/2816/30000: loss 0.2058, policy_loss:0.1781, value_loss:0.0277, time 6.38s, iter_time: 39.89ms\n",
      "step 3000: losses: train:0.2221, train_policy_loss:0.1819, train_value_loss:0.0401, val:0.2228, val_policy_loss:0.1836, val_value_loss:0.0392\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-24\n",
      "iter 3000/3168/30000: loss 0.2135, policy_loss:0.1824, value_loss:0.0312, time 3.38s, iter_time: 422.88ms\n",
      "iter 3200/3344/30000: loss 0.2300, policy_loss:0.1763, value_loss:0.0537, time 1.46s, iter_time: 45.66ms\n",
      "iter 3400/3520/30000: loss 0.2132, policy_loss:0.1784, value_loss:0.0348, time 2.42s, iter_time: 43.29ms\n",
      "iter 3600/3696/30000: loss 0.2309, policy_loss:0.1829, value_loss:0.0479, time 3.57s, iter_time: 44.58ms\n",
      "iter 3800/3872/30000: loss 0.2721, policy_loss:0.1844, value_loss:0.0877, time 4.11s, iter_time: 39.49ms\n",
      "step 4000: losses: train:0.2196, train_policy_loss:0.1801, train_value_loss:0.0395, val:0.2211, val_policy_loss:0.1833, val_value_loss:0.0378\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-24\n",
      "iter 4000/4048/30000: loss 0.1996, policy_loss:0.1781, value_loss:0.0214, time 11.33s, iter_time: 88.48ms\n",
      "iter 4200/4224/30000: loss 0.1941, policy_loss:0.1761, value_loss:0.0180, time 6.26s, iter_time: 41.16ms\n",
      "iter 4400/4576/30000: loss 0.2537, policy_loss:0.1879, value_loss:0.0658, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2252, policy_loss:0.1831, value_loss:0.0422, time 1.19s, iter_time: 49.50ms\n",
      "iter 4800/4928/30000: loss 0.2502, policy_loss:0.1885, value_loss:0.0617, time 2.31s, iter_time: 48.04ms\n",
      "step 5000: losses: train:0.2186, train_policy_loss:0.1795, train_value_loss:0.0391, val:0.2211, val_policy_loss:0.1831, val_value_loss:0.0380\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-24/best.pt (val_loss=0.2148)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-24.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 736810\n",
      "  Avg trajectory length: 7.37\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98874 loss=1126 draw=0 win1%=98.87 model-win1%=98.73\n",
      "actions=(1,): 106 win=38 loss=68 draw=0 win1%=35.85 model-win1%=30.55\n",
      "actions=(2,): 148 win=107 loss=41 draw=0 win1%=72.30 model-win1%=70.91\n",
      "actions=(3,): 115 win=40 loss=75 draw=0 win1%=34.78 model-win1%=35.25\n",
      "actions=(4,): 99152 win=98412 loss=740 draw=0 win1%=99.25 model-win1%=99.10\n",
      "actions=(4, 5): 95762 win=95062 loss=700 draw=0 win1%=99.27 model-win1%=99.13\n",
      "actions=(5,): 257 win=150 loss=107 draw=0 win1%=58.37 model-win1%=51.59\n",
      "actions=(6,): 121 win=81 loss=40 draw=0 win1%=66.94 model-win1%=67.69\n",
      "actions=(7,): 101 win=46 loss=55 draw=0 win1%=45.54 model-win1%=29.98\n",
      "\n",
      "=== Generation 25 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9993/10000 [01:22<00:00, 20.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=9, eval-per-second=4137.75, total-batches=1000, mean-eval-per-second=33021.11, mean-time-per-batch=0.016, mean-batch-size=522.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:22<00:00, 121.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 25...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2274, train_policy_loss:0.1856, train_value_loss:0.0418, val:0.2196, val_policy_loss:0.1829, val_value_loss:0.0366\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-25/best.pt\n",
      "iter 0/176/30000: loss 0.2363, policy_loss:0.1916, value_loss:0.0448, time 7.08s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.1896, policy_loss:0.1724, value_loss:0.0172, time 1.01s, iter_time: 42.08ms\n",
      "iter 400/528/30000: loss 0.2458, policy_loss:0.1829, value_loss:0.0629, time 2.14s, iter_time: 44.57ms\n",
      "iter 600/704/30000: loss 0.2100, policy_loss:0.1747, value_loss:0.0353, time 2.95s, iter_time: 40.96ms\n",
      "iter 800/880/30000: loss 0.2306, policy_loss:0.1924, value_loss:0.0382, time 3.78s, iter_time: 39.35ms\n",
      "step 1000: losses: train:0.2294, train_policy_loss:0.1864, train_value_loss:0.0430, val:0.2248, val_policy_loss:0.1857, val_value_loss:0.0391\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-25\n",
      "iter 1000/1056/30000: loss 0.2346, policy_loss:0.1921, value_loss:0.0425, time 8.49s, iter_time: 70.72ms\n",
      "iter 1200/1232/30000: loss 0.2414, policy_loss:0.1991, value_loss:0.0423, time 5.96s, iter_time: 41.39ms\n",
      "iter 1400/1408/30000: loss 0.2394, policy_loss:0.1902, value_loss:0.0493, time 6.69s, iter_time: 39.84ms\n",
      "iter 1600/1760/30000: loss 0.1990, policy_loss:0.1787, value_loss:0.0203, time 0.73s, iter_time: 45.37ms\n",
      "iter 1800/1936/30000: loss 0.2736, policy_loss:0.1974, value_loss:0.0762, time 1.79s, iter_time: 44.83ms\n",
      "step 2000: losses: train:0.2237, train_policy_loss:0.1843, train_value_loss:0.0394, val:0.2222, val_policy_loss:0.1845, val_value_loss:0.0377\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-25\n",
      "iter 2000/2112/30000: loss 0.2646, policy_loss:0.2031, value_loss:0.0615, time 5.36s, iter_time: 83.82ms\n",
      "iter 2200/2288/30000: loss 0.2255, policy_loss:0.1889, value_loss:0.0365, time 3.56s, iter_time: 40.49ms\n",
      "iter 2400/2464/30000: loss 0.2048, policy_loss:0.1746, value_loss:0.0302, time 4.61s, iter_time: 41.17ms\n",
      "iter 2600/2640/30000: loss 0.2273, policy_loss:0.1901, value_loss:0.0372, time 5.40s, iter_time: 39.72ms\n",
      "iter 2800/2816/30000: loss 0.2298, policy_loss:0.1851, value_loss:0.0447, time 6.32s, iter_time: 39.48ms\n",
      "step 3000: losses: train:0.2205, train_policy_loss:0.1819, train_value_loss:0.0386, val:0.2229, val_policy_loss:0.1837, val_value_loss:0.0392\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-25\n",
      "iter 3000/3168/30000: loss 0.2307, policy_loss:0.1832, value_loss:0.0476, time 7.92s, iter_time: 990.22ms\n",
      "iter 3200/3344/30000: loss 0.2624, policy_loss:0.1874, value_loss:0.0750, time 1.42s, iter_time: 44.49ms\n",
      "iter 3400/3520/30000: loss 0.2067, policy_loss:0.1787, value_loss:0.0279, time 2.45s, iter_time: 43.77ms\n",
      "iter 3600/3696/30000: loss 0.2163, policy_loss:0.1718, value_loss:0.0445, time 7.38s, iter_time: 92.22ms\n",
      "iter 3800/3872/30000: loss 0.2007, policy_loss:0.1744, value_loss:0.0263, time 6.83s, iter_time: 65.68ms\n",
      "step 4000: losses: train:0.2194, train_policy_loss:0.1802, train_value_loss:0.0391, val:0.2226, val_policy_loss:0.1831, val_value_loss:0.0395\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-25\n",
      "iter 4000/4048/30000: loss 0.2232, policy_loss:0.1808, value_loss:0.0424, time 11.51s, iter_time: 89.91ms\n",
      "iter 4200/4224/30000: loss 0.2177, policy_loss:0.1782, value_loss:0.0395, time 6.79s, iter_time: 44.66ms\n",
      "iter 4400/4576/30000: loss 0.2150, policy_loss:0.1837, value_loss:0.0313, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2144, policy_loss:0.1819, value_loss:0.0325, time 4.35s, iter_time: 181.10ms\n",
      "iter 4800/4928/30000: loss 0.1995, policy_loss:0.1762, value_loss:0.0233, time 1.93s, iter_time: 40.15ms\n",
      "step 5000: losses: train:0.2167, train_policy_loss:0.1789, train_value_loss:0.0379, val:0.2240, val_policy_loss:0.1836, val_value_loss:0.0404\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-25/best.pt (val_loss=0.2196)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-25.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 736713\n",
      "  Avg trajectory length: 7.37\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98891 loss=1109 draw=0 win1%=98.89 model-win1%=98.73\n",
      "actions=(1,): 108 win=39 loss=69 draw=0 win1%=36.11 model-win1%=30.55\n",
      "actions=(2,): 179 win=122 loss=57 draw=0 win1%=68.16 model-win1%=70.91\n",
      "actions=(3,): 109 win=37 loss=72 draw=0 win1%=33.94 model-win1%=35.25\n",
      "actions=(4,): 99143 win=98429 loss=714 draw=0 win1%=99.28 model-win1%=99.10\n",
      "actions=(4, 5): 95813 win=95141 loss=672 draw=0 win1%=99.30 model-win1%=99.13\n",
      "actions=(5,): 238 win=139 loss=99 draw=0 win1%=58.40 model-win1%=51.59\n",
      "actions=(6,): 131 win=78 loss=53 draw=0 win1%=59.54 model-win1%=67.69\n",
      "actions=(7,): 92 win=47 loss=45 draw=0 win1%=51.09 model-win1%=29.98\n",
      "\n",
      "=== Generation 26 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9996/10000 [01:22<00:00, 15.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.004 seconds, size=5, eval-per-second=1369.08, total-batches=1000, mean-eval-per-second=31454.23, mean-time-per-batch=0.016, mean-batch-size=514.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:22<00:00, 120.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 26...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2278, train_policy_loss:0.1874, train_value_loss:0.0404, val:0.2251, val_policy_loss:0.1854, val_value_loss:0.0397\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-26/best.pt\n",
      "iter 0/176/30000: loss 0.2147, policy_loss:0.1822, value_loss:0.0325, time 6.55s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2205, policy_loss:0.1848, value_loss:0.0357, time 1.44s, iter_time: 59.98ms\n",
      "iter 400/528/30000: loss 0.2149, policy_loss:0.1767, value_loss:0.0382, time 2.03s, iter_time: 42.38ms\n",
      "iter 600/704/30000: loss 0.2150, policy_loss:0.1857, value_loss:0.0293, time 2.96s, iter_time: 41.17ms\n",
      "iter 800/880/30000: loss 0.2113, policy_loss:0.1832, value_loss:0.0282, time 3.90s, iter_time: 40.67ms\n",
      "step 1000: losses: train:0.2287, train_policy_loss:0.1874, train_value_loss:0.0412, val:0.2301, val_policy_loss:0.1879, val_value_loss:0.0422\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-26\n",
      "iter 1000/1056/30000: loss 0.2395, policy_loss:0.1986, value_loss:0.0409, time 8.48s, iter_time: 70.65ms\n",
      "iter 1200/1232/30000: loss 0.2511, policy_loss:0.1966, value_loss:0.0546, time 5.93s, iter_time: 41.18ms\n",
      "iter 1400/1408/30000: loss 0.2488, policy_loss:0.1820, value_loss:0.0669, time 6.92s, iter_time: 41.17ms\n",
      "iter 1600/1760/30000: loss 0.2729, policy_loss:0.1945, value_loss:0.0784, time 0.64s, iter_time: 40.03ms\n",
      "iter 1800/1936/30000: loss 0.2323, policy_loss:0.1884, value_loss:0.0439, time 1.64s, iter_time: 40.99ms\n",
      "step 2000: losses: train:0.2205, train_policy_loss:0.1834, train_value_loss:0.0372, val:0.2276, val_policy_loss:0.1862, val_value_loss:0.0414\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-26\n",
      "iter 2000/2112/30000: loss 0.2169, policy_loss:0.1842, value_loss:0.0327, time 5.39s, iter_time: 84.26ms\n",
      "iter 2200/2288/30000: loss 0.2320, policy_loss:0.1894, value_loss:0.0427, time 3.55s, iter_time: 40.31ms\n",
      "iter 2400/2464/30000: loss 0.2175, policy_loss:0.1890, value_loss:0.0285, time 4.51s, iter_time: 40.26ms\n",
      "iter 2600/2640/30000: loss 0.2167, policy_loss:0.1823, value_loss:0.0344, time 5.35s, iter_time: 39.31ms\n",
      "iter 2800/2816/30000: loss 0.2152, policy_loss:0.1887, value_loss:0.0265, time 6.42s, iter_time: 40.15ms\n",
      "step 3000: losses: train:0.2173, train_policy_loss:0.1815, train_value_loss:0.0358, val:0.2258, val_policy_loss:0.1853, val_value_loss:0.0404\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-26\n",
      "iter 3000/3168/30000: loss 0.2182, policy_loss:0.1743, value_loss:0.0439, time 6.63s, iter_time: 828.46ms\n",
      "iter 3200/3344/30000: loss 0.2265, policy_loss:0.1818, value_loss:0.0447, time 1.25s, iter_time: 39.11ms\n",
      "iter 3400/3520/30000: loss 0.2117, policy_loss:0.1778, value_loss:0.0339, time 2.21s, iter_time: 39.44ms\n",
      "iter 3600/3696/30000: loss 0.2121, policy_loss:0.1797, value_loss:0.0324, time 3.20s, iter_time: 40.01ms\n",
      "iter 3800/3872/30000: loss 0.2201, policy_loss:0.1820, value_loss:0.0381, time 4.22s, iter_time: 40.60ms\n",
      "step 4000: losses: train:0.2121, train_policy_loss:0.1783, train_value_loss:0.0338, val:0.2273, val_policy_loss:0.1846, val_value_loss:0.0427\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-26\n",
      "iter 4000/4048/30000: loss 0.2216, policy_loss:0.1782, value_loss:0.0435, time 12.83s, iter_time: 100.27ms\n",
      "iter 4200/4224/30000: loss 0.2339, policy_loss:0.1786, value_loss:0.0553, time 6.65s, iter_time: 43.76ms\n",
      "iter 4400/4576/30000: loss 0.2028, policy_loss:0.1804, value_loss:0.0224, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2026, policy_loss:0.1693, value_loss:0.0333, time 1.03s, iter_time: 42.90ms\n",
      "iter 4800/4928/30000: loss 0.2540, policy_loss:0.1832, value_loss:0.0708, time 2.00s, iter_time: 41.60ms\n",
      "step 5000: losses: train:0.2129, train_policy_loss:0.1783, train_value_loss:0.0346, val:0.2280, val_policy_loss:0.1848, val_value_loss:0.0432\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-26/best.pt (val_loss=0.2251)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-26.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 736403\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=98963 loss=1037 draw=0 win1%=98.96 model-win1%=98.73\n",
      "actions=(1,): 106 win=38 loss=68 draw=0 win1%=35.85 model-win1%=30.55\n",
      "actions=(2,): 205 win=139 loss=66 draw=0 win1%=67.80 model-win1%=70.91\n",
      "actions=(3,): 104 win=34 loss=70 draw=0 win1%=32.69 model-win1%=35.25\n",
      "actions=(4,): 99152 win=98499 loss=653 draw=0 win1%=99.34 model-win1%=99.10\n",
      "actions=(4, 5): 95901 win=95287 loss=614 draw=0 win1%=99.36 model-win1%=99.13\n",
      "actions=(5,): 215 win=128 loss=87 draw=0 win1%=59.53 model-win1%=51.59\n",
      "actions=(6,): 129 win=74 loss=55 draw=0 win1%=57.36 model-win1%=67.69\n",
      "actions=(7,): 89 win=51 loss=38 draw=0 win1%=57.30 model-win1%=29.98\n",
      "\n",
      "=== Generation 27 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9991/10000 [01:21<00:00, 25.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=15, eval-per-second=8103.37, total-batches=1000, mean-eval-per-second=34697.26, mean-time-per-batch=0.015, mean-batch-size=523.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:22<00:00, 121.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 27...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2267, train_policy_loss:0.1877, train_value_loss:0.0389, val:0.2283, val_policy_loss:0.1877, val_value_loss:0.0406\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27/best.pt\n",
      "iter 0/176/30000: loss 0.1974, policy_loss:0.1762, value_loss:0.0212, time 3.56s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2122, policy_loss:0.1771, value_loss:0.0352, time 1.09s, iter_time: 45.33ms\n",
      "iter 400/528/30000: loss 0.2061, policy_loss:0.1809, value_loss:0.0252, time 1.94s, iter_time: 40.49ms\n",
      "iter 600/704/30000: loss 0.1956, policy_loss:0.1748, value_loss:0.0208, time 2.92s, iter_time: 40.57ms\n",
      "iter 800/880/30000: loss 0.2182, policy_loss:0.1830, value_loss:0.0352, time 3.69s, iter_time: 38.42ms\n",
      "step 1000: losses: train:0.2215, train_policy_loss:0.1841, train_value_loss:0.0374, val:0.2255, val_policy_loss:0.1853, val_value_loss:0.0402\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27\n",
      "iter 1000/1056/30000: loss 0.2231, policy_loss:0.1869, value_loss:0.0362, time 7.61s, iter_time: 63.44ms\n",
      "iter 1200/1232/30000: loss 0.2407, policy_loss:0.1888, value_loss:0.0519, time 5.86s, iter_time: 40.73ms\n",
      "iter 1400/1408/30000: loss 0.1946, policy_loss:0.1781, value_loss:0.0165, time 7.13s, iter_time: 42.46ms\n",
      "iter 1600/1760/30000: loss 0.2006, policy_loss:0.1808, value_loss:0.0198, time 0.72s, iter_time: 44.92ms\n",
      "iter 1800/1936/30000: loss 0.2172, policy_loss:0.1899, value_loss:0.0273, time 3.77s, iter_time: 94.35ms\n",
      "step 2000: losses: train:0.2177, train_policy_loss:0.1825, train_value_loss:0.0352, val:0.2262, val_policy_loss:0.1849, val_value_loss:0.0413\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27\n",
      "iter 2000/2112/30000: loss 0.1886, policy_loss:0.1790, value_loss:0.0096, time 8.65s, iter_time: 135.20ms\n",
      "iter 2200/2288/30000: loss 0.1942, policy_loss:0.1737, value_loss:0.0205, time 3.64s, iter_time: 41.36ms\n",
      "iter 2400/2464/30000: loss 0.2323, policy_loss:0.1858, value_loss:0.0464, time 5.28s, iter_time: 47.10ms\n",
      "iter 2600/2640/30000: loss 0.2567, policy_loss:0.1863, value_loss:0.0704, time 5.61s, iter_time: 41.25ms\n",
      "iter 2800/2816/30000: loss 0.2378, policy_loss:0.1939, value_loss:0.0438, time 6.60s, iter_time: 41.27ms\n",
      "step 3000: losses: train:0.2151, train_policy_loss:0.1803, train_value_loss:0.0348, val:0.2243, val_policy_loss:0.1842, val_value_loss:0.0402\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27\n",
      "iter 3000/3168/30000: loss 0.2064, policy_loss:0.1778, value_loss:0.0286, time 3.24s, iter_time: 404.49ms\n",
      "iter 3200/3344/30000: loss 0.2064, policy_loss:0.1830, value_loss:0.0235, time 1.32s, iter_time: 41.22ms\n",
      "iter 3400/3520/30000: loss 0.2399, policy_loss:0.1842, value_loss:0.0557, time 2.38s, iter_time: 42.50ms\n",
      "iter 3600/3696/30000: loss 0.2225, policy_loss:0.1823, value_loss:0.0401, time 3.30s, iter_time: 41.23ms\n",
      "iter 3800/3872/30000: loss 0.2095, policy_loss:0.1701, value_loss:0.0394, time 4.48s, iter_time: 43.03ms\n",
      "step 4000: losses: train:0.2122, train_policy_loss:0.1781, train_value_loss:0.0341, val:0.2248, val_policy_loss:0.1834, val_value_loss:0.0414\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27\n",
      "iter 4000/4048/30000: loss 0.2188, policy_loss:0.1776, value_loss:0.0412, time 8.00s, iter_time: 62.54ms\n",
      "iter 4200/4224/30000: loss 0.1975, policy_loss:0.1793, value_loss:0.0182, time 5.99s, iter_time: 39.40ms\n",
      "iter 4400/4576/30000: loss 0.2103, policy_loss:0.1790, value_loss:0.0313, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2228, policy_loss:0.1785, value_loss:0.0443, time 0.99s, iter_time: 41.14ms\n",
      "iter 4800/4928/30000: loss 0.2017, policy_loss:0.1837, value_loss:0.0181, time 2.04s, iter_time: 42.47ms\n",
      "step 5000: losses: train:0.2101, train_policy_loss:0.1774, train_value_loss:0.0328, val:0.2257, val_policy_loss:0.1834, val_value_loss:0.0423\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27\n",
      "iter 5000/5104/30000: loss 0.2233, policy_loss:0.1777, value_loss:0.0455, time 5.96s, iter_time: 82.72ms\n",
      "iter 5200/5280/30000: loss 0.1917, policy_loss:0.1754, value_loss:0.0163, time 3.93s, iter_time: 40.92ms\n",
      "iter 5400/5456/30000: loss 0.2214, policy_loss:0.1769, value_loss:0.0445, time 4.70s, iter_time: 39.14ms\n",
      "iter 5600/5632/30000: loss 0.2008, policy_loss:0.1748, value_loss:0.0259, time 5.83s, iter_time: 40.48ms\n",
      "iter 5800/5808/30000: loss 0.2575, policy_loss:0.1928, value_loss:0.0647, time 6.61s, iter_time: 39.35ms\n",
      "step 6000: losses: train:0.2090, train_policy_loss:0.1770, train_value_loss:0.0320, val:0.2260, val_policy_loss:0.1839, val_value_loss:0.0421\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27\n",
      "iter 6000/6160/30000: loss 0.2065, policy_loss:0.1756, value_loss:0.0310, time 7.62s, iter_time: 476.37ms\n",
      "iter 6200/6336/30000: loss 0.1903, policy_loss:0.1707, value_loss:0.0196, time 1.64s, iter_time: 40.88ms\n",
      "iter 6400/6512/30000: loss 0.1898, policy_loss:0.1702, value_loss:0.0196, time 3.24s, iter_time: 50.68ms\n",
      "iter 6600/6688/30000: loss 0.2212, policy_loss:0.1720, value_loss:0.0492, time 3.45s, iter_time: 39.17ms\n",
      "iter 6800/6864/30000: loss 0.2002, policy_loss:0.1744, value_loss:0.0258, time 4.44s, iter_time: 39.63ms\n",
      "step 7000: losses: train:0.2107, train_policy_loss:0.1776, train_value_loss:0.0332, val:0.2269, val_policy_loss:0.1839, val_value_loss:0.0430\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27\n",
      "iter 7000/7040/30000: loss 0.2305, policy_loss:0.1836, value_loss:0.0469, time 8.36s, iter_time: 61.47ms\n",
      "iter 7200/7216/30000: loss 0.2059, policy_loss:0.1770, value_loss:0.0289, time 6.53s, iter_time: 40.84ms\n",
      "iter 7400/7568/30000: loss 0.1842, policy_loss:0.1725, value_loss:0.0117, time 0.34s, iter_time: 43.01ms\n",
      "iter 7600/7744/30000: loss 0.2098, policy_loss:0.1722, value_loss:0.0376, time 1.36s, iter_time: 42.43ms\n",
      "iter 7800/7920/30000: loss 0.2055, policy_loss:0.1784, value_loss:0.0271, time 2.55s, iter_time: 45.55ms\n",
      "step 8000: losses: train:0.2111, train_policy_loss:0.1772, train_value_loss:0.0339, val:0.2275, val_policy_loss:0.1837, val_value_loss:0.0438\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-27/best.pt (val_loss=0.2243)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-27.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 735827\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99019 loss=981 draw=0 win1%=99.02 model-win1%=99.13\n",
      "actions=(1,): 107 win=41 loss=66 draw=0 win1%=38.32 model-win1%=37.06\n",
      "actions=(2,): 222 win=144 loss=78 draw=0 win1%=64.86 model-win1%=64.36\n",
      "actions=(3,): 102 win=35 loss=67 draw=0 win1%=34.31 model-win1%=36.27\n",
      "actions=(4,): 99149 win=98553 loss=596 draw=0 win1%=99.40 model-win1%=99.43\n",
      "actions=(4, 5): 95931 win=95369 loss=562 draw=0 win1%=99.41 model-win1%=99.46\n",
      "actions=(5,): 192 win=120 loss=72 draw=0 win1%=62.50 model-win1%=55.05\n",
      "actions=(6,): 138 win=73 loss=65 draw=0 win1%=52.90 model-win1%=47.16\n",
      "actions=(7,): 90 win=53 loss=37 draw=0 win1%=58.89 model-win1%=48.62\n",
      "\n",
      "=== Generation 28 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9995/10000 [01:22<00:00, 16.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.003 seconds, size=8, eval-per-second=2864.23, total-batches=1000, mean-eval-per-second=34618.07, mean-time-per-batch=0.015, mean-batch-size=527.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9999/10000 [01:22<00:00, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=1, eval-per-second=540.78, total-batches=2000, mean-eval-per-second=30877.02, mean-time-per-batch=0.009, mean-batch-size=264.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:24<00:00, 118.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 28...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2154, train_policy_loss:0.1812, train_value_loss:0.0341, val:0.2154, val_policy_loss:0.1801, val_value_loss:0.0353\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-28/best.pt\n",
      "iter 0/176/30000: loss 0.2062, policy_loss:0.1789, value_loss:0.0272, time 8.01s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2115, policy_loss:0.1744, value_loss:0.0371, time 1.13s, iter_time: 47.15ms\n",
      "iter 400/528/30000: loss 0.2006, policy_loss:0.1735, value_loss:0.0271, time 1.95s, iter_time: 40.58ms\n",
      "iter 600/704/30000: loss 0.2077, policy_loss:0.1775, value_loss:0.0303, time 2.85s, iter_time: 39.53ms\n",
      "iter 800/880/30000: loss 0.2393, policy_loss:0.1810, value_loss:0.0583, time 3.71s, iter_time: 38.64ms\n",
      "step 1000: losses: train:0.2184, train_policy_loss:0.1833, train_value_loss:0.0352, val:0.2227, val_policy_loss:0.1838, val_value_loss:0.0389\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-28\n",
      "iter 1000/1056/30000: loss 0.2087, policy_loss:0.1836, value_loss:0.0251, time 11.10s, iter_time: 92.48ms\n",
      "iter 1200/1232/30000: loss 0.1982, policy_loss:0.1777, value_loss:0.0204, time 6.38s, iter_time: 44.32ms\n",
      "iter 1400/1408/30000: loss 0.1906, policy_loss:0.1779, value_loss:0.0127, time 6.60s, iter_time: 39.31ms\n",
      "iter 1600/1760/30000: loss 0.1825, policy_loss:0.1716, value_loss:0.0109, time 0.67s, iter_time: 42.05ms\n",
      "iter 1800/1936/30000: loss 0.1818, policy_loss:0.1707, value_loss:0.0111, time 1.59s, iter_time: 39.66ms\n",
      "step 2000: losses: train:0.2165, train_policy_loss:0.1824, train_value_loss:0.0342, val:0.2207, val_policy_loss:0.1828, val_value_loss:0.0379\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-28\n",
      "iter 2000/2112/30000: loss 0.1955, policy_loss:0.1781, value_loss:0.0173, time 10.45s, iter_time: 163.23ms\n",
      "iter 2200/2288/30000: loss 0.1925, policy_loss:0.1766, value_loss:0.0159, time 3.65s, iter_time: 41.53ms\n",
      "iter 2400/2464/30000: loss 0.1891, policy_loss:0.1722, value_loss:0.0169, time 4.66s, iter_time: 41.64ms\n",
      "iter 2600/2640/30000: loss 0.1883, policy_loss:0.1752, value_loss:0.0131, time 5.41s, iter_time: 39.79ms\n",
      "iter 2800/2816/30000: loss 0.1991, policy_loss:0.1723, value_loss:0.0268, time 7.45s, iter_time: 46.54ms\n",
      "step 3000: losses: train:0.2127, train_policy_loss:0.1794, train_value_loss:0.0333, val:0.2202, val_policy_loss:0.1822, val_value_loss:0.0380\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-28\n",
      "iter 3000/3168/30000: loss 0.2133, policy_loss:0.1925, value_loss:0.0208, time 9.45s, iter_time: 1180.89ms\n",
      "iter 3200/3344/30000: loss 0.2258, policy_loss:0.1850, value_loss:0.0408, time 1.53s, iter_time: 47.95ms\n",
      "iter 3400/3520/30000: loss 0.2027, policy_loss:0.1798, value_loss:0.0229, time 2.35s, iter_time: 42.01ms\n",
      "iter 3600/3696/30000: loss 0.2099, policy_loss:0.1757, value_loss:0.0341, time 3.22s, iter_time: 40.31ms\n",
      "iter 3800/3872/30000: loss 0.1891, policy_loss:0.1697, value_loss:0.0193, time 4.15s, iter_time: 39.91ms\n",
      "step 4000: losses: train:0.2077, train_policy_loss:0.1773, train_value_loss:0.0304, val:0.2208, val_policy_loss:0.1814, val_value_loss:0.0394\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-28\n",
      "iter 4000/4048/30000: loss 0.2343, policy_loss:0.1841, value_loss:0.0503, time 8.11s, iter_time: 63.36ms\n",
      "iter 4200/4224/30000: loss 0.2137, policy_loss:0.1779, value_loss:0.0359, time 6.15s, iter_time: 40.45ms\n",
      "iter 4400/4576/30000: loss 0.2368, policy_loss:0.1842, value_loss:0.0526, time 0.08s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2148, policy_loss:0.1777, value_loss:0.0371, time 1.08s, iter_time: 44.85ms\n",
      "iter 4800/4928/30000: loss 0.1930, policy_loss:0.1692, value_loss:0.0238, time 1.94s, iter_time: 40.39ms\n",
      "step 5000: losses: train:0.2080, train_policy_loss:0.1767, train_value_loss:0.0313, val:0.2199, val_policy_loss:0.1810, val_value_loss:0.0389\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-28/best.pt (val_loss=0.2154)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-28.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 735437\n",
      "  Avg trajectory length: 7.35\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99057 loss=943 draw=0 win1%=99.06 model-win1%=99.13\n",
      "actions=(1,): 103 win=40 loss=63 draw=0 win1%=38.83 model-win1%=37.06\n",
      "actions=(2,): 229 win=147 loss=82 draw=0 win1%=64.19 model-win1%=64.36\n",
      "actions=(3,): 91 win=27 loss=64 draw=0 win1%=29.67 model-win1%=36.27\n",
      "actions=(4,): 99161 win=98597 loss=564 draw=0 win1%=99.43 model-win1%=99.43\n",
      "actions=(4, 5): 95950 win=95417 loss=533 draw=0 win1%=99.44 model-win1%=99.46\n",
      "actions=(5,): 170 win=112 loss=58 draw=0 win1%=65.88 model-win1%=55.05\n",
      "actions=(6,): 139 win=70 loss=69 draw=0 win1%=50.36 model-win1%=47.16\n",
      "actions=(7,): 107 win=64 loss=43 draw=0 win1%=59.81 model-win1%=48.62\n",
      "\n",
      "=== Generation 29 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9992/10000 [01:22<00:00, 17.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.004 seconds, size=10, eval-per-second=2562.82, total-batches=1000, mean-eval-per-second=33013.44, mean-time-per-batch=0.016, mean-batch-size=531.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:24<00:00, 118.61it/s]\n",
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 29...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2172, train_policy_loss:0.1833, train_value_loss:0.0339, val:0.2186, val_policy_loss:0.1849, val_value_loss:0.0337\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-29/best.pt\n",
      "iter 0/176/30000: loss 0.2154, policy_loss:0.1830, value_loss:0.0324, time 3.27s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2096, policy_loss:0.1820, value_loss:0.0275, time 0.98s, iter_time: 40.74ms\n",
      "iter 400/528/30000: loss 0.2119, policy_loss:0.1811, value_loss:0.0308, time 2.01s, iter_time: 41.92ms\n",
      "iter 600/704/30000: loss 0.2083, policy_loss:0.1752, value_loss:0.0331, time 3.44s, iter_time: 47.75ms\n",
      "iter 800/880/30000: loss 0.2196, policy_loss:0.1896, value_loss:0.0301, time 4.41s, iter_time: 45.95ms\n",
      "step 1000: losses: train:0.2195, train_policy_loss:0.1840, train_value_loss:0.0355, val:0.2232, val_policy_loss:0.1870, val_value_loss:0.0362\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-29\n",
      "iter 1000/1056/30000: loss 0.2143, policy_loss:0.1842, value_loss:0.0301, time 7.65s, iter_time: 63.73ms\n",
      "iter 1200/1232/30000: loss 0.2330, policy_loss:0.1909, value_loss:0.0420, time 5.86s, iter_time: 40.71ms\n",
      "iter 1400/1408/30000: loss 0.2072, policy_loss:0.1734, value_loss:0.0338, time 7.52s, iter_time: 44.75ms\n",
      "iter 1600/1760/30000: loss 0.2239, policy_loss:0.1813, value_loss:0.0425, time 0.62s, iter_time: 38.93ms\n",
      "iter 1800/1936/30000: loss 0.2589, policy_loss:0.1941, value_loss:0.0648, time 1.53s, iter_time: 38.23ms\n",
      "step 2000: losses: train:0.2131, train_policy_loss:0.1810, train_value_loss:0.0321, val:0.2250, val_policy_loss:0.1869, val_value_loss:0.0381\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-29\n",
      "iter 2000/2112/30000: loss 0.2082, policy_loss:0.1861, value_loss:0.0221, time 5.58s, iter_time: 87.18ms\n",
      "iter 2200/2288/30000: loss 0.2083, policy_loss:0.1805, value_loss:0.0278, time 3.78s, iter_time: 42.91ms\n",
      "iter 2400/2464/30000: loss 0.2381, policy_loss:0.1910, value_loss:0.0471, time 4.62s, iter_time: 41.24ms\n",
      "iter 2600/2640/30000: loss 0.1825, policy_loss:0.1707, value_loss:0.0118, time 5.57s, iter_time: 40.94ms\n",
      "iter 2800/2816/30000: loss 0.1957, policy_loss:0.1710, value_loss:0.0247, time 6.70s, iter_time: 41.90ms\n",
      "step 3000: losses: train:0.2109, train_policy_loss:0.1796, train_value_loss:0.0314, val:0.2246, val_policy_loss:0.1850, val_value_loss:0.0396\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-29\n",
      "iter 3000/3168/30000: loss 0.1947, policy_loss:0.1760, value_loss:0.0187, time 6.11s, iter_time: 764.05ms\n",
      "iter 3200/3344/30000: loss 0.1896, policy_loss:0.1729, value_loss:0.0168, time 1.22s, iter_time: 38.14ms\n",
      "iter 3400/3520/30000: loss 0.2496, policy_loss:0.1827, value_loss:0.0669, time 2.18s, iter_time: 38.96ms\n",
      "iter 3600/3696/30000: loss 0.1985, policy_loss:0.1762, value_loss:0.0224, time 3.14s, iter_time: 39.25ms\n",
      "iter 3800/3872/30000: loss 0.1948, policy_loss:0.1737, value_loss:0.0211, time 4.12s, iter_time: 39.58ms\n",
      "step 4000: losses: train:0.2096, train_policy_loss:0.1778, train_value_loss:0.0318, val:0.2241, val_policy_loss:0.1846, val_value_loss:0.0394\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-29\n",
      "iter 4000/4048/30000: loss 0.1918, policy_loss:0.1727, value_loss:0.0191, time 8.15s, iter_time: 63.64ms\n",
      "iter 4200/4224/30000: loss 0.2027, policy_loss:0.1762, value_loss:0.0265, time 5.97s, iter_time: 39.30ms\n",
      "iter 4400/4576/30000: loss 0.1959, policy_loss:0.1733, value_loss:0.0226, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2351, policy_loss:0.1743, value_loss:0.0608, time 0.93s, iter_time: 38.56ms\n",
      "iter 4800/4928/30000: loss 0.2117, policy_loss:0.1817, value_loss:0.0300, time 1.94s, iter_time: 40.38ms\n",
      "step 5000: losses: train:0.2074, train_policy_loss:0.1771, train_value_loss:0.0304, val:0.2244, val_policy_loss:0.1840, val_value_loss:0.0405\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-29/best.pt (val_loss=0.2186)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-29.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 735728\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99094 loss=906 draw=0 win1%=99.09 model-win1%=99.13\n",
      "actions=(1,): 106 win=36 loss=70 draw=0 win1%=33.96 model-win1%=37.06\n",
      "actions=(2,): 224 win=142 loss=82 draw=0 win1%=63.39 model-win1%=64.36\n",
      "actions=(3,): 93 win=26 loss=67 draw=0 win1%=27.96 model-win1%=36.27\n",
      "actions=(4,): 99170 win=98640 loss=530 draw=0 win1%=99.47 model-win1%=99.43\n",
      "actions=(4, 5): 95925 win=95426 loss=499 draw=0 win1%=99.48 model-win1%=99.46\n",
      "actions=(5,): 157 win=110 loss=47 draw=0 win1%=70.06 model-win1%=55.05\n",
      "actions=(6,): 140 win=69 loss=71 draw=0 win1%=49.29 model-win1%=47.16\n",
      "actions=(7,): 110 win=71 loss=39 draw=0 win1%=64.55 model-win1%=48.62\n",
      "\n",
      "=== Generation 30 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9995/10000 [01:22<00:00, 26.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.006 seconds, size=7, eval-per-second=1218.46, total-batches=1000, mean-eval-per-second=33739.46, mean-time-per-batch=0.016, mean-batch-size=525.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:23<00:00, 119.80it/s]\n",
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 30...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2182, train_policy_loss:0.1849, train_value_loss:0.0333, val:0.2156, val_policy_loss:0.1846, val_value_loss:0.0310\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-30/best.pt\n",
      "iter 0/176/30000: loss 0.2190, policy_loss:0.1858, value_loss:0.0332, time 8.92s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2111, policy_loss:0.1844, value_loss:0.0266, time 1.04s, iter_time: 43.36ms\n",
      "iter 400/528/30000: loss 0.2398, policy_loss:0.1964, value_loss:0.0433, time 2.07s, iter_time: 43.20ms\n",
      "iter 600/704/30000: loss 0.2150, policy_loss:0.1901, value_loss:0.0249, time 3.24s, iter_time: 45.03ms\n",
      "iter 800/880/30000: loss 0.1908, policy_loss:0.1767, value_loss:0.0140, time 4.24s, iter_time: 44.20ms\n",
      "step 1000: losses: train:0.2171, train_policy_loss:0.1840, train_value_loss:0.0332, val:0.2182, val_policy_loss:0.1864, val_value_loss:0.0317\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-30\n",
      "iter 1000/1056/30000: loss 0.2228, policy_loss:0.1830, value_loss:0.0398, time 8.01s, iter_time: 66.78ms\n",
      "iter 1200/1232/30000: loss 0.2050, policy_loss:0.1817, value_loss:0.0233, time 5.75s, iter_time: 39.95ms\n",
      "iter 1400/1408/30000: loss 0.2516, policy_loss:0.1906, value_loss:0.0610, time 6.69s, iter_time: 39.82ms\n",
      "iter 1600/1760/30000: loss 0.2222, policy_loss:0.1830, value_loss:0.0393, time 0.68s, iter_time: 42.29ms\n",
      "iter 1800/1936/30000: loss 0.2264, policy_loss:0.1936, value_loss:0.0328, time 1.69s, iter_time: 42.34ms\n",
      "step 2000: losses: train:0.2132, train_policy_loss:0.1818, train_value_loss:0.0314, val:0.2199, val_policy_loss:0.1859, val_value_loss:0.0340\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-30\n",
      "iter 2000/2112/30000: loss 0.2201, policy_loss:0.1888, value_loss:0.0313, time 9.12s, iter_time: 142.44ms\n",
      "iter 2200/2288/30000: loss 0.1900, policy_loss:0.1717, value_loss:0.0183, time 3.55s, iter_time: 40.28ms\n",
      "iter 2400/2464/30000: loss 0.2103, policy_loss:0.1865, value_loss:0.0238, time 4.37s, iter_time: 38.99ms\n",
      "iter 2600/2640/30000: loss 0.2236, policy_loss:0.1887, value_loss:0.0349, time 5.43s, iter_time: 39.91ms\n",
      "iter 2800/2816/30000: loss 0.2105, policy_loss:0.1861, value_loss:0.0244, time 6.23s, iter_time: 38.95ms\n",
      "step 3000: losses: train:0.2094, train_policy_loss:0.1797, train_value_loss:0.0298, val:0.2203, val_policy_loss:0.1861, val_value_loss:0.0342\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-30\n",
      "iter 3000/3168/30000: loss 0.2095, policy_loss:0.1816, value_loss:0.0279, time 3.54s, iter_time: 441.96ms\n",
      "iter 3200/3344/30000: loss 0.2058, policy_loss:0.1781, value_loss:0.0278, time 1.33s, iter_time: 41.49ms\n",
      "iter 3400/3520/30000: loss 0.2175, policy_loss:0.1797, value_loss:0.0377, time 2.33s, iter_time: 41.61ms\n",
      "iter 3600/3696/30000: loss 0.1993, policy_loss:0.1792, value_loss:0.0201, time 3.45s, iter_time: 43.13ms\n",
      "iter 3800/3872/30000: loss 0.1924, policy_loss:0.1751, value_loss:0.0173, time 4.41s, iter_time: 42.40ms\n",
      "step 4000: losses: train:0.2065, train_policy_loss:0.1784, train_value_loss:0.0281, val:0.2203, val_policy_loss:0.1855, val_value_loss:0.0347\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-30\n",
      "iter 4000/4048/30000: loss 0.2131, policy_loss:0.1780, value_loss:0.0351, time 10.78s, iter_time: 84.21ms\n",
      "iter 4200/4224/30000: loss 0.1920, policy_loss:0.1749, value_loss:0.0170, time 6.10s, iter_time: 40.13ms\n",
      "iter 4400/4576/30000: loss 0.1819, policy_loss:0.1702, value_loss:0.0117, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.1978, policy_loss:0.1718, value_loss:0.0260, time 1.20s, iter_time: 50.01ms\n",
      "iter 4800/4928/30000: loss 0.1917, policy_loss:0.1740, value_loss:0.0177, time 1.83s, iter_time: 38.08ms\n",
      "step 5000: losses: train:0.2049, train_policy_loss:0.1777, train_value_loss:0.0272, val:0.2203, val_policy_loss:0.1855, val_value_loss:0.0349\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-30/best.pt (val_loss=0.2156)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-30.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 735809\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99133 loss=867 draw=0 win1%=99.13 model-win1%=99.13\n",
      "actions=(1,): 98 win=29 loss=69 draw=0 win1%=29.59 model-win1%=37.06\n",
      "actions=(2,): 233 win=150 loss=83 draw=0 win1%=64.38 model-win1%=64.36\n",
      "actions=(3,): 92 win=27 loss=65 draw=0 win1%=29.35 model-win1%=36.27\n",
      "actions=(4,): 99180 win=98680 loss=500 draw=0 win1%=99.50 model-win1%=99.43\n",
      "actions=(4, 5): 95930 win=95460 loss=470 draw=0 win1%=99.51 model-win1%=99.46\n",
      "actions=(5,): 154 win=112 loss=42 draw=0 win1%=72.73 model-win1%=55.05\n",
      "actions=(6,): 134 win=61 loss=73 draw=0 win1%=45.52 model-win1%=47.16\n",
      "actions=(7,): 109 win=74 loss=35 draw=0 win1%=67.89 model-win1%=48.62\n",
      "\n",
      "=== Generation 31 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9995/10000 [01:22<00:00, 27.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=6, eval-per-second=3397.11, total-batches=1000, mean-eval-per-second=32705.68, mean-time-per-batch=0.016, mean-batch-size=533.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:23<00:00, 119.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2239, train_policy_loss:0.1886, train_value_loss:0.0353, val:0.2255, val_policy_loss:0.1906, val_value_loss:0.0349\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31/best.pt\n",
      "iter 0/176/30000: loss 0.2446, policy_loss:0.1922, value_loss:0.0524, time 3.24s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.1974, policy_loss:0.1763, value_loss:0.0212, time 1.13s, iter_time: 46.98ms\n",
      "iter 400/528/30000: loss 0.2264, policy_loss:0.1832, value_loss:0.0432, time 2.04s, iter_time: 42.60ms\n",
      "iter 600/704/30000: loss 0.2295, policy_loss:0.1873, value_loss:0.0422, time 2.89s, iter_time: 40.17ms\n",
      "iter 800/880/30000: loss 0.2206, policy_loss:0.1849, value_loss:0.0358, time 3.83s, iter_time: 39.88ms\n",
      "step 1000: losses: train:0.2147, train_policy_loss:0.1834, train_value_loss:0.0314, val:0.2256, val_policy_loss:0.1894, val_value_loss:0.0363\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31\n",
      "iter 1000/1056/30000: loss 0.2467, policy_loss:0.1972, value_loss:0.0495, time 8.09s, iter_time: 67.44ms\n",
      "iter 1200/1232/30000: loss 0.2318, policy_loss:0.1871, value_loss:0.0447, time 6.12s, iter_time: 42.49ms\n",
      "iter 1400/1408/30000: loss 0.2065, policy_loss:0.1922, value_loss:0.0143, time 7.13s, iter_time: 42.42ms\n",
      "iter 1600/1760/30000: loss 0.2056, policy_loss:0.1811, value_loss:0.0246, time 0.73s, iter_time: 45.78ms\n",
      "iter 1800/1936/30000: loss 0.1968, policy_loss:0.1773, value_loss:0.0195, time 1.71s, iter_time: 42.81ms\n",
      "step 2000: losses: train:0.2125, train_policy_loss:0.1818, train_value_loss:0.0307, val:0.2239, val_policy_loss:0.1879, val_value_loss:0.0360\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31\n",
      "iter 2000/2112/30000: loss 0.2339, policy_loss:0.1845, value_loss:0.0494, time 5.96s, iter_time: 93.18ms\n",
      "iter 2200/2288/30000: loss 0.2387, policy_loss:0.1942, value_loss:0.0444, time 3.48s, iter_time: 39.53ms\n",
      "iter 2400/2464/30000: loss 0.2063, policy_loss:0.1834, value_loss:0.0230, time 4.38s, iter_time: 39.14ms\n",
      "iter 2600/2640/30000: loss 0.2145, policy_loss:0.1829, value_loss:0.0316, time 5.35s, iter_time: 39.37ms\n",
      "iter 2800/2816/30000: loss 0.2263, policy_loss:0.1839, value_loss:0.0424, time 7.51s, iter_time: 46.94ms\n",
      "step 3000: losses: train:0.2092, train_policy_loss:0.1800, train_value_loss:0.0292, val:0.2228, val_policy_loss:0.1872, val_value_loss:0.0356\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31\n",
      "iter 3000/3168/30000: loss 0.2087, policy_loss:0.1746, value_loss:0.0342, time 3.22s, iter_time: 402.90ms\n",
      "iter 3200/3344/30000: loss 0.1884, policy_loss:0.1757, value_loss:0.0127, time 1.56s, iter_time: 48.80ms\n",
      "iter 3400/3520/30000: loss 0.2077, policy_loss:0.1799, value_loss:0.0278, time 2.31s, iter_time: 41.31ms\n",
      "iter 3600/3696/30000: loss 0.2167, policy_loss:0.1811, value_loss:0.0356, time 3.22s, iter_time: 40.31ms\n",
      "iter 3800/3872/30000: loss 0.2096, policy_loss:0.1827, value_loss:0.0269, time 4.25s, iter_time: 40.86ms\n",
      "step 4000: losses: train:0.2049, train_policy_loss:0.1780, train_value_loss:0.0270, val:0.2240, val_policy_loss:0.1869, val_value_loss:0.0370\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31\n",
      "iter 4000/4048/30000: loss 0.2070, policy_loss:0.1716, value_loss:0.0354, time 11.29s, iter_time: 88.21ms\n",
      "iter 4200/4224/30000: loss 0.2548, policy_loss:0.1822, value_loss:0.0725, time 6.27s, iter_time: 41.25ms\n",
      "iter 4400/4576/30000: loss 0.1876, policy_loss:0.1745, value_loss:0.0130, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2075, policy_loss:0.1839, value_loss:0.0236, time 0.95s, iter_time: 39.47ms\n",
      "iter 4800/4928/30000: loss 0.2324, policy_loss:0.1832, value_loss:0.0491, time 1.92s, iter_time: 40.04ms\n",
      "step 5000: losses: train:0.2056, train_policy_loss:0.1778, train_value_loss:0.0278, val:0.2255, val_policy_loss:0.1873, val_value_loss:0.0381\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31\n",
      "iter 5000/5104/30000: loss 0.1827, policy_loss:0.1700, value_loss:0.0127, time 5.48s, iter_time: 76.14ms\n",
      "iter 5200/5280/30000: loss 0.1882, policy_loss:0.1727, value_loss:0.0155, time 3.68s, iter_time: 38.33ms\n",
      "iter 5400/5456/30000: loss 0.2154, policy_loss:0.1831, value_loss:0.0323, time 4.78s, iter_time: 39.79ms\n",
      "iter 5600/5632/30000: loss 0.1911, policy_loss:0.1766, value_loss:0.0145, time 6.14s, iter_time: 42.63ms\n",
      "iter 5800/5808/30000: loss 0.1889, policy_loss:0.1772, value_loss:0.0116, time 6.79s, iter_time: 40.41ms\n",
      "step 6000: losses: train:0.2064, train_policy_loss:0.1781, train_value_loss:0.0283, val:0.2274, val_policy_loss:0.1879, val_value_loss:0.0395\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31\n",
      "iter 6000/6160/30000: loss 0.1908, policy_loss:0.1727, value_loss:0.0181, time 3.65s, iter_time: 228.02ms\n",
      "iter 6200/6336/30000: loss 0.2116, policy_loss:0.1841, value_loss:0.0275, time 1.64s, iter_time: 41.09ms\n",
      "iter 6400/6512/30000: loss 0.1825, policy_loss:0.1702, value_loss:0.0123, time 2.64s, iter_time: 41.30ms\n",
      "iter 6600/6688/30000: loss 0.1882, policy_loss:0.1738, value_loss:0.0144, time 4.34s, iter_time: 49.30ms\n",
      "iter 6800/6864/30000: loss 0.1897, policy_loss:0.1744, value_loss:0.0154, time 4.92s, iter_time: 43.93ms\n",
      "step 7000: losses: train:0.2042, train_policy_loss:0.1775, train_value_loss:0.0267, val:0.2265, val_policy_loss:0.1875, val_value_loss:0.0390\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31\n",
      "iter 7000/7040/30000: loss 0.2013, policy_loss:0.1779, value_loss:0.0234, time 11.28s, iter_time: 82.92ms\n",
      "iter 7200/7216/30000: loss 0.1971, policy_loss:0.1790, value_loss:0.0182, time 6.59s, iter_time: 41.21ms\n",
      "iter 7400/7568/30000: loss 0.2064, policy_loss:0.1791, value_loss:0.0273, time 0.35s, iter_time: 43.16ms\n",
      "iter 7600/7744/30000: loss 0.1952, policy_loss:0.1749, value_loss:0.0202, time 1.37s, iter_time: 42.88ms\n",
      "iter 7800/7920/30000: loss 0.2158, policy_loss:0.1811, value_loss:0.0348, time 2.20s, iter_time: 39.26ms\n",
      "step 8000: losses: train:0.2059, train_policy_loss:0.1774, train_value_loss:0.0285, val:0.2253, val_policy_loss:0.1872, val_value_loss:0.0381\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-31/best.pt (val_loss=0.2228)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-31.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 735546\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99150 loss=850 draw=0 win1%=99.15 model-win1%=98.96\n",
      "actions=(1,): 94 win=24 loss=70 draw=0 win1%=25.53 model-win1%=22.46\n",
      "actions=(2,): 224 win=144 loss=80 draw=0 win1%=64.29 model-win1%=62.93\n",
      "actions=(3,): 89 win=29 loss=60 draw=0 win1%=32.58 model-win1%=36.23\n",
      "actions=(4,): 99198 win=98715 loss=483 draw=0 win1%=99.51 model-win1%=99.41\n",
      "actions=(4, 5): 95946 win=95491 loss=455 draw=0 win1%=99.53 model-win1%=99.38\n",
      "actions=(5,): 141 win=97 loss=44 draw=0 win1%=68.79 model-win1%=68.27\n",
      "actions=(6,): 137 win=59 loss=78 draw=0 win1%=43.07 model-win1%=48.48\n",
      "actions=(7,): 117 win=82 loss=35 draw=0 win1%=70.09 model-win1%=70.68\n",
      "\n",
      "=== Generation 32 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9988/10000 [01:25<00:01, 10.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.006 seconds, size=13, eval-per-second=2326.89, total-batches=1000, mean-eval-per-second=30322.23, mean-time-per-batch=0.018, mean-batch-size=536.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:26<00:00, 115.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2119, train_policy_loss:0.1823, train_value_loss:0.0296, val:0.2078, val_policy_loss:0.1807, val_value_loss:0.0271\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-32/best.pt\n",
      "iter 0/176/30000: loss 0.2293, policy_loss:0.1906, value_loss:0.0387, time 8.92s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2053, policy_loss:0.1798, value_loss:0.0255, time 1.31s, iter_time: 54.60ms\n",
      "iter 400/528/30000: loss 0.2249, policy_loss:0.1852, value_loss:0.0397, time 2.04s, iter_time: 42.53ms\n",
      "iter 600/704/30000: loss 0.1929, policy_loss:0.1820, value_loss:0.0110, time 3.16s, iter_time: 43.86ms\n",
      "iter 800/880/30000: loss 0.2033, policy_loss:0.1834, value_loss:0.0199, time 3.92s, iter_time: 40.88ms\n",
      "step 1000: losses: train:0.2137, train_policy_loss:0.1846, train_value_loss:0.0292, val:0.2118, val_policy_loss:0.1844, val_value_loss:0.0274\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-32\n",
      "iter 1000/1056/30000: loss 0.2226, policy_loss:0.1852, value_loss:0.0374, time 7.80s, iter_time: 65.00ms\n",
      "iter 1200/1232/30000: loss 0.2046, policy_loss:0.1905, value_loss:0.0140, time 9.09s, iter_time: 63.11ms\n",
      "iter 1400/1408/30000: loss 0.1921, policy_loss:0.1757, value_loss:0.0164, time 6.78s, iter_time: 40.33ms\n",
      "iter 1600/1760/30000: loss 0.1860, policy_loss:0.1750, value_loss:0.0110, time 0.62s, iter_time: 38.66ms\n",
      "iter 1800/1936/30000: loss 0.2089, policy_loss:0.1879, value_loss:0.0210, time 1.57s, iter_time: 39.26ms\n",
      "step 2000: losses: train:0.2104, train_policy_loss:0.1825, train_value_loss:0.0278, val:0.2122, val_policy_loss:0.1838, val_value_loss:0.0284\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-32\n",
      "iter 2000/2112/30000: loss 0.2155, policy_loss:0.1868, value_loss:0.0287, time 8.60s, iter_time: 134.35ms\n",
      "iter 2200/2288/30000: loss 0.2038, policy_loss:0.1795, value_loss:0.0244, time 3.63s, iter_time: 41.21ms\n",
      "iter 2400/2464/30000: loss 0.2216, policy_loss:0.1812, value_loss:0.0404, time 4.55s, iter_time: 40.63ms\n",
      "iter 2600/2640/30000: loss 0.2222, policy_loss:0.1844, value_loss:0.0377, time 5.62s, iter_time: 41.31ms\n",
      "iter 2800/2816/30000: loss 0.2486, policy_loss:0.1882, value_loss:0.0603, time 6.37s, iter_time: 39.81ms\n",
      "step 3000: losses: train:0.2081, train_policy_loss:0.1806, train_value_loss:0.0275, val:0.2125, val_policy_loss:0.1831, val_value_loss:0.0293\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-32\n",
      "iter 3000/3168/30000: loss 0.2090, policy_loss:0.1819, value_loss:0.0271, time 2.96s, iter_time: 370.52ms\n",
      "iter 3200/3344/30000: loss 0.1811, policy_loss:0.1756, value_loss:0.0055, time 1.35s, iter_time: 42.33ms\n",
      "iter 3400/3520/30000: loss 0.2142, policy_loss:0.1777, value_loss:0.0364, time 2.22s, iter_time: 39.68ms\n",
      "iter 3600/3696/30000: loss 0.2136, policy_loss:0.1849, value_loss:0.0287, time 3.13s, iter_time: 39.13ms\n",
      "iter 3800/3872/30000: loss 0.1968, policy_loss:0.1779, value_loss:0.0189, time 4.10s, iter_time: 39.38ms\n",
      "step 4000: losses: train:0.2069, train_policy_loss:0.1792, train_value_loss:0.0278, val:0.2113, val_policy_loss:0.1824, val_value_loss:0.0289\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-32\n",
      "iter 4000/4048/30000: loss 0.2153, policy_loss:0.1846, value_loss:0.0306, time 12.59s, iter_time: 98.36ms\n",
      "iter 4200/4224/30000: loss 0.2106, policy_loss:0.1780, value_loss:0.0326, time 7.57s, iter_time: 49.80ms\n",
      "iter 4400/4576/30000: loss 0.2018, policy_loss:0.1780, value_loss:0.0238, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.1945, policy_loss:0.1839, value_loss:0.0106, time 0.97s, iter_time: 40.45ms\n",
      "iter 4800/4928/30000: loss 0.2323, policy_loss:0.1864, value_loss:0.0459, time 1.95s, iter_time: 40.65ms\n",
      "step 5000: losses: train:0.2074, train_policy_loss:0.1790, train_value_loss:0.0284, val:0.2124, val_policy_loss:0.1824, val_value_loss:0.0300\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-32/best.pt (val_loss=0.2078)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-32.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 735749\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99197 loss=803 draw=0 win1%=99.20 model-win1%=98.96\n",
      "actions=(1,): 94 win=23 loss=71 draw=0 win1%=24.47 model-win1%=22.46\n",
      "actions=(2,): 218 win=140 loss=78 draw=0 win1%=64.22 model-win1%=62.93\n",
      "actions=(3,): 89 win=34 loss=55 draw=0 win1%=38.20 model-win1%=36.23\n",
      "actions=(4,): 99181 win=98747 loss=434 draw=0 win1%=99.56 model-win1%=99.41\n",
      "actions=(4, 5): 95899 win=95488 loss=411 draw=0 win1%=99.57 model-win1%=99.38\n",
      "actions=(5,): 152 win=107 loss=45 draw=0 win1%=70.39 model-win1%=68.27\n",
      "actions=(6,): 143 win=62 loss=81 draw=0 win1%=43.36 model-win1%=48.48\n",
      "actions=(7,): 123 win=84 loss=39 draw=0 win1%=68.29 model-win1%=70.68\n",
      "\n",
      "=== Generation 33 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9992/10000 [01:24<00:00, 26.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=14, eval-per-second=7000.51, total-batches=1000, mean-eval-per-second=30410.48, mean-time-per-batch=0.017, mean-batch-size=528.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:24<00:00, 118.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 33...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2159, train_policy_loss:0.1842, train_value_loss:0.0317, val:0.2158, val_policy_loss:0.1854, val_value_loss:0.0305\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-33/best.pt\n",
      "iter 0/176/30000: loss 0.1985, policy_loss:0.1779, value_loss:0.0206, time 3.69s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2048, policy_loss:0.1848, value_loss:0.0200, time 1.12s, iter_time: 46.57ms\n",
      "iter 400/528/30000: loss 0.2346, policy_loss:0.1805, value_loss:0.0541, time 2.06s, iter_time: 42.84ms\n",
      "iter 600/704/30000: loss 0.2430, policy_loss:0.1993, value_loss:0.0436, time 3.04s, iter_time: 42.21ms\n",
      "iter 800/880/30000: loss 0.2012, policy_loss:0.1816, value_loss:0.0196, time 4.03s, iter_time: 41.96ms\n",
      "step 1000: losses: train:0.2139, train_policy_loss:0.1848, train_value_loss:0.0291, val:0.2221, val_policy_loss:0.1892, val_value_loss:0.0329\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-33\n",
      "iter 1000/1056/30000: loss 0.2214, policy_loss:0.1843, value_loss:0.0371, time 8.32s, iter_time: 69.29ms\n",
      "iter 1200/1232/30000: loss 0.2262, policy_loss:0.1909, value_loss:0.0352, time 6.41s, iter_time: 44.49ms\n",
      "iter 1400/1408/30000: loss 0.2433, policy_loss:0.1950, value_loss:0.0483, time 6.83s, iter_time: 40.68ms\n",
      "iter 1600/1760/30000: loss 0.2262, policy_loss:0.1892, value_loss:0.0370, time 0.70s, iter_time: 43.98ms\n",
      "iter 1800/1936/30000: loss 0.2094, policy_loss:0.1830, value_loss:0.0263, time 1.66s, iter_time: 41.60ms\n",
      "step 2000: losses: train:0.2116, train_policy_loss:0.1828, train_value_loss:0.0288, val:0.2244, val_policy_loss:0.1893, val_value_loss:0.0351\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-33\n",
      "iter 2000/2112/30000: loss 0.2217, policy_loss:0.1940, value_loss:0.0276, time 5.57s, iter_time: 87.02ms\n",
      "iter 2200/2288/30000: loss 0.1920, policy_loss:0.1784, value_loss:0.0137, time 3.46s, iter_time: 39.26ms\n",
      "iter 2400/2464/30000: loss 0.2275, policy_loss:0.1822, value_loss:0.0453, time 4.89s, iter_time: 43.64ms\n",
      "iter 2600/2640/30000: loss 0.2077, policy_loss:0.1849, value_loss:0.0228, time 5.61s, iter_time: 41.27ms\n",
      "iter 2800/2816/30000: loss 0.1964, policy_loss:0.1835, value_loss:0.0128, time 6.59s, iter_time: 41.17ms\n",
      "step 3000: losses: train:0.2099, train_policy_loss:0.1820, train_value_loss:0.0279, val:0.2239, val_policy_loss:0.1891, val_value_loss:0.0348\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-33\n",
      "iter 3000/3168/30000: loss 0.1982, policy_loss:0.1791, value_loss:0.0191, time 6.86s, iter_time: 857.85ms\n",
      "iter 3200/3344/30000: loss 0.2035, policy_loss:0.1793, value_loss:0.0242, time 1.24s, iter_time: 38.76ms\n",
      "iter 3400/3520/30000: loss 0.2133, policy_loss:0.1744, value_loss:0.0388, time 2.38s, iter_time: 42.55ms\n",
      "iter 3600/3696/30000: loss 0.2221, policy_loss:0.1820, value_loss:0.0401, time 3.21s, iter_time: 40.11ms\n",
      "iter 3800/3872/30000: loss 0.2327, policy_loss:0.1844, value_loss:0.0483, time 4.17s, iter_time: 40.08ms\n",
      "step 4000: losses: train:0.2082, train_policy_loss:0.1800, train_value_loss:0.0282, val:0.2246, val_policy_loss:0.1881, val_value_loss:0.0365\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-33\n",
      "iter 4000/4048/30000: loss 0.2101, policy_loss:0.1786, value_loss:0.0315, time 12.58s, iter_time: 98.27ms\n",
      "iter 4200/4224/30000: loss 0.2109, policy_loss:0.1829, value_loss:0.0280, time 6.80s, iter_time: 44.72ms\n",
      "iter 4400/4576/30000: loss 0.2039, policy_loss:0.1778, value_loss:0.0260, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.1929, policy_loss:0.1791, value_loss:0.0138, time 0.99s, iter_time: 41.14ms\n",
      "iter 4800/4928/30000: loss 0.1954, policy_loss:0.1776, value_loss:0.0178, time 1.94s, iter_time: 40.47ms\n",
      "step 5000: losses: train:0.2069, train_policy_loss:0.1796, train_value_loss:0.0273, val:0.2242, val_policy_loss:0.1877, val_value_loss:0.0365\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-33/best.pt (val_loss=0.2158)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-33.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 736125\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99203 loss=797 draw=0 win1%=99.20 model-win1%=98.96\n",
      "actions=(1,): 89 win=23 loss=66 draw=0 win1%=25.84 model-win1%=22.46\n",
      "actions=(2,): 211 win=151 loss=60 draw=0 win1%=71.56 model-win1%=62.93\n",
      "actions=(3,): 88 win=36 loss=52 draw=0 win1%=40.91 model-win1%=36.23\n",
      "actions=(4,): 99178 win=98724 loss=454 draw=0 win1%=99.54 model-win1%=99.41\n",
      "actions=(4, 5): 95885 win=95452 loss=433 draw=0 win1%=99.55 model-win1%=99.38\n",
      "actions=(5,): 164 win=118 loss=46 draw=0 win1%=71.95 model-win1%=68.27\n",
      "actions=(6,): 146 win=68 loss=78 draw=0 win1%=46.58 model-win1%=48.48\n",
      "actions=(7,): 124 win=83 loss=41 draw=0 win1%=66.94 model-win1%=70.68\n",
      "\n",
      "=== Generation 34 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9989/10000 [01:21<00:00, 14.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=13, eval-per-second=7165.98, total-batches=1000, mean-eval-per-second=33779.93, mean-time-per-batch=0.016, mean-batch-size=526.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:24<00:00, 118.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=1, eval-per-second=553.63, total-batches=2000, mean-eval-per-second=28739.77, mean-time-per-batch=0.009, mean-batch-size=264.87\n",
      "Writing 10000 trajectories...\n",
      "Training model for gen 34...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2179, train_policy_loss:0.1860, train_value_loss:0.0319, val:0.2204, val_policy_loss:0.1862, val_value_loss:0.0342\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-34/best.pt\n",
      "iter 0/176/30000: loss 0.2188, policy_loss:0.1853, value_loss:0.0335, time 8.52s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.1811, policy_loss:0.1753, value_loss:0.0058, time 1.05s, iter_time: 43.61ms\n",
      "iter 400/528/30000: loss 0.2056, policy_loss:0.1858, value_loss:0.0198, time 2.07s, iter_time: 43.20ms\n",
      "iter 600/704/30000: loss 0.2249, policy_loss:0.1833, value_loss:0.0415, time 3.10s, iter_time: 43.02ms\n",
      "iter 800/880/30000: loss 0.2039, policy_loss:0.1816, value_loss:0.0223, time 4.15s, iter_time: 43.27ms\n",
      "step 1000: losses: train:0.2162, train_policy_loss:0.1861, train_value_loss:0.0301, val:0.2258, val_policy_loss:0.1888, val_value_loss:0.0370\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-34\n",
      "iter 1000/1056/30000: loss 0.2457, policy_loss:0.1891, value_loss:0.0566, time 7.47s, iter_time: 62.24ms\n",
      "iter 1200/1232/30000: loss 0.2002, policy_loss:0.1826, value_loss:0.0176, time 5.79s, iter_time: 40.20ms\n",
      "iter 1400/1408/30000: loss 0.2666, policy_loss:0.1939, value_loss:0.0727, time 6.81s, iter_time: 40.52ms\n",
      "iter 1600/1760/30000: loss 0.2086, policy_loss:0.1786, value_loss:0.0301, time 0.77s, iter_time: 48.12ms\n",
      "iter 1800/1936/30000: loss 0.2075, policy_loss:0.1821, value_loss:0.0253, time 1.67s, iter_time: 41.67ms\n",
      "step 2000: losses: train:0.2118, train_policy_loss:0.1836, train_value_loss:0.0282, val:0.2258, val_policy_loss:0.1884, val_value_loss:0.0374\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-34\n",
      "iter 2000/2112/30000: loss 0.2175, policy_loss:0.1866, value_loss:0.0308, time 5.17s, iter_time: 80.80ms\n",
      "iter 2200/2288/30000: loss 0.1802, policy_loss:0.1735, value_loss:0.0067, time 3.37s, iter_time: 38.33ms\n",
      "iter 2400/2464/30000: loss 0.1978, policy_loss:0.1740, value_loss:0.0238, time 4.33s, iter_time: 38.67ms\n",
      "iter 2600/2640/30000: loss 0.2129, policy_loss:0.1855, value_loss:0.0275, time 6.52s, iter_time: 47.90ms\n",
      "iter 2800/2816/30000: loss 0.2009, policy_loss:0.1786, value_loss:0.0223, time 6.82s, iter_time: 42.64ms\n",
      "step 3000: losses: train:0.2092, train_policy_loss:0.1818, train_value_loss:0.0274, val:0.2262, val_policy_loss:0.1874, val_value_loss:0.0388\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-34\n",
      "iter 3000/3168/30000: loss 0.2053, policy_loss:0.1836, value_loss:0.0217, time 3.68s, iter_time: 459.48ms\n",
      "iter 3200/3344/30000: loss 0.2252, policy_loss:0.1867, value_loss:0.0385, time 1.37s, iter_time: 42.78ms\n",
      "iter 3400/3520/30000: loss 0.2094, policy_loss:0.1825, value_loss:0.0269, time 2.60s, iter_time: 46.38ms\n",
      "iter 3600/3696/30000: loss 0.1892, policy_loss:0.1829, value_loss:0.0063, time 3.48s, iter_time: 43.45ms\n",
      "iter 3800/3872/30000: loss 0.1952, policy_loss:0.1722, value_loss:0.0230, time 4.18s, iter_time: 40.23ms\n",
      "step 4000: losses: train:0.2082, train_policy_loss:0.1810, train_value_loss:0.0272, val:0.2240, val_policy_loss:0.1863, val_value_loss:0.0377\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-34\n",
      "iter 4000/4048/30000: loss 0.2459, policy_loss:0.1861, value_loss:0.0597, time 7.96s, iter_time: 62.21ms\n",
      "iter 4200/4224/30000: loss 0.2117, policy_loss:0.1768, value_loss:0.0349, time 6.70s, iter_time: 44.09ms\n",
      "iter 4400/4576/30000: loss 0.2068, policy_loss:0.1780, value_loss:0.0287, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2042, policy_loss:0.1859, value_loss:0.0182, time 1.00s, iter_time: 41.70ms\n",
      "iter 4800/4928/30000: loss 0.2131, policy_loss:0.1836, value_loss:0.0294, time 2.10s, iter_time: 43.85ms\n",
      "step 5000: losses: train:0.2076, train_policy_loss:0.1806, train_value_loss:0.0269, val:0.2261, val_policy_loss:0.1868, val_value_loss:0.0393\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-34/best.pt (val_loss=0.2204)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-34.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 736281\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99205 loss=795 draw=0 win1%=99.20 model-win1%=98.96\n",
      "actions=(1,): 94 win=30 loss=64 draw=0 win1%=31.91 model-win1%=22.46\n",
      "actions=(2,): 207 win=151 loss=56 draw=0 win1%=72.95 model-win1%=62.93\n",
      "actions=(3,): 82 win=37 loss=45 draw=0 win1%=45.12 model-win1%=36.23\n",
      "actions=(4,): 99166 win=98714 loss=452 draw=0 win1%=99.54 model-win1%=99.41\n",
      "actions=(4, 5): 95857 win=95425 loss=432 draw=0 win1%=99.55 model-win1%=99.38\n",
      "actions=(5,): 179 win=125 loss=54 draw=0 win1%=69.83 model-win1%=68.27\n",
      "actions=(6,): 142 win=65 loss=77 draw=0 win1%=45.77 model-win1%=48.48\n",
      "actions=(7,): 130 win=83 loss=47 draw=0 win1%=63.85 model-win1%=70.68\n",
      "\n",
      "=== Generation 35 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9992/10000 [01:22<00:00, 25.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.005 seconds, size=11, eval-per-second=2169.13, total-batches=1000, mean-eval-per-second=35728.86, mean-time-per-batch=0.015, mean-batch-size=537.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:23<00:00, 120.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 35...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2189, train_policy_loss:0.1878, train_value_loss:0.0311, val:0.2231, val_policy_loss:0.1890, val_value_loss:0.0341\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35/best.pt\n",
      "iter 0/176/30000: loss 0.2023, policy_loss:0.1798, value_loss:0.0225, time 3.20s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2153, policy_loss:0.1926, value_loss:0.0227, time 0.95s, iter_time: 39.47ms\n",
      "iter 400/528/30000: loss 0.2028, policy_loss:0.1801, value_loss:0.0227, time 2.03s, iter_time: 42.34ms\n",
      "iter 600/704/30000: loss 0.2013, policy_loss:0.1778, value_loss:0.0236, time 3.10s, iter_time: 43.02ms\n",
      "iter 800/880/30000: loss 0.2158, policy_loss:0.1883, value_loss:0.0275, time 3.89s, iter_time: 40.50ms\n",
      "step 1000: losses: train:0.2186, train_policy_loss:0.1881, train_value_loss:0.0306, val:0.2239, val_policy_loss:0.1907, val_value_loss:0.0332\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 1000/1056/30000: loss 0.2160, policy_loss:0.1865, value_loss:0.0295, time 8.33s, iter_time: 69.38ms\n",
      "iter 1200/1232/30000: loss 0.2003, policy_loss:0.1850, value_loss:0.0153, time 6.01s, iter_time: 41.70ms\n",
      "iter 1400/1408/30000: loss 0.1989, policy_loss:0.1804, value_loss:0.0186, time 6.83s, iter_time: 40.68ms\n",
      "iter 1600/1760/30000: loss 0.2413, policy_loss:0.2055, value_loss:0.0359, time 0.69s, iter_time: 43.28ms\n",
      "iter 1800/1936/30000: loss 0.2007, policy_loss:0.1875, value_loss:0.0131, time 1.81s, iter_time: 45.29ms\n",
      "step 2000: losses: train:0.2164, train_policy_loss:0.1860, train_value_loss:0.0304, val:0.2225, val_policy_loss:0.1901, val_value_loss:0.0324\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 2000/2112/30000: loss 0.2430, policy_loss:0.1887, value_loss:0.0542, time 5.47s, iter_time: 85.39ms\n",
      "iter 2200/2288/30000: loss 0.2047, policy_loss:0.1807, value_loss:0.0240, time 3.51s, iter_time: 39.90ms\n",
      "iter 2400/2464/30000: loss 0.1986, policy_loss:0.1772, value_loss:0.0214, time 5.08s, iter_time: 45.32ms\n",
      "iter 2600/2640/30000: loss 0.2147, policy_loss:0.1817, value_loss:0.0330, time 5.70s, iter_time: 41.93ms\n",
      "iter 2800/2816/30000: loss 0.2244, policy_loss:0.1883, value_loss:0.0361, time 6.64s, iter_time: 41.47ms\n",
      "step 3000: losses: train:0.2115, train_policy_loss:0.1825, train_value_loss:0.0290, val:0.2223, val_policy_loss:0.1884, val_value_loss:0.0338\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 3000/3168/30000: loss 0.2021, policy_loss:0.1859, value_loss:0.0162, time 2.99s, iter_time: 373.82ms\n",
      "iter 3200/3344/30000: loss 0.2115, policy_loss:0.1885, value_loss:0.0230, time 1.25s, iter_time: 39.14ms\n",
      "iter 3400/3520/30000: loss 0.2067, policy_loss:0.1811, value_loss:0.0257, time 2.17s, iter_time: 38.83ms\n",
      "iter 3600/3696/30000: loss 0.2266, policy_loss:0.1783, value_loss:0.0483, time 3.20s, iter_time: 40.03ms\n",
      "iter 3800/3872/30000: loss 0.2122, policy_loss:0.1820, value_loss:0.0302, time 4.44s, iter_time: 42.73ms\n",
      "step 4000: losses: train:0.2100, train_policy_loss:0.1808, train_value_loss:0.0292, val:0.2204, val_policy_loss:0.1870, val_value_loss:0.0334\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 4000/4048/30000: loss 0.1870, policy_loss:0.1736, value_loss:0.0134, time 12.53s, iter_time: 97.86ms\n",
      "iter 4200/4224/30000: loss 0.2365, policy_loss:0.1848, value_loss:0.0517, time 6.39s, iter_time: 42.04ms\n",
      "iter 4400/4576/30000: loss 0.2085, policy_loss:0.1789, value_loss:0.0296, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2216, policy_loss:0.1808, value_loss:0.0408, time 0.99s, iter_time: 41.43ms\n",
      "iter 4800/4928/30000: loss 0.2014, policy_loss:0.1759, value_loss:0.0255, time 1.80s, iter_time: 37.51ms\n",
      "step 5000: losses: train:0.2071, train_policy_loss:0.1797, train_value_loss:0.0275, val:0.2209, val_policy_loss:0.1872, val_value_loss:0.0337\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 5000/5104/30000: loss 0.1999, policy_loss:0.1733, value_loss:0.0266, time 6.09s, iter_time: 84.65ms\n",
      "iter 5200/5280/30000: loss 0.2041, policy_loss:0.1774, value_loss:0.0267, time 4.24s, iter_time: 44.15ms\n",
      "iter 5400/5456/30000: loss 0.1927, policy_loss:0.1770, value_loss:0.0156, time 4.92s, iter_time: 41.04ms\n",
      "iter 5600/5632/30000: loss 0.2180, policy_loss:0.1813, value_loss:0.0366, time 5.81s, iter_time: 40.37ms\n",
      "iter 5800/5808/30000: loss 0.2051, policy_loss:0.1792, value_loss:0.0258, time 6.69s, iter_time: 39.85ms\n",
      "step 6000: losses: train:0.2077, train_policy_loss:0.1801, train_value_loss:0.0276, val:0.2204, val_policy_loss:0.1871, val_value_loss:0.0333\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 6000/6160/30000: loss 0.2067, policy_loss:0.1786, value_loss:0.0281, time 3.36s, iter_time: 209.90ms\n",
      "iter 6200/6336/30000: loss 0.2149, policy_loss:0.1814, value_loss:0.0335, time 1.57s, iter_time: 39.27ms\n",
      "iter 6400/6512/30000: loss 0.2045, policy_loss:0.1807, value_loss:0.0238, time 2.86s, iter_time: 44.66ms\n",
      "iter 6600/6688/30000: loss 0.2083, policy_loss:0.1829, value_loss:0.0254, time 3.63s, iter_time: 41.22ms\n",
      "iter 6800/6864/30000: loss 0.1871, policy_loss:0.1784, value_loss:0.0086, time 4.72s, iter_time: 42.16ms\n",
      "step 7000: losses: train:0.2075, train_policy_loss:0.1803, train_value_loss:0.0271, val:0.2214, val_policy_loss:0.1872, val_value_loss:0.0343\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 7000/7040/30000: loss 0.2056, policy_loss:0.1734, value_loss:0.0322, time 8.10s, iter_time: 59.56ms\n",
      "iter 7200/7216/30000: loss 0.2178, policy_loss:0.1789, value_loss:0.0388, time 6.46s, iter_time: 40.36ms\n",
      "iter 7400/7568/30000: loss 0.2239, policy_loss:0.1878, value_loss:0.0361, time 0.35s, iter_time: 43.37ms\n",
      "iter 7600/7744/30000: loss 0.1855, policy_loss:0.1795, value_loss:0.0060, time 1.84s, iter_time: 57.62ms\n",
      "iter 7800/7920/30000: loss 0.2171, policy_loss:0.1813, value_loss:0.0358, time 2.27s, iter_time: 40.53ms\n",
      "step 8000: losses: train:0.2071, train_policy_loss:0.1800, train_value_loss:0.0270, val:0.2214, val_policy_loss:0.1872, val_value_loss:0.0343\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35\n",
      "iter 8000/8096/30000: loss 0.2056, policy_loss:0.1859, value_loss:0.0197, time 5.96s, iter_time: 74.55ms\n",
      "iter 8200/8272/30000: loss 0.2122, policy_loss:0.1871, value_loss:0.0250, time 4.66s, iter_time: 44.80ms\n",
      "iter 8400/8448/30000: loss 0.2017, policy_loss:0.1856, value_loss:0.0162, time 5.36s, iter_time: 41.89ms\n",
      "iter 8600/8624/30000: loss 0.2003, policy_loss:0.1810, value_loss:0.0193, time 6.12s, iter_time: 40.27ms\n",
      "iter 8800/8976/30000: loss 0.2213, policy_loss:0.1940, value_loss:0.0274, time 0.05s, iter_time: 0.00ms\n",
      "step 9000: losses: train:0.2080, train_policy_loss:0.1801, train_value_loss:0.0278, val:0.2224, val_policy_loss:0.1878, val_value_loss:0.0346\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-35/best.pt (val_loss=0.2204)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-35.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 736479\n",
      "  Avg trajectory length: 7.36\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99209 loss=791 draw=0 win1%=99.21 model-win1%=99.37\n",
      "actions=(1,): 92 win=30 loss=62 draw=0 win1%=32.61 model-win1%=38.33\n",
      "actions=(2,): 180 win=141 loss=39 draw=0 win1%=78.33 model-win1%=85.67\n",
      "actions=(3,): 88 win=36 loss=52 draw=0 win1%=40.91 model-win1%=56.52\n",
      "actions=(4,): 99174 win=98712 loss=462 draw=0 win1%=99.53 model-win1%=99.54\n",
      "actions=(4, 5): 95860 win=95417 loss=443 draw=0 win1%=99.54 model-win1%=99.59\n",
      "actions=(5,): 185 win=127 loss=58 draw=0 win1%=68.65 model-win1%=80.24\n",
      "actions=(6,): 137 win=74 loss=63 draw=0 win1%=54.01 model-win1%=58.18\n",
      "actions=(7,): 144 win=89 loss=55 draw=0 win1%=61.81 model-win1%=66.58\n",
      "\n",
      "=== Generation 36 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9989/10000 [01:27<00:00, 35.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.006 seconds, size=16, eval-per-second=2496.89, total-batches=1000, mean-eval-per-second=36359.74, mean-time-per-batch=0.017, mean-batch-size=605.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:28<00:00, 113.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 36...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2204, train_policy_loss:0.1867, train_value_loss:0.0337, val:0.2192, val_policy_loss:0.1888, val_value_loss:0.0304\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-36/best.pt\n",
      "iter 0/176/30000: loss 0.2289, policy_loss:0.1830, value_loss:0.0459, time 3.39s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.1993, policy_loss:0.1791, value_loss:0.0203, time 0.95s, iter_time: 39.64ms\n",
      "iter 400/528/30000: loss 0.2357, policy_loss:0.1857, value_loss:0.0500, time 2.05s, iter_time: 42.62ms\n",
      "iter 600/704/30000: loss 0.1978, policy_loss:0.1839, value_loss:0.0138, time 2.93s, iter_time: 40.65ms\n",
      "iter 800/880/30000: loss 0.1966, policy_loss:0.1798, value_loss:0.0168, time 3.87s, iter_time: 40.35ms\n",
      "step 1000: losses: train:0.2195, train_policy_loss:0.1876, train_value_loss:0.0318, val:0.2242, val_policy_loss:0.1920, val_value_loss:0.0322\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-36\n",
      "iter 1000/1056/30000: loss 0.2160, policy_loss:0.1844, value_loss:0.0316, time 8.01s, iter_time: 66.77ms\n",
      "iter 1200/1232/30000: loss 0.2457, policy_loss:0.2027, value_loss:0.0430, time 6.11s, iter_time: 42.46ms\n",
      "iter 1400/1408/30000: loss 0.2440, policy_loss:0.1913, value_loss:0.0527, time 6.88s, iter_time: 40.95ms\n",
      "iter 1600/1760/30000: loss 0.2282, policy_loss:0.1905, value_loss:0.0377, time 0.70s, iter_time: 43.58ms\n",
      "iter 1800/1936/30000: loss 0.1951, policy_loss:0.1809, value_loss:0.0142, time 1.85s, iter_time: 46.20ms\n",
      "step 2000: losses: train:0.2181, train_policy_loss:0.1866, train_value_loss:0.0316, val:0.2262, val_policy_loss:0.1925, val_value_loss:0.0337\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-36\n",
      "iter 2000/2112/30000: loss 0.1891, policy_loss:0.1764, value_loss:0.0126, time 5.47s, iter_time: 85.41ms\n",
      "iter 2200/2288/30000: loss 0.2347, policy_loss:0.1870, value_loss:0.0477, time 3.63s, iter_time: 41.30ms\n",
      "iter 2400/2464/30000: loss 0.2354, policy_loss:0.1969, value_loss:0.0385, time 4.69s, iter_time: 41.88ms\n",
      "iter 2600/2640/30000: loss 0.2138, policy_loss:0.1870, value_loss:0.0269, time 5.54s, iter_time: 40.70ms\n",
      "iter 2800/2816/30000: loss 0.2305, policy_loss:0.1921, value_loss:0.0384, time 6.57s, iter_time: 41.04ms\n",
      "step 3000: losses: train:0.2158, train_policy_loss:0.1852, train_value_loss:0.0306, val:0.2261, val_policy_loss:0.1916, val_value_loss:0.0345\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-36\n",
      "iter 3000/3168/30000: loss 0.2170, policy_loss:0.1855, value_loss:0.0315, time 3.19s, iter_time: 398.76ms\n",
      "iter 3200/3344/30000: loss 0.2113, policy_loss:0.1872, value_loss:0.0241, time 1.24s, iter_time: 38.80ms\n",
      "iter 3400/3520/30000: loss 0.2383, policy_loss:0.1900, value_loss:0.0483, time 2.23s, iter_time: 39.86ms\n",
      "iter 3600/3696/30000: loss 0.2047, policy_loss:0.1858, value_loss:0.0190, time 3.28s, iter_time: 41.04ms\n",
      "iter 3800/3872/30000: loss 0.2082, policy_loss:0.1852, value_loss:0.0229, time 4.25s, iter_time: 40.88ms\n",
      "step 4000: losses: train:0.2141, train_policy_loss:0.1834, train_value_loss:0.0307, val:0.2238, val_policy_loss:0.1905, val_value_loss:0.0333\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-36\n",
      "iter 4000/4048/30000: loss 0.2257, policy_loss:0.1848, value_loss:0.0409, time 7.81s, iter_time: 61.05ms\n",
      "iter 4200/4224/30000: loss 0.2195, policy_loss:0.1859, value_loss:0.0336, time 6.48s, iter_time: 42.65ms\n",
      "iter 4400/4576/30000: loss 0.2312, policy_loss:0.1786, value_loss:0.0527, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2089, policy_loss:0.1812, value_loss:0.0278, time 0.95s, iter_time: 39.45ms\n",
      "iter 4800/4928/30000: loss 0.2149, policy_loss:0.1837, value_loss:0.0312, time 1.90s, iter_time: 39.52ms\n",
      "step 5000: losses: train:0.2116, train_policy_loss:0.1830, train_value_loss:0.0286, val:0.2248, val_policy_loss:0.1905, val_value_loss:0.0344\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-36/best.pt (val_loss=0.2192)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-36.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 737542\n",
      "  Avg trajectory length: 7.38\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99180 loss=820 draw=0 win1%=99.18 model-win1%=99.37\n",
      "actions=(1,): 94 win=31 loss=63 draw=0 win1%=32.98 model-win1%=38.33\n",
      "actions=(2,): 249 win=221 loss=28 draw=0 win1%=88.76 model-win1%=85.67\n",
      "actions=(3,): 92 win=42 loss=50 draw=0 win1%=45.65 model-win1%=56.52\n",
      "actions=(4,): 99045 win=98542 loss=503 draw=0 win1%=99.49 model-win1%=99.54\n",
      "actions=(4, 5): 95736 win=95252 loss=484 draw=0 win1%=99.49 model-win1%=99.59\n",
      "actions=(5,): 218 win=155 loss=63 draw=0 win1%=71.10 model-win1%=80.24\n",
      "actions=(6,): 142 win=86 loss=56 draw=0 win1%=60.56 model-win1%=58.18\n",
      "actions=(7,): 160 win=103 loss=57 draw=0 win1%=64.38 model-win1%=66.58\n",
      "\n",
      "=== Generation 37 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9983/10000 [01:29<00:00, 17.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=17, eval-per-second=8896.22, total-batches=1000, mean-eval-per-second=33171.30, mean-time-per-batch=0.018, mean-batch-size=600.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:31<00:00, 109.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 37...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2275, train_policy_loss:0.1925, train_value_loss:0.0350, val:0.2258, val_policy_loss:0.1916, val_value_loss:0.0342\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-37/best.pt\n",
      "iter 0/176/30000: loss 0.2186, policy_loss:0.1901, value_loss:0.0285, time 4.12s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2316, policy_loss:0.1875, value_loss:0.0441, time 1.13s, iter_time: 46.99ms\n",
      "iter 400/528/30000: loss 0.2166, policy_loss:0.1935, value_loss:0.0232, time 2.07s, iter_time: 43.13ms\n",
      "iter 600/704/30000: loss 0.2104, policy_loss:0.1874, value_loss:0.0230, time 3.00s, iter_time: 41.64ms\n",
      "iter 800/880/30000: loss 0.2423, policy_loss:0.1956, value_loss:0.0467, time 4.03s, iter_time: 41.97ms\n",
      "step 1000: losses: train:0.2246, train_policy_loss:0.1912, train_value_loss:0.0334, val:0.2272, val_policy_loss:0.1942, val_value_loss:0.0330\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-37\n",
      "iter 1000/1056/30000: loss 0.2013, policy_loss:0.1834, value_loss:0.0179, time 8.01s, iter_time: 66.73ms\n",
      "iter 1200/1232/30000: loss 0.2045, policy_loss:0.1817, value_loss:0.0228, time 7.08s, iter_time: 49.19ms\n",
      "iter 1400/1408/30000: loss 0.2070, policy_loss:0.1893, value_loss:0.0177, time 6.97s, iter_time: 41.48ms\n",
      "iter 1600/1760/30000: loss 0.2309, policy_loss:0.1915, value_loss:0.0394, time 0.68s, iter_time: 42.25ms\n",
      "iter 1800/1936/30000: loss 0.2364, policy_loss:0.1874, value_loss:0.0490, time 1.65s, iter_time: 41.25ms\n",
      "step 2000: losses: train:0.2233, train_policy_loss:0.1897, train_value_loss:0.0336, val:0.2305, val_policy_loss:0.1935, val_value_loss:0.0371\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-37\n",
      "iter 2000/2112/30000: loss 0.2176, policy_loss:0.1979, value_loss:0.0197, time 5.40s, iter_time: 84.36ms\n",
      "iter 2200/2288/30000: loss 0.2218, policy_loss:0.1854, value_loss:0.0364, time 3.46s, iter_time: 39.29ms\n",
      "iter 2400/2464/30000: loss 0.2390, policy_loss:0.1923, value_loss:0.0468, time 4.40s, iter_time: 39.28ms\n",
      "iter 2600/2640/30000: loss 0.2532, policy_loss:0.1984, value_loss:0.0547, time 6.06s, iter_time: 44.58ms\n",
      "iter 2800/2816/30000: loss 0.2243, policy_loss:0.1925, value_loss:0.0318, time 6.94s, iter_time: 43.36ms\n",
      "step 3000: losses: train:0.2201, train_policy_loss:0.1879, train_value_loss:0.0322, val:0.2286, val_policy_loss:0.1935, val_value_loss:0.0351\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-37\n",
      "iter 3000/3168/30000: loss 0.2224, policy_loss:0.1878, value_loss:0.0346, time 7.97s, iter_time: 996.85ms\n",
      "iter 3200/3344/30000: loss 0.2078, policy_loss:0.1870, value_loss:0.0209, time 1.53s, iter_time: 47.79ms\n",
      "iter 3400/3520/30000: loss 0.2525, policy_loss:0.1916, value_loss:0.0610, time 2.12s, iter_time: 37.82ms\n",
      "iter 3600/3696/30000: loss 0.2021, policy_loss:0.1837, value_loss:0.0183, time 3.12s, iter_time: 38.99ms\n",
      "iter 3800/3872/30000: loss 0.2261, policy_loss:0.1917, value_loss:0.0344, time 4.16s, iter_time: 40.03ms\n",
      "step 4000: losses: train:0.2168, train_policy_loss:0.1863, train_value_loss:0.0305, val:0.2288, val_policy_loss:0.1921, val_value_loss:0.0367\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-37\n",
      "iter 4000/4048/30000: loss 0.1973, policy_loss:0.1860, value_loss:0.0112, time 8.28s, iter_time: 64.66ms\n",
      "iter 4200/4224/30000: loss 0.2210, policy_loss:0.1929, value_loss:0.0281, time 6.12s, iter_time: 40.25ms\n",
      "iter 4400/4576/30000: loss 0.2149, policy_loss:0.1865, value_loss:0.0285, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2117, policy_loss:0.1841, value_loss:0.0276, time 1.07s, iter_time: 44.59ms\n",
      "iter 4800/4928/30000: loss 0.2145, policy_loss:0.1874, value_loss:0.0271, time 1.97s, iter_time: 40.98ms\n",
      "step 5000: losses: train:0.2169, train_policy_loss:0.1860, train_value_loss:0.0309, val:0.2288, val_policy_loss:0.1919, val_value_loss:0.0369\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-37/best.pt (val_loss=0.2258)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-37.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 738561\n",
      "  Avg trajectory length: 7.39\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99167 loss=833 draw=0 win1%=99.17 model-win1%=99.37\n",
      "actions=(1,): 100 win=32 loss=68 draw=0 win1%=32.00 model-win1%=38.33\n",
      "actions=(2,): 303 win=287 loss=16 draw=0 win1%=94.72 model-win1%=85.67\n",
      "actions=(3,): 96 win=49 loss=47 draw=0 win1%=51.04 model-win1%=56.52\n",
      "actions=(4,): 98934 win=98407 loss=527 draw=0 win1%=99.47 model-win1%=99.54\n",
      "actions=(4, 5): 95632 win=95128 loss=504 draw=0 win1%=99.47 model-win1%=99.59\n",
      "actions=(5,): 258 win=187 loss=71 draw=0 win1%=72.48 model-win1%=80.24\n",
      "actions=(6,): 137 win=89 loss=48 draw=0 win1%=64.96 model-win1%=58.18\n",
      "actions=(7,): 172 win=116 loss=56 draw=0 win1%=67.44 model-win1%=66.58\n",
      "\n",
      "=== Generation 38 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9987/10000 [01:25<00:00, 22.49it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=13, eval-per-second=6602.00, total-batches=1000, mean-eval-per-second=36864.61, mean-time-per-batch=0.016, mean-batch-size=586.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:28<00:00, 113.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 38...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2332, train_policy_loss:0.1966, train_value_loss:0.0366, val:0.2342, val_policy_loss:0.1986, val_value_loss:0.0356\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38/best.pt\n",
      "iter 0/176/30000: loss 0.2199, policy_loss:0.1861, value_loss:0.0339, time 4.31s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2311, policy_loss:0.1898, value_loss:0.0412, time 0.96s, iter_time: 39.97ms\n",
      "iter 400/528/30000: loss 0.2357, policy_loss:0.1891, value_loss:0.0466, time 2.00s, iter_time: 41.70ms\n",
      "iter 600/704/30000: loss 0.2290, policy_loss:0.1973, value_loss:0.0316, time 3.67s, iter_time: 50.90ms\n",
      "iter 800/880/30000: loss 0.2203, policy_loss:0.1938, value_loss:0.0265, time 4.07s, iter_time: 42.38ms\n",
      "step 1000: losses: train:0.2290, train_policy_loss:0.1946, train_value_loss:0.0344, val:0.2312, val_policy_loss:0.1973, val_value_loss:0.0338\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38\n",
      "iter 1000/1056/30000: loss 0.2300, policy_loss:0.1966, value_loss:0.0334, time 7.70s, iter_time: 64.14ms\n",
      "iter 1200/1232/30000: loss 0.2251, policy_loss:0.1919, value_loss:0.0332, time 5.79s, iter_time: 40.24ms\n",
      "iter 1400/1408/30000: loss 0.2337, policy_loss:0.1955, value_loss:0.0382, time 6.72s, iter_time: 40.00ms\n",
      "iter 1600/1760/30000: loss 0.2351, policy_loss:0.2063, value_loss:0.0287, time 0.71s, iter_time: 44.15ms\n",
      "iter 1800/1936/30000: loss 0.2508, policy_loss:0.1933, value_loss:0.0575, time 1.65s, iter_time: 41.22ms\n",
      "step 2000: losses: train:0.2254, train_policy_loss:0.1924, train_value_loss:0.0331, val:0.2329, val_policy_loss:0.1975, val_value_loss:0.0355\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38\n",
      "iter 2000/2112/30000: loss 0.2067, policy_loss:0.1925, value_loss:0.0142, time 5.81s, iter_time: 90.72ms\n",
      "iter 2200/2288/30000: loss 0.1998, policy_loss:0.1857, value_loss:0.0141, time 3.55s, iter_time: 40.39ms\n",
      "iter 2400/2464/30000: loss 0.2199, policy_loss:0.1909, value_loss:0.0291, time 4.48s, iter_time: 40.02ms\n",
      "iter 2600/2640/30000: loss 0.2060, policy_loss:0.1942, value_loss:0.0117, time 5.59s, iter_time: 41.11ms\n",
      "iter 2800/2816/30000: loss 0.2419, policy_loss:0.1924, value_loss:0.0495, time 6.33s, iter_time: 39.56ms\n",
      "step 3000: losses: train:0.2226, train_policy_loss:0.1903, train_value_loss:0.0322, val:0.2324, val_policy_loss:0.1958, val_value_loss:0.0366\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38\n",
      "iter 3000/3168/30000: loss 0.2251, policy_loss:0.1894, value_loss:0.0358, time 5.76s, iter_time: 719.90ms\n",
      "iter 3200/3344/30000: loss 0.2171, policy_loss:0.1973, value_loss:0.0198, time 1.41s, iter_time: 44.05ms\n",
      "iter 3400/3520/30000: loss 0.1964, policy_loss:0.1853, value_loss:0.0110, time 2.34s, iter_time: 41.83ms\n",
      "iter 3600/3696/30000: loss 0.2023, policy_loss:0.1901, value_loss:0.0122, time 3.26s, iter_time: 40.73ms\n",
      "iter 3800/3872/30000: loss 0.2582, policy_loss:0.1877, value_loss:0.0706, time 4.26s, iter_time: 40.92ms\n",
      "step 4000: losses: train:0.2172, train_policy_loss:0.1883, train_value_loss:0.0289, val:0.2328, val_policy_loss:0.1959, val_value_loss:0.0370\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38\n",
      "iter 4000/4048/30000: loss 0.2639, policy_loss:0.1892, value_loss:0.0747, time 7.83s, iter_time: 61.21ms\n",
      "iter 4200/4224/30000: loss 0.2136, policy_loss:0.1915, value_loss:0.0221, time 5.93s, iter_time: 39.00ms\n",
      "iter 4400/4576/30000: loss 0.2264, policy_loss:0.1892, value_loss:0.0372, time 0.04s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2192, policy_loss:0.1854, value_loss:0.0339, time 1.03s, iter_time: 42.80ms\n",
      "iter 4800/4928/30000: loss 0.2043, policy_loss:0.1837, value_loss:0.0206, time 1.94s, iter_time: 40.45ms\n",
      "step 5000: losses: train:0.2188, train_policy_loss:0.1878, train_value_loss:0.0310, val:0.2330, val_policy_loss:0.1953, val_value_loss:0.0376\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38\n",
      "iter 5000/5104/30000: loss 0.2465, policy_loss:0.1924, value_loss:0.0540, time 11.66s, iter_time: 161.98ms\n",
      "iter 5200/5280/30000: loss 0.1915, policy_loss:0.1799, value_loss:0.0116, time 3.98s, iter_time: 41.45ms\n",
      "iter 5400/5456/30000: loss 0.2353, policy_loss:0.1933, value_loss:0.0420, time 4.95s, iter_time: 41.25ms\n",
      "iter 5600/5632/30000: loss 0.2113, policy_loss:0.1894, value_loss:0.0219, time 5.98s, iter_time: 41.49ms\n",
      "iter 5800/5808/30000: loss 0.2252, policy_loss:0.1932, value_loss:0.0320, time 12.62s, iter_time: 75.11ms\n",
      "step 6000: losses: train:0.2180, train_policy_loss:0.1875, train_value_loss:0.0304, val:0.2350, val_policy_loss:0.1962, val_value_loss:0.0388\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-38/best.pt (val_loss=0.2312)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-38.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 739019\n",
      "  Avg trajectory length: 7.39\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99189 loss=811 draw=0 win1%=99.19 model-win1%=99.15\n",
      "actions=(1,): 99 win=35 loss=64 draw=0 win1%=35.35 model-win1%=40.36\n",
      "actions=(2,): 364 win=348 loss=16 draw=0 win1%=95.60 model-win1%=93.59\n",
      "actions=(3,): 111 win=63 loss=48 draw=0 win1%=56.76 model-win1%=59.82\n",
      "actions=(4,): 98818 win=98304 loss=514 draw=0 win1%=99.48 model-win1%=99.54\n",
      "actions=(4, 5): 95551 win=95062 loss=489 draw=0 win1%=99.49 model-win1%=99.46\n",
      "actions=(5,): 297 win=223 loss=74 draw=0 win1%=75.08 model-win1%=77.72\n",
      "actions=(6,): 141 win=97 loss=44 draw=0 win1%=68.79 model-win1%=57.09\n",
      "actions=(7,): 170 win=119 loss=51 draw=0 win1%=70.00 model-win1%=61.42\n",
      "\n",
      "=== Generation 39 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9993/10000 [01:23<00:00, 35.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=8, eval-per-second=5051.10, total-batches=1000, mean-eval-per-second=36337.44, mean-time-per-batch=0.015, mean-batch-size=556.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:24<00:00, 118.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 39...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:0.2290, train_policy_loss:0.1959, train_value_loss:0.0331, val:0.2334, val_policy_loss:0.1973, val_value_loss:0.0361\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-39/best.pt\n",
      "iter 0/176/30000: loss 0.2122, policy_loss:0.1846, value_loss:0.0277, time 4.28s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2209, policy_loss:0.1913, value_loss:0.0297, time 1.02s, iter_time: 42.68ms\n",
      "iter 400/528/30000: loss 0.2239, policy_loss:0.1963, value_loss:0.0275, time 2.04s, iter_time: 42.41ms\n",
      "iter 600/704/30000: loss 0.2177, policy_loss:0.1843, value_loss:0.0334, time 3.06s, iter_time: 42.55ms\n",
      "iter 800/880/30000: loss 0.2109, policy_loss:0.1952, value_loss:0.0157, time 3.99s, iter_time: 41.57ms\n",
      "step 1000: losses: train:0.2301, train_policy_loss:0.1962, train_value_loss:0.0339, val:0.2394, val_policy_loss:0.2008, val_value_loss:0.0386\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-39\n",
      "iter 1000/1056/30000: loss 0.2388, policy_loss:0.2020, value_loss:0.0369, time 7.54s, iter_time: 62.82ms\n",
      "iter 1200/1232/30000: loss 0.2294, policy_loss:0.1931, value_loss:0.0363, time 5.88s, iter_time: 40.83ms\n",
      "iter 1400/1408/30000: loss 0.2043, policy_loss:0.1923, value_loss:0.0120, time 6.83s, iter_time: 40.66ms\n",
      "iter 1600/1760/30000: loss 0.2270, policy_loss:0.1883, value_loss:0.0387, time 0.64s, iter_time: 39.88ms\n",
      "iter 1800/1936/30000: loss 0.2639, policy_loss:0.1955, value_loss:0.0685, time 1.55s, iter_time: 38.78ms\n",
      "step 2000: losses: train:0.2229, train_policy_loss:0.1930, train_value_loss:0.0299, val:0.2395, val_policy_loss:0.2005, val_value_loss:0.0390\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-39\n",
      "iter 2000/2112/30000: loss 0.2573, policy_loss:0.1998, value_loss:0.0575, time 5.32s, iter_time: 83.06ms\n",
      "iter 2200/2288/30000: loss 0.2133, policy_loss:0.1879, value_loss:0.0255, time 3.53s, iter_time: 40.09ms\n",
      "iter 2400/2464/30000: loss 0.2512, policy_loss:0.1965, value_loss:0.0547, time 4.51s, iter_time: 40.30ms\n",
      "iter 2600/2640/30000: loss 0.2264, policy_loss:0.1931, value_loss:0.0333, time 5.43s, iter_time: 39.95ms\n",
      "iter 2800/2816/30000: loss 0.2255, policy_loss:0.1980, value_loss:0.0276, time 6.50s, iter_time: 40.65ms\n",
      "step 3000: losses: train:0.2217, train_policy_loss:0.1918, train_value_loss:0.0299, val:0.2390, val_policy_loss:0.1993, val_value_loss:0.0397\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-39\n",
      "iter 3000/3168/30000: loss 0.2401, policy_loss:0.1976, value_loss:0.0425, time 3.15s, iter_time: 394.14ms\n",
      "iter 3200/3344/30000: loss 0.2230, policy_loss:0.1934, value_loss:0.0295, time 1.38s, iter_time: 43.16ms\n",
      "iter 3400/3520/30000: loss 0.2438, policy_loss:0.1938, value_loss:0.0499, time 2.30s, iter_time: 41.07ms\n",
      "iter 3600/3696/30000: loss 0.1896, policy_loss:0.1822, value_loss:0.0075, time 3.20s, iter_time: 40.02ms\n",
      "iter 3800/3872/30000: loss 0.2261, policy_loss:0.1918, value_loss:0.0343, time 4.21s, iter_time: 40.47ms\n",
      "step 4000: losses: train:0.2190, train_policy_loss:0.1896, train_value_loss:0.0294, val:0.2389, val_policy_loss:0.1981, val_value_loss:0.0408\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-39\n",
      "iter 4000/4048/30000: loss 0.2623, policy_loss:0.1958, value_loss:0.0665, time 7.95s, iter_time: 62.14ms\n",
      "iter 4200/4224/30000: loss 0.2143, policy_loss:0.1860, value_loss:0.0283, time 6.30s, iter_time: 41.47ms\n",
      "iter 4400/4576/30000: loss 0.2253, policy_loss:0.1843, value_loss:0.0411, time 0.05s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2329, policy_loss:0.1923, value_loss:0.0406, time 0.98s, iter_time: 40.80ms\n",
      "iter 4800/4928/30000: loss 0.2257, policy_loss:0.1900, value_loss:0.0357, time 1.94s, iter_time: 40.40ms\n",
      "step 5000: losses: train:0.2191, train_policy_loss:0.1893, train_value_loss:0.0298, val:0.2382, val_policy_loss:0.1975, val_value_loss:0.0408\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-39/best.pt (val_loss=0.2334)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-39.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 739213\n",
      "  Avg trajectory length: 7.39\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99221 loss=779 draw=0 win1%=99.22 model-win1%=99.15\n",
      "actions=(1,): 97 win=38 loss=59 draw=0 win1%=39.18 model-win1%=40.36\n",
      "actions=(2,): 438 win=420 loss=18 draw=0 win1%=95.89 model-win1%=93.59\n",
      "actions=(3,): 116 win=71 loss=45 draw=0 win1%=61.21 model-win1%=59.82\n",
      "actions=(4,): 98719 win=98227 loss=492 draw=0 win1%=99.50 model-win1%=99.54\n",
      "actions=(4, 5): 95472 win=95003 loss=469 draw=0 win1%=99.51 model-win1%=99.46\n",
      "actions=(5,): 318 win=245 loss=73 draw=0 win1%=77.04 model-win1%=77.72\n",
      "actions=(6,): 144 win=102 loss=42 draw=0 win1%=70.83 model-win1%=57.09\n",
      "actions=(7,): 168 win=118 loss=50 draw=0 win1%=70.24 model-win1%=61.42\n",
      "\n",
      "=== Generation 40 ===\n",
      "Playing 10000 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|█████████▉| 9988/10000 [01:25<00:00, 13.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.002 seconds, size=13, eval-per-second=7869.24, total-batches=1000, mean-eval-per-second=32424.49, mean-time-per-batch=0.017, mean-batch-size=562.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 10000/10000 [01:26<00:00, 115.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 10000 trajectories...\n",
      "Training model for gen 40...\n",
      "num decayed parameter tensors: 19, with 200,064 parameters\n",
      "num non-decayed parameter tensors: 11, with 586 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:0.2313, train_policy_loss:0.1982, train_value_loss:0.0331, val:0.2272, val_policy_loss:0.1967, val_value_loss:0.0305\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40/best.pt\n",
      "iter 0/176/30000: loss 0.2346, policy_loss:0.1977, value_loss:0.0370, time 3.90s, iter_time: 0.00ms\n",
      "iter 200/352/30000: loss 0.2351, policy_loss:0.1971, value_loss:0.0381, time 1.13s, iter_time: 47.11ms\n",
      "iter 400/528/30000: loss 0.2233, policy_loss:0.1894, value_loss:0.0339, time 2.34s, iter_time: 48.83ms\n",
      "iter 600/704/30000: loss 0.2026, policy_loss:0.1894, value_loss:0.0132, time 3.18s, iter_time: 44.10ms\n",
      "iter 800/880/30000: loss 0.2142, policy_loss:0.1939, value_loss:0.0203, time 3.96s, iter_time: 41.20ms\n",
      "step 1000: losses: train:0.2301, train_policy_loss:0.1970, train_value_loss:0.0331, val:0.2273, val_policy_loss:0.1976, val_value_loss:0.0297\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 1000/1056/30000: loss 0.2339, policy_loss:0.2040, value_loss:0.0299, time 7.62s, iter_time: 63.50ms\n",
      "iter 1200/1232/30000: loss 0.2475, policy_loss:0.2061, value_loss:0.0413, time 6.07s, iter_time: 42.18ms\n",
      "iter 1400/1408/30000: loss 0.2252, policy_loss:0.1912, value_loss:0.0340, time 6.77s, iter_time: 40.29ms\n",
      "iter 1600/1760/30000: loss 0.2489, policy_loss:0.2014, value_loss:0.0475, time 0.63s, iter_time: 39.26ms\n",
      "iter 1800/1936/30000: loss 0.2401, policy_loss:0.1966, value_loss:0.0435, time 1.54s, iter_time: 38.41ms\n",
      "step 2000: losses: train:0.2286, train_policy_loss:0.1960, train_value_loss:0.0327, val:0.2279, val_policy_loss:0.1972, val_value_loss:0.0307\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 2000/2112/30000: loss 0.2357, policy_loss:0.1959, value_loss:0.0398, time 6.28s, iter_time: 98.19ms\n",
      "iter 2200/2288/30000: loss 0.2024, policy_loss:0.1871, value_loss:0.0152, time 3.74s, iter_time: 42.49ms\n",
      "iter 2400/2464/30000: loss 0.2470, policy_loss:0.2048, value_loss:0.0422, time 4.88s, iter_time: 43.56ms\n",
      "iter 2600/2640/30000: loss 0.2244, policy_loss:0.1976, value_loss:0.0267, time 5.39s, iter_time: 39.63ms\n",
      "iter 2800/2816/30000: loss 0.2383, policy_loss:0.1945, value_loss:0.0438, time 6.27s, iter_time: 39.16ms\n",
      "step 3000: losses: train:0.2238, train_policy_loss:0.1928, train_value_loss:0.0310, val:0.2278, val_policy_loss:0.1968, val_value_loss:0.0310\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 3000/3168/30000: loss 0.2433, policy_loss:0.1942, value_loss:0.0491, time 3.51s, iter_time: 438.71ms\n",
      "iter 3200/3344/30000: loss 0.2243, policy_loss:0.1936, value_loss:0.0308, time 1.28s, iter_time: 40.15ms\n",
      "iter 3400/3520/30000: loss 0.2019, policy_loss:0.1888, value_loss:0.0132, time 2.22s, iter_time: 39.56ms\n",
      "iter 3600/3696/30000: loss 0.2514, policy_loss:0.2007, value_loss:0.0507, time 3.45s, iter_time: 43.10ms\n",
      "iter 3800/3872/30000: loss 0.2177, policy_loss:0.1951, value_loss:0.0226, time 4.55s, iter_time: 43.78ms\n",
      "step 4000: losses: train:0.2208, train_policy_loss:0.1909, train_value_loss:0.0299, val:0.2258, val_policy_loss:0.1952, val_value_loss:0.0306\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 4000/4048/30000: loss 0.2090, policy_loss:0.1882, value_loss:0.0208, time 8.43s, iter_time: 65.82ms\n",
      "iter 4200/4224/30000: loss 0.2072, policy_loss:0.1889, value_loss:0.0183, time 6.32s, iter_time: 41.56ms\n",
      "iter 4400/4576/30000: loss 0.2140, policy_loss:0.1838, value_loss:0.0302, time 0.05s, iter_time: 0.00ms\n",
      "iter 4600/4752/30000: loss 0.2120, policy_loss:0.1891, value_loss:0.0229, time 0.93s, iter_time: 38.77ms\n",
      "iter 4800/4928/30000: loss 0.2412, policy_loss:0.1891, value_loss:0.0521, time 1.85s, iter_time: 38.56ms\n",
      "step 5000: losses: train:0.2200, train_policy_loss:0.1905, train_value_loss:0.0294, val:0.2258, val_policy_loss:0.1952, val_value_loss:0.0306\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40/best.pt\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 5000/5104/30000: loss 0.2191, policy_loss:0.1854, value_loss:0.0337, time 6.11s, iter_time: 84.88ms\n",
      "iter 5200/5280/30000: loss 0.2141, policy_loss:0.1862, value_loss:0.0280, time 3.85s, iter_time: 40.11ms\n",
      "iter 5400/5456/30000: loss 0.2052, policy_loss:0.1847, value_loss:0.0205, time 4.90s, iter_time: 40.85ms\n",
      "iter 5600/5632/30000: loss 0.2208, policy_loss:0.1956, value_loss:0.0252, time 5.76s, iter_time: 40.03ms\n",
      "iter 5800/5808/30000: loss 0.2432, policy_loss:0.1921, value_loss:0.0511, time 6.94s, iter_time: 41.30ms\n",
      "step 6000: losses: train:0.2193, train_policy_loss:0.1900, train_value_loss:0.0293, val:0.2260, val_policy_loss:0.1953, val_value_loss:0.0308\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 6000/6160/30000: loss 0.2196, policy_loss:0.1927, value_loss:0.0269, time 3.64s, iter_time: 227.57ms\n",
      "iter 6200/6336/30000: loss 0.2457, policy_loss:0.1969, value_loss:0.0488, time 1.55s, iter_time: 38.81ms\n",
      "iter 6400/6512/30000: loss 0.2069, policy_loss:0.1844, value_loss:0.0225, time 2.75s, iter_time: 43.03ms\n",
      "iter 6600/6688/30000: loss 0.2271, policy_loss:0.1889, value_loss:0.0382, time 3.67s, iter_time: 41.74ms\n",
      "iter 6800/6864/30000: loss 0.1998, policy_loss:0.1856, value_loss:0.0142, time 4.45s, iter_time: 39.70ms\n",
      "step 7000: losses: train:0.2220, train_policy_loss:0.1911, train_value_loss:0.0309, val:0.2262, val_policy_loss:0.1953, val_value_loss:0.0309\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 7000/7040/30000: loss 0.2017, policy_loss:0.1850, value_loss:0.0167, time 8.47s, iter_time: 62.29ms\n",
      "iter 7200/7216/30000: loss 0.2179, policy_loss:0.1863, value_loss:0.0316, time 6.41s, iter_time: 40.06ms\n",
      "iter 7400/7568/30000: loss 0.2062, policy_loss:0.1853, value_loss:0.0209, time 0.40s, iter_time: 49.41ms\n",
      "iter 7600/7744/30000: loss 0.2221, policy_loss:0.1920, value_loss:0.0301, time 1.50s, iter_time: 46.82ms\n",
      "iter 7800/7920/30000: loss 0.2059, policy_loss:0.1868, value_loss:0.0191, time 2.72s, iter_time: 48.55ms\n",
      "step 8000: losses: train:0.2199, train_policy_loss:0.1899, train_value_loss:0.0300, val:0.2267, val_policy_loss:0.1954, val_value_loss:0.0314\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 8000/8096/30000: loss 0.2065, policy_loss:0.1856, value_loss:0.0209, time 6.31s, iter_time: 78.85ms\n",
      "iter 8200/8272/30000: loss 0.2081, policy_loss:0.1860, value_loss:0.0221, time 4.15s, iter_time: 39.94ms\n",
      "iter 8400/8448/30000: loss 0.2591, policy_loss:0.1980, value_loss:0.0611, time 5.38s, iter_time: 42.02ms\n",
      "iter 8600/8624/30000: loss 0.2044, policy_loss:0.1894, value_loss:0.0150, time 6.07s, iter_time: 39.96ms\n",
      "iter 8800/8976/30000: loss 0.2169, policy_loss:0.1882, value_loss:0.0287, time 0.04s, iter_time: 0.00ms\n",
      "step 9000: losses: train:0.2198, train_policy_loss:0.1903, train_value_loss:0.0295, val:0.2287, val_policy_loss:0.1958, val_value_loss:0.0329\n",
      "saving checkpoint to /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40\n",
      "iter 9000/9152/30000: loss 0.2249, policy_loss:0.1931, value_loss:0.0318, time 4.11s, iter_time: 171.23ms\n",
      "iter 9200/9328/30000: loss 0.2043, policy_loss:0.1930, value_loss:0.0113, time 2.01s, iter_time: 41.96ms\n",
      "iter 9400/9504/30000: loss 0.2560, policy_loss:0.1902, value_loss:0.0658, time 3.02s, iter_time: 41.90ms\n",
      "iter 9600/9680/30000: loss 0.2343, policy_loss:0.2002, value_loss:0.0341, time 3.91s, iter_time: 40.72ms\n",
      "iter 9800/9856/30000: loss 0.2128, policy_loss:0.1921, value_loss:0.0206, time 4.95s, iter_time: 41.23ms\n",
      "step 10000: losses: train:0.2191, train_policy_loss:0.1901, train_value_loss:0.0289, val:0.2274, val_policy_loss:0.1957, val_value_loss:0.0318\n",
      "Early stopping triggered! Valid loss hasn't improved for 5 evals.\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/smoketest-e2e-v3/gen-40/best.pt (val_loss=0.2258)\n",
      "Saved model to /Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/models/gen-40.pt\n",
      "Dataset Stats:\n",
      "  Trajectories: 100000\n",
      "  Total actions: 739547\n",
      "  Avg trajectory length: 7.40\n",
      "Prefix Stats:\n",
      "actions=(): 100000 win=99247 loss=753 draw=0 win1%=99.25 model-win1%=99.27\n",
      "actions=(1,): 106 win=45 loss=61 draw=0 win1%=42.45 model-win1%=40.02\n",
      "actions=(2,): 502 win=486 loss=16 draw=0 win1%=96.81 model-win1%=96.82\n",
      "actions=(3,): 119 win=77 loss=42 draw=0 win1%=64.71 model-win1%=61.08\n",
      "actions=(4,): 98613 win=98135 loss=478 draw=0 win1%=99.52 model-win1%=99.51\n",
      "actions=(4, 5): 95365 win=94910 loss=455 draw=0 win1%=99.52 model-win1%=99.51\n",
      "actions=(5,): 334 win=267 loss=67 draw=0 win1%=79.94 model-win1%=78.29\n",
      "actions=(6,): 154 win=114 loss=40 draw=0 win1%=74.03 model-win1%=74.56\n",
      "actions=(7,): 172 win=123 loss=49 draw=0 win1%=71.51 model-win1%=70.26\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "trajectory_paths_dict = {}\n",
    "model_dict = {0: model_0}\n",
    "\n",
    "current_model = model_dict[0]\n",
    "if RUN_GENERATIONS:\n",
    "    for generation_id in range(1, experiment_config.num_generations+1):\n",
    "        current_model = await experiment_runner.run_generation_step_async(generation_id, current_model)\n",
    "        dataset_paths = experiment_runner.get_trajectory_paths(generation_id)\n",
    "        \n",
    "        # print stats for visibility\n",
    "        print_dataset_stats(dataset_paths, n_max_context, action_vocab, model=current_model, game=game)\n",
    "        \n",
    "        model_dict[generation_id] = current_model\n",
    "\n",
    "# 10m to play 2x10k generations... probabilities still very wrong.\n",
    "# Evaluation time: 0.015 seconds, size=574, eval-per-second=37837.60, total-batches=6000, mean-eval-per-second=94963.99, mean-time-per-batch=0.010, mean-batch-size=990.34\n",
    "\n",
    "# >>> log(2) + log(7) -> 2.6390573296152584\n",
    "## Model doesn't seem to improve loss at all?\n",
    "# step.   0: losses: train:2.5971, train_policy_loss:1.9146, train_value_loss:0.6825, val:2.5972, val_policy_loss:1.9147, val_value_loss:0.6825\n",
    "# step 1000: losses: train:2.6036, train_policy_loss:1.9122, train_value_loss:0.6914, val:2.6050, val_policy_loss:1.9132, val_value_loss:0.6917\n",
    "# step 2000: losses: train:2.6056, train_policy_loss:1.9119, train_value_loss:0.6937, val:2.6056, val_policy_loss:1.9123, val_value_loss:0.6933\n",
    "# iter    0/1170/5000: loss 2.5699, policy_loss:1.9129, value_loss:0.6570, time 5.18s, iter_time: 0.00ms\n",
    "# iter 1000/1170/5000: loss 2.5996, policy_loss:1.9068, value_loss:0.6928, time 1.96s, iter_time: 1957.74ms\n",
    "# iter 2339/2340/5000: loss 2.6014, policy_loss:1.9131, value_loss:0.6884, time 0.01s, iter_time: 14.61ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070: RuntimeWarning: assigning None to 2 unbound locals\n",
      "  frame.f_lineno = line\n"
     ]
    }
   ],
   "source": [
    "# current_model = await experiment_runner.run_generation_step_async(generation_id, current_model)\n",
    "\n",
    "experiment_config.experiment_name='smoketest-e2e-v3-hack'   # Use sliding window.\n",
    "experiment_config.parent_experiment_name='smoketest-e2e-v3'\n",
    "experiment_config.num_generations=41\n",
    "experiment_config.num_games_per_gen=1\n",
    "\n",
    "experiment_runner = ExperimentRunner(experiment_config, experiment_base_dir, training_args=tuned_params)\n",
    "await experiment_runner.play_generation_async(current_model, gen_id=experiment_config.num_generations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model (initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_config_fields: {'n_max_context', 'dropout', 'n_head', 'n_layer', 'n_embd', 'bias'}\n",
      "train_config_fields: {'wandb_log', 'beta1', 'min_lr', 'eval_iters', 'decay_lr', 'max_iters', 'max_epochs', 'warmup_iters', 'batch_size', 'eval_only', 'patience', 'device', 'model_version', 'learning_rate', 'eval_interval', 'weight_decay', 'lr_decay_iters', 'compile', 'always_save_checkpoint', 'beta2', 'gradient_accumulation_steps', 'model_name', 'dtype', 'grad_clip', 'log_interval'}\n",
      "Using initial model as baseline.\n",
      "Training initial\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.1, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.01, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 41.51s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 55.675215005874634s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.1, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.01, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## Initial Model, loss=2.7775665044784548 elapsed=55.675215005874634s, val_policy=2.1004, val_value=0.6772\n",
      "## Searching generation 0 with 18 candidates, including ['learning_rate: 0.1 -> 0.05', 'learning_rate: 0.1 -> 0.2', 'batch_size: 32 -> 16', 'batch_size: 32 -> 64', 'beta1: 0.9 -> 0.95']\n",
      "Training learning_rate: 0.1 -> 0.05\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.63s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.4931111335754395s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7776 elapsed=7.49s, mutation learning_rate: 0.1 -> 0.05\n",
      "## Searching generation 1 with 18 candidates, including ['learning_rate: 0.05 -> 0.02', 'learning_rate: 0.05 -> 0.1', 'batch_size: 32 -> 16', 'batch_size: 32 -> 64', 'beta1: 0.9 -> 0.95']\n",
      "Training learning_rate: 0.05 -> 0.02\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.49s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.180812120437622s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7776 elapsed=7.18s, mutation learning_rate: 0.05 -> 0.02\n",
      "## Searching generation 2 with 18 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'batch_size: 32 -> 16', 'batch_size: 32 -> 64', 'beta1: 0.9 -> 0.95']\n",
      "## improved: False, loss=2.7776 elapsed=7.49s, mutation learning_rate: 0.02 -> 0.05\n",
      "Training learning_rate: 0.02 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.72s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.686541795730591s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.69s, mutation learning_rate: 0.02 -> 0.01\n",
      "Training batch_size: 32 -> 16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 60.95s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 70.05358600616455s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=70.05s, mutation batch_size: 32 -> 16\n",
      "Training batch_size: 32 -> 64\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=64, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7776, train_policy_loss:2.1003, train_value_loss:0.6772, val:2.7776, val_policy_loss:2.1004, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7789, policy_loss:2.0993, value_loss:0.6795, time 115.24s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7776)\n",
      "## train_loss: 2.7774, val_loss: 2.7776, Time taken: 138.09453701972961s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 64, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=138.09s, mutation batch_size: 32 -> 64\n",
      "Training beta1: 0.9 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.95, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.98s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.559458017349243s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.95, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.56s, mutation beta1: 0.9 -> 0.95\n",
      "Training beta2: 0.95 -> 0.98\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.74s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 6.749730110168457s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7776 elapsed=6.75s, mutation beta2: 0.95 -> 0.98\n",
      "## Searching generation 3 with 19 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'beta1: 0.9 -> 0.95', 'bias: False -> True', 'decay_lr: True -> False']\n",
      "Training learning_rate: 0.02 -> 0.05\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 3.12s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.102126836776733s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.10s, mutation learning_rate: 0.02 -> 0.05\n",
      "Training learning_rate: 0.02 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.86s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.028873920440674s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.03s, mutation learning_rate: 0.02 -> 0.01\n",
      "Training beta1: 0.9 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.95, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.94s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 6.997674942016602s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.95, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.00s, mutation beta1: 0.9 -> 0.95\n",
      "Training bias: False -> True\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=True)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 20, with 234 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7792, train_policy_loss:2.0801, train_value_loss:0.6991, val:2.7792, val_policy_loss:2.0801, val_value_loss:0.6991\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7809, policy_loss:2.0819, value_loss:0.6990, time 5.79s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7792)\n",
      "## train_loss: 2.7791, val_loss: 2.7792, Time taken: 11.624053001403809s, val_policy_loss: 2.0801, val_value_loss: 0.6991, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': True, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7792 elapsed=11.62s, mutation bias: False -> True\n",
      "Training decay_lr: True -> False\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=False, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 3.07s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 6.983636140823364s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': False, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=6.98s, mutation decay_lr: True -> False\n",
      "Training dropout: 0.0 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.01, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7790, policy_loss:2.1017, value_loss:0.6773, time 4.24s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 9.56999397277832s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.01, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=9.57s, mutation dropout: 0.0 -> 0.01\n",
      "Training dtype: float16 -> bfloat16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 3.08s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.232019901275635s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'bfloat16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.23s, mutation dtype: float16 -> bfloat16\n",
      "Training max_iters: 100 -> 300\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=300, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=300, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/300/300: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 2.80s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 10.227452754974365s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 300, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 300, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=10.23s, mutation max_iters: 100 -> 300\n",
      "Training n_embd: 8 -> 16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7311, train_policy_loss:2.0920, train_value_loss:0.6391, val:2.7310, val_policy_loss:2.0919, val_value_loss:0.6391\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7307, policy_loss:2.0925, value_loss:0.6382, time 11.98s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7310)\n",
      "## train_loss: 2.7309, val_loss: 2.7309, Time taken: 17.631279230117798s, val_policy_loss: 2.0920, val_value_loss: 0.6389, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7309 elapsed=17.63s, mutation n_embd: 8 -> 16\n",
      "Training n_head: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 6.12s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 11.17986798286438s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 1, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=11.18s, mutation n_head: 2 -> 1\n",
      "Training n_head: 2 -> 4\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=4, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 4.48s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 9.6476731300354s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 4, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=9.65s, mutation n_head: 2 -> 4\n",
      "Training n_layer: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=1, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 7, with 1,200 parameters\n",
      "num non-decayed parameter tensors: 5, with 34 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7915, train_policy_loss:2.1002, train_value_loss:0.6912, val:2.7915, val_policy_loss:2.1003, val_value_loss:0.6911\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7914, policy_loss:2.1004, value_loss:0.6910, time 3.33s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7915)\n",
      "## train_loss: 2.7914, val_loss: 2.7915, Time taken: 7.781635046005249s, val_policy_loss: 2.1003, val_value_loss: 0.6912, overrides={'n_layer': 1, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7915 elapsed=7.78s, mutation n_layer: 2 -> 1\n",
      "Training n_layer: 2 -> 3\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=3, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 15, with 2,736 parameters\n",
      "num non-decayed parameter tensors: 9, with 66 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.8041, train_policy_loss:2.0920, train_value_loss:0.7121, val:2.8041, val_policy_loss:2.0920, val_value_loss:0.7121\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.8063, policy_loss:2.0933, value_loss:0.7130, time 3.72s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.8041)\n",
      "## train_loss: 2.8040, val_loss: 2.8041, Time taken: 8.892699956893921s, val_policy_loss: 2.0919, val_value_loss: 0.7122, overrides={'n_layer': 3, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.8041 elapsed=8.89s, mutation n_layer: 2 -> 3\n",
      "Training weight_decay: 0.1 -> 0.05\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 3.25s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.18946099281311s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.05, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.19s, mutation weight_decay: 0.1 -> 0.05\n",
      "Training weight_decay: 0.1 -> 0.2\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.2, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 3.06s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.116979122161865s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.2, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.12s, mutation weight_decay: 0.1 -> 0.2\n",
      "Training beta2: 0.98 -> 0.99\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.99, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6771, val:2.7777, val_policy_loss:2.1005, val_value_loss:0.6772\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7791, policy_loss:2.1015, value_loss:0.6775, time 3.12s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7777)\n",
      "## train_loss: 2.7775, val_loss: 2.7776, Time taken: 7.197895050048828s, val_policy_loss: 2.1004, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.99, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.20s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.7776 elapsed=7.18s, mutation beta2: 0.98 -> 0.95\n",
      "Training batch_size: 32 -> 16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.80s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 6.736835956573486s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7776 elapsed=6.74s, mutation batch_size: 32 -> 16\n",
      "## Searching generation 4 with 18 candidates, including ['learning_rate: 0.02 -> 0.05', 'learning_rate: 0.02 -> 0.01', 'batch_size: 16 -> 32', 'max_iters: 100 -> 300', 'weight_decay: 0.1 -> 0.2']\n",
      "Training learning_rate: 0.02 -> 0.05\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.27s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 6.402606010437012s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7776 elapsed=6.40s, mutation learning_rate: 0.02 -> 0.05\n",
      "## Searching generation 5 with 18 candidates, including ['learning_rate: 0.05 -> 0.02', 'learning_rate: 0.05 -> 0.1', 'batch_size: 16 -> 32', 'max_iters: 100 -> 300', 'weight_decay: 0.1 -> 0.2']\n",
      "## improved: False, loss=2.7776 elapsed=6.74s, mutation learning_rate: 0.05 -> 0.02\n",
      "Training learning_rate: 0.05 -> 0.1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.1, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.01, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.35s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 6.448047161102295s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.1, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.01, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=6.45s, mutation learning_rate: 0.05 -> 0.1\n",
      "## improved: False, loss=2.7776 elapsed=7.10s, mutation batch_size: 16 -> 32\n",
      "Training max_iters: 100 -> 300\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=300, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=300, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/300/300: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.32s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 19.243173122406006s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 300, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 300, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=19.24s, mutation max_iters: 100 -> 300\n",
      "Training weight_decay: 0.1 -> 0.2\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.2, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.52s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 7.245619058609009s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.2, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.25s, mutation weight_decay: 0.1 -> 0.2\n",
      "Training weight_decay: 0.1 -> 0.05\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.25s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 7.102996110916138s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.05, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=7.10s, mutation weight_decay: 0.1 -> 0.05\n",
      "Training beta1: 0.9 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.95, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.55s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 6.748692989349365s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.95, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=6.75s, mutation beta1: 0.9 -> 0.95\n",
      "Training decay_lr: True -> False\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=False, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.75s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 6.564391136169434s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': False, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=6.56s, mutation decay_lr: True -> False\n",
      "Training dtype: float16 -> bfloat16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.75s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 6.507054090499878s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'bfloat16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=6.51s, mutation dtype: float16 -> bfloat16\n",
      "Training n_layer: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=1, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 7, with 1,200 parameters\n",
      "num non-decayed parameter tensors: 5, with 34 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7916, train_policy_loss:2.1004, train_value_loss:0.6912, val:2.7916, val_policy_loss:2.1005, val_value_loss:0.6911\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7936, policy_loss:2.1027, value_loss:0.6909, time 2.47s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7916)\n",
      "## train_loss: 2.7914, val_loss: 2.7913, Time taken: 5.920759677886963s, val_policy_loss: 2.1001, val_value_loss: 0.6912, overrides={'n_layer': 1, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7913 elapsed=5.92s, mutation n_layer: 2 -> 1\n",
      "Training n_head: 2 -> 4\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=4, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 4.94s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 9.053121089935303s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 4, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=9.05s, mutation n_head: 2 -> 4\n",
      "Training dropout: 0.0 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.01, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7758, policy_loss:2.1006, value_loss:0.6752, time 6.41s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 10.412021160125732s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.01, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=10.41s, mutation dropout: 0.0 -> 0.01\n",
      "Training n_layer: 2 -> 3\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=3, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 15, with 2,736 parameters\n",
      "num non-decayed parameter tensors: 9, with 66 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.8043, train_policy_loss:2.0922, train_value_loss:0.7121, val:2.8042, val_policy_loss:2.0921, val_value_loss:0.7121\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.8060, policy_loss:2.0929, value_loss:0.7130, time 3.00s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.8042)\n",
      "## train_loss: 2.8042, val_loss: 2.8040, Time taken: 7.244549989700317s, val_policy_loss: 2.0918, val_value_loss: 0.7122, overrides={'n_layer': 3, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.8040 elapsed=7.24s, mutation n_layer: 2 -> 3\n",
      "Training n_head: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 5.57s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 9.712861061096191s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 1, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=9.71s, mutation n_head: 2 -> 1\n",
      "Training bias: False -> True\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=True)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 20, with 234 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7792, train_policy_loss:2.0801, train_value_loss:0.6991, val:2.7793, val_policy_loss:2.0801, val_value_loss:0.6992\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7777, policy_loss:2.0778, value_loss:0.6999, time 2.40s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7793)\n",
      "## train_loss: 2.7792, val_loss: 2.7792, Time taken: 7.08407187461853s, val_policy_loss: 2.0801, val_value_loss: 0.6991, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': True, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7792 elapsed=7.08s, mutation bias: False -> True\n",
      "Training n_embd: 8 -> 16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.05, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 3.59s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 8.62743616104126s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.05, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7311 elapsed=8.63s, mutation n_embd: 8 -> 16\n",
      "## Searching generation 6 with 19 candidates, including ['learning_rate: 0.05 -> 0.02', 'learning_rate: 0.05 -> 0.1', 'weight_decay: 0.1 -> 0.05', 'decay_lr: True -> False', 'weight_decay: 0.1 -> 0.2']\n",
      "Training learning_rate: 0.05 -> 0.02\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.02, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.23s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.6698620319366455s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.02, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.002, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7311 elapsed=6.67s, mutation learning_rate: 0.05 -> 0.02\n",
      "## Searching generation 7 with 19 candidates, including ['learning_rate: 0.02 -> 0.01', 'learning_rate: 0.02 -> 0.05', 'weight_decay: 0.1 -> 0.05', 'decay_lr: True -> False', 'weight_decay: 0.1 -> 0.2']\n",
      "Training learning_rate: 0.02 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.27s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.061525106430054s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.7311 elapsed=6.06s, mutation learning_rate: 0.02 -> 0.01\n",
      "## Searching generation 8 with 19 candidates, including ['learning_rate: 0.01 -> 0.005', 'learning_rate: 0.01 -> 0.02', 'decay_lr: True -> False', 'weight_decay: 0.1 -> 0.05', 'weight_decay: 0.1 -> 0.2']\n",
      "Training learning_rate: 0.01 -> 0.005\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.66s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.59116005897522s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.005, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.0005, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.59s, mutation learning_rate: 0.01 -> 0.005\n",
      "## improved: False, loss=2.7311 elapsed=6.67s, mutation learning_rate: 0.01 -> 0.02\n",
      "Training decay_lr: True -> False\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=False, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.78s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.526685953140259s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': False, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.53s, mutation decay_lr: True -> False\n",
      "Training weight_decay: 0.1 -> 0.05\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.70s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.550430059432983s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.05, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.55s, mutation weight_decay: 0.1 -> 0.05\n",
      "Training weight_decay: 0.1 -> 0.2\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.2, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.64s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.8383378982543945s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.2, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.84s, mutation weight_decay: 0.1 -> 0.2\n",
      "Training dtype: float16 -> bfloat16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.69s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.484174728393555s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'bfloat16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.48s, mutation dtype: float16 -> bfloat16\n",
      "Training beta1: 0.9 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.95, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.42s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 7.131251096725464s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.95, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=7.13s, mutation beta1: 0.9 -> 0.95\n",
      "Training n_layer: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=1, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 7, with 3,936 parameters\n",
      "num non-decayed parameter tensors: 5, with 58 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7489, train_policy_loss:2.0806, train_value_loss:0.6683, val:2.7487, val_policy_loss:2.0805, val_value_loss:0.6681\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7456, policy_loss:2.0786, value_loss:0.6670, time 2.26s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7487)\n",
      "## train_loss: 2.7486, val_loss: 2.7491, Time taken: 6.2312469482421875s, val_policy_loss: 2.0809, val_value_loss: 0.6682, overrides={'n_layer': 1, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7491 elapsed=6.23s, mutation n_layer: 2 -> 1\n",
      "Training n_head: 2 -> 4\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=4, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7309, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 3.71s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 8.863770246505737s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 4, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=8.86s, mutation n_head: 2 -> 4\n",
      "Training n_layer: 2 -> 3\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=3, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 15, with 10,080 parameters\n",
      "num non-decayed parameter tensors: 9, with 122 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7766, train_policy_loss:2.0946, train_value_loss:0.6820, val:2.7768, val_policy_loss:2.0948, val_value_loss:0.6820\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7789, policy_loss:2.0966, value_loss:0.6823, time 2.43s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7768)\n",
      "## train_loss: 2.7761, val_loss: 2.7762, Time taken: 7.046210050582886s, val_policy_loss: 2.0944, val_value_loss: 0.6818, overrides={'n_layer': 3, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7762 elapsed=7.05s, mutation n_layer: 2 -> 3\n",
      "Training bias: False -> True\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=True)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 20, with 458 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7841, train_policy_loss:2.0674, train_value_loss:0.7167, val:2.7846, val_policy_loss:2.0678, val_value_loss:0.7168\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7853, policy_loss:2.0672, value_loss:0.7181, time 3.77s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7846)\n",
      "## train_loss: 2.7846, val_loss: 2.7849, Time taken: 8.98731017112732s, val_policy_loss: 2.0682, val_value_loss: 0.7167, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': True, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7849 elapsed=8.99s, mutation bias: False -> True\n",
      "Training dropout: 0.0 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.01, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7275, policy_loss:2.0919, value_loss:0.6357, time 3.54s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 8.800753831863403s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.01, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=8.80s, mutation dropout: 0.0 -> 0.01\n",
      "Training n_head: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0921, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 4.77s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 9.915497064590454s, val_policy_loss: 2.0922, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 1, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=9.92s, mutation n_head: 2 -> 1\n",
      "Training beta2: 0.98 -> 0.99\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.99, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.71s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.4183738231658936s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.99, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.42s, mutation beta2: 0.98 -> 0.99\n",
      "Training batch_size: 16 -> 32\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7311, train_policy_loss:2.0920, train_value_loss:0.6391, val:2.7310, val_policy_loss:2.0919, val_value_loss:0.6391\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7307, policy_loss:2.0925, value_loss:0.6382, time 2.98s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7310)\n",
      "## train_loss: 2.7309, val_loss: 2.7309, Time taken: 7.022016763687134s, val_policy_loss: 2.0920, val_value_loss: 0.6389, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 32, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7309 elapsed=7.02s, mutation batch_size: 16 -> 32\n",
      "Training max_iters: 100 -> 300\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=300, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=300, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/300/300: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.80s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 9.918485641479492s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 300, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 300, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=9.92s, mutation max_iters: 100 -> 300\n",
      "Training n_embd: 16 -> 32\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 6.32s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 10.851203918457031s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 32, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=10.85s, mutation n_embd: 16 -> 32\n",
      "Training n_embd: 16 -> 8\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=8, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 1,968 parameters\n",
      "num non-decayed parameter tensors: 7, with 50 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7775, train_policy_loss:2.1004, train_value_loss:0.6770, val:2.7774, val_policy_loss:2.1004, val_value_loss:0.6770\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7761, policy_loss:2.1005, value_loss:0.6757, time 2.37s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7774)\n",
      "## train_loss: 2.7776, val_loss: 2.7776, Time taken: 6.582316160202026s, val_policy_loss: 2.1003, val_value_loss: 0.6772, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 8, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.98, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7776 elapsed=6.58s, mutation n_embd: 16 -> 8\n",
      "Training beta2: 0.98 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.48s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.629193305969238s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'n_layer': 2, 'n_head': 2, 'n_embd': 16, 'batch_size': 16, 'gradient_accumulation_steps': 1, 'max_iters': 100, 'max_epochs': 1000000, 'learning_rate': 0.01, 'decay_lr': True, 'lr_decay_iters': 100, 'min_lr': 0.001, 'warmup_iters': 0, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'dtype': 'float16', 'dropout': 0.0, 'bias': False, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.63s, mutation beta2: 0.98 -> 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 2.7311145186424257,\n",
       " 6.061525106430054,\n",
       " {'n_layer': 2,\n",
       "  'n_head': 2,\n",
       "  'n_embd': 16,\n",
       "  'n_max_context': 44,\n",
       "  'batch_size': 16,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'max_iters': 100,\n",
       "  'max_epochs': 1000000,\n",
       "  'learning_rate': 0.01,\n",
       "  'decay_lr': True,\n",
       "  'lr_decay_iters': 100,\n",
       "  'min_lr': 0.001,\n",
       "  'warmup_iters': 0,\n",
       "  'weight_decay': 0.1,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.98,\n",
       "  'grad_clip': 1.0,\n",
       "  'dtype': 'float16',\n",
       "  'dropout': 0.0,\n",
       "  'bias': False,\n",
       "  'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40',\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-31'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-32'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-33'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-34'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-35'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-36'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-37'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-38'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-39'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "state_0 = game.initial_state()\n",
    "NUM_GENERATIONS = 5\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "# Parameters which will never be used for tuning.\n",
    "fixed_params = dict(\n",
    "    model_name='c4-smoketest',\n",
    "    model_version='0.1',\n",
    "    num_players = game.num_players(state_0),\n",
    "    vocab_size = action_vocab.vocab_size,\n",
    "    dataset_paths = tuple(experiment_runner.get_trajectory_paths(experiment_config.num_generations)),\n",
    "\n",
    "\n",
    "    eval_iters = 200,\n",
    "    log_interval = 1000,\n",
    "    eval_interval = 10_000,\n",
    "\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "initial_params = dict(\n",
    "    n_layer=2,\n",
    "    n_head=2,\n",
    "    n_embd=8,  # tiny model\n",
    "\n",
    "    n_max_context=n_max_context,\n",
    "    batch_size = 32,\n",
    "    gradient_accumulation_steps = 1,\n",
    "\n",
    "    max_iters=100,\n",
    "    max_epochs=1_000_000, # Make max_epoch high, rely on max_iters to stop.\n",
    "        \n",
    "    learning_rate = LEARNING_RATE,    \n",
    "    decay_lr = True,  # whether to decay the learning rate\n",
    "    lr_decay_iters = 100,  # make equal to max_iters usually\n",
    "    min_lr = LEARNING_RATE / 10,  # learning_rate / 10 usually\n",
    "    warmup_iters = 0,  # not super necessary potentially\n",
    "\n",
    "    weight_decay = 1e-1,\n",
    "    beta1 = 0.9,\n",
    "    beta2 = 0.95,\n",
    "    grad_clip = 1.0,  # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "    dtype = \"float16\",\n",
    "\n",
    "    dropout = 0.0,\n",
    "    bias = False,  # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "    last_file = None,   # Used in tuning key only.\n",
    ")\n",
    "\n",
    "tune_options = dict(\n",
    "    n_layer = [1, 2, 3, 4, 5, 6, 8, 10, 12, 16, 32],\n",
    "    # n_head = [1, 2, 4, 8, 16, 32],   # Needs to be calcualted to ensure n_embed % n_head == 0\n",
    "    n_embd = [8, 16, 32, 64, 128, 256, 512, 1024, 2048],\n",
    "\n",
    "    n_max_context = [initial_params['n_max_context']],\n",
    "    batch_size = [16, 32, 64, 128, 256, 512, 1024],\n",
    "    gradient_accumulation_steps = [1],  # TODO: We only support 1 for now. This fails is we don't have an exact multiple of the batch size per epoch.\n",
    "\n",
    "    max_iters = [100, 300, 1_000, 3_000, 5_000, 10_000, 30_000, 100_000, 300_000],\n",
    "    max_epochs = [1_000_000], # Make max_epoch high, rely on max_iters to stop.\n",
    " \n",
    "    learning_rate = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0],\n",
    "    decay_lr = [False, True],\n",
    "\n",
    "    # TODO: What is a sensible range here?\n",
    "    beta1 = [0.90, 0.95, 0.99],\n",
    "    beta2 = [0.95, 0.98, 0.99],\n",
    "\n",
    "    weight_decay = [0.01, 0.05, 0.1, 0.2],\n",
    "    grad_clip = [0,0, 1.0],  # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "    dtype = [\"bfloat16\", \"float16\"],\n",
    "    dropout = [0.0, 0.01, 0.02, 0.05, 0.1],\n",
    "    bias = [True, False],    \n",
    ")\n",
    "\n",
    "_n_head_options = [1, 2, 4, 8, 16, 32]\n",
    "computed_tune_options = dict(\n",
    "    min_lr = lambda opt: [opt['learning_rate'] / 10],\n",
    "    lr_decay_iters = lambda opt: [opt['max_iters']],\n",
    "    warmup_iters = lambda opt: [x for x in [0, 100, 500, 1000] if x < opt['lr_decay_iters']] if opt['decay_lr'] else [0],\n",
    "    n_head = lambda opt: [n for n in _n_head_options if opt['n_embd'] % n == 0],\n",
    "    last_file = lambda opt: [str(opt['dataset_paths'][-1])],\n",
    ")\n",
    "\n",
    "TUNER_VERSION = \"0.0.6-smoketest\"\n",
    "\n",
    "from rgi.rgizero.models.tuner import Tuner\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=1.00)\n",
    "tuner.autotune_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.697791143655777 elapsed=10.851203918457031s, val_policy=2.0774, val_value=0.6204\n",
      "## Searching generation 0 with 19 candidates, including ['learning_rate: 0.01 -> 0.005', 'learning_rate: 0.01 -> 0.02', 'weight_decay: 0.1 -> 0.05', 'decay_lr: True -> False', 'weight_decay: 0.1 -> 0.2']\n",
      "Training learning_rate: 0.01 -> 0.005\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.29s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.646500110626221s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.1, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.6978 elapsed=6.65s, mutation learning_rate: 0.01 -> 0.005\n",
      "## Searching generation 1 with 19 candidates, including ['learning_rate: 0.005 -> 0.01', 'learning_rate: 0.005 -> 0.002', 'weight_decay: 0.1 -> 0.05', 'decay_lr: True -> False', 'dtype: float16 -> bfloat16']\n",
      "## improved: False, loss=2.6978 elapsed=10.85s, mutation learning_rate: 0.005 -> 0.01\n",
      "Training learning_rate: 0.005 -> 0.002\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.65s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 7.1439478397369385s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.1, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=7.14s, mutation learning_rate: 0.005 -> 0.002\n",
      "Training weight_decay: 0.1 -> 0.05\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.62s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.355707168579102s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.6978 elapsed=6.36s, mutation weight_decay: 0.1 -> 0.05\n",
      "## Searching generation 2 with 19 candidates, including ['learning_rate: 0.005 -> 0.002', 'learning_rate: 0.005 -> 0.01', 'decay_lr: True -> False', 'dtype: float16 -> bfloat16', 'beta2: 0.98 -> 0.99']\n",
      "Training learning_rate: 0.005 -> 0.002\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.90s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.664028167724609s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.66s, mutation learning_rate: 0.005 -> 0.002\n",
      "Training learning_rate: 0.005 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.74s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.554748058319092s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.01, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.001, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.55s, mutation learning_rate: 0.005 -> 0.01\n",
      "Training decay_lr: True -> False\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=False, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.61s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.576114892959595s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': False, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.58s, mutation decay_lr: True -> False\n",
      "Training dtype: float16 -> bfloat16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.27s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.22353196144104s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.6978 elapsed=6.22s, mutation dtype: float16 -> bfloat16\n",
      "## Searching generation 3 with 19 candidates, including ['learning_rate: 0.005 -> 0.002', 'learning_rate: 0.005 -> 0.01', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99', 'n_head: 2 -> 4']\n",
      "Training learning_rate: 0.005 -> 0.002\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.41s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.404025077819824s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.40s, mutation learning_rate: 0.005 -> 0.002\n",
      "Training learning_rate: 0.005 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.01, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.001, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.31s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.533339262008667s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.01, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.001, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.53s, mutation learning_rate: 0.005 -> 0.01\n",
      "Training decay_lr: True -> False\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=False, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.29s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.553138971328735s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': False, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.55s, mutation decay_lr: True -> False\n",
      "Training beta2: 0.98 -> 0.99\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.99, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.47s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.872704982757568s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.99, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.87s, mutation beta2: 0.98 -> 0.99\n",
      "Training n_head: 2 -> 4\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=4, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0774, val_value_loss:0.6212\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6197, time 4.03s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6975, val_loss: 2.6978, Time taken: 9.132418155670166s, val_policy_loss: 2.0774, val_value_loss: 0.6205, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 4, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=9.13s, mutation n_head: 2 -> 4\n",
      "Training beta1: 0.9 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.95, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.55s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.357401132583618s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.95, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.36s, mutation beta1: 0.9 -> 0.95\n",
      "Training dropout: 0.0 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.01, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6933, policy_loss:2.0730, value_loss:0.6203, time 3.81s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 8.997928857803345s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.01, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=9.00s, mutation dropout: 0.0 -> 0.01\n",
      "Training n_head: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 4.67s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 9.468239068984985s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=9.47s, mutation n_head: 2 -> 1\n",
      "Training n_layer: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=1, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 7, with 14,016 parameters\n",
      "num non-decayed parameter tensors: 5, with 106 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.8473, train_policy_loss:2.1895, train_value_loss:0.6578, val:2.8478, val_policy_loss:2.1900, val_value_loss:0.6579\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.8523, policy_loss:2.1968, value_loss:0.6555, time 2.57s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.8478)\n",
      "## train_loss: 2.8470, val_loss: 2.8463, Time taken: 5.935090065002441s, val_policy_loss: 2.1889, val_value_loss: 0.6575, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 1, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.8463 elapsed=5.94s, mutation n_layer: 2 -> 1\n",
      "Training max_iters: 100 -> 300\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=300, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=300, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/300/300: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.83s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 9.899419784545898s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 300, 'max_epochs': 1000000, 'max_iters': 300, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=9.90s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.6978 elapsed=6.36s, mutation dtype: bfloat16 -> float16\n",
      "Training bias: False -> True\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=True)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 20, with 906 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.9161, train_policy_loss:2.1843, train_value_loss:0.7318, val:2.9169, val_policy_loss:2.1852, val_value_loss:0.7316\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.9210, policy_loss:2.1889, value_loss:0.7321, time 4.36s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.9169)\n",
      "## train_loss: 2.9167, val_loss: 2.9165, Time taken: 9.964789152145386s, val_policy_loss: 2.1846, val_value_loss: 0.7319, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': True, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.9165 elapsed=9.96s, mutation bias: False -> True\n",
      "Training batch_size: 16 -> 32\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0772, train_value_loss:0.6209, val:2.6982, val_policy_loss:2.0774, val_value_loss:0.6208\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6967, policy_loss:2.0790, value_loss:0.6177, time 4.88s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6982)\n",
      "## train_loss: 2.6973, val_loss: 2.6980, Time taken: 9.914875984191895s, val_policy_loss: 2.0774, val_value_loss: 0.6205, overrides={'batch_size': 32, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6980 elapsed=9.91s, mutation batch_size: 16 -> 32\n",
      "Training n_layer: 2 -> 3\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=3, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 15, with 38,592 parameters\n",
      "num non-decayed parameter tensors: 9, with 234 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.8263, train_policy_loss:2.1317, train_value_loss:0.6946, val:2.8270, val_policy_loss:2.1322, val_value_loss:0.6949\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.8321, policy_loss:2.1352, value_loss:0.6969, time 2.48s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.8270)\n",
      "## train_loss: 2.8259, val_loss: 2.8261, Time taken: 7.052602767944336s, val_policy_loss: 2.1315, val_value_loss: 0.6946, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 3, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.8261 elapsed=7.05s, mutation n_layer: 2 -> 3\n",
      "Training n_embd: 32 -> 16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0920, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.21s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.358166217803955s, val_policy_loss: 2.0921, val_value_loss: 0.6390, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 16, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.36s, mutation n_embd: 32 -> 16\n",
      "Training weight_decay: 0.05 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.23s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.34697699546814s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.35s, mutation weight_decay: 0.05 -> 0.01\n",
      "Training weight_decay: 0.05 -> 0.1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.1, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.46s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.279694080352783s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.1, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.28s, mutation weight_decay: 0.05 -> 0.1\n",
      "Training beta2: 0.98 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.79s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 6.672981023788452s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.95, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=6.67s, mutation beta2: 0.98 -> 0.95\n",
      "Training n_embd: 32 -> 64\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=64, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 101,760 parameters\n",
      "num non-decayed parameter tensors: 7, with 330 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.9559, train_policy_loss:2.2070, train_value_loss:0.7489, val:2.9569, val_policy_loss:2.2082, val_value_loss:0.7488\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.9664, policy_loss:2.2138, value_loss:0.7526, time 6.50s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.9569)\n",
      "## train_loss: 2.9565, val_loss: 2.9557, Time taken: 11.077908992767334s, val_policy_loss: 2.2071, val_value_loss: 0.7486, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 64, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.9557 elapsed=11.08s, mutation n_embd: 32 -> 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 2.697791143655777,\n",
       " 6.22353196144104,\n",
       " {'batch_size': 16,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.98,\n",
       "  'bias': False,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.0,\n",
       "  'dtype': 'bfloat16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40',\n",
       "  'learning_rate': 0.005,\n",
       "  'lr_decay_iters': 100,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 100,\n",
       "  'min_lr': 0.0005,\n",
       "  'n_embd': 32,\n",
       "  'n_head': 2,\n",
       "  'n_layer': 2,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 0,\n",
       "  'weight_decay': 0.05,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-31'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-32'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-33'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-34'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-35'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-36'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-37'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-38'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-39'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.1)\n",
    "tuner.autotune_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.697791143655777 elapsed=6.22353196144104s, val_policy=2.0774, val_value=0.6204\n",
      "## Searching generation 0 with 19 candidates, including ['learning_rate: 0.005 -> 0.002', 'learning_rate: 0.005 -> 0.01', 'weight_decay: 0.05 -> 0.01', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.6978 elapsed=6.40s, mutation learning_rate: 0.005 -> 0.002\n",
      "## improved: False, loss=2.6978 elapsed=6.53s, mutation learning_rate: 0.005 -> 0.01\n",
      "## improved: False, loss=2.6978 elapsed=6.35s, mutation weight_decay: 0.05 -> 0.01\n",
      "## improved: False, loss=2.6978 elapsed=6.55s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.6978 elapsed=6.87s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.6978 elapsed=9.90s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.6978 elapsed=9.13s, mutation n_head: 2 -> 4\n",
      "## improved: False, loss=2.6977 elapsed=9.47s, mutation n_head: 2 -> 1\n",
      "## improved: False, loss=2.6978 elapsed=9.00s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.6978 elapsed=6.36s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.6978 elapsed=6.67s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.6978 elapsed=6.36s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.7311 elapsed=6.36s, mutation n_embd: 32 -> 16\n",
      "## improved: False, loss=2.6978 elapsed=6.28s, mutation weight_decay: 0.05 -> 0.1\n",
      "## improved: False, loss=2.6980 elapsed=9.91s, mutation batch_size: 16 -> 32\n",
      "## improved: False, loss=2.8463 elapsed=5.94s, mutation n_layer: 2 -> 1\n",
      "## improved: False, loss=2.8261 elapsed=7.05s, mutation n_layer: 2 -> 3\n",
      "## improved: False, loss=2.9165 elapsed=9.96s, mutation bias: False -> True\n",
      "## improved: False, loss=2.9557 elapsed=11.08s, mutation n_embd: 32 -> 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 2.697791143655777,\n",
       " 6.22353196144104,\n",
       " {'batch_size': 16,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.98,\n",
       "  'bias': False,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.0,\n",
       "  'dtype': 'bfloat16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40',\n",
       "  'learning_rate': 0.005,\n",
       "  'lr_decay_iters': 100,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 100,\n",
       "  'min_lr': 0.0005,\n",
       "  'n_embd': 32,\n",
       "  'n_head': 2,\n",
       "  'n_layer': 2,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 0,\n",
       "  'weight_decay': 0.05,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-31'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-32'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-33'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-34'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-35'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-36'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-37'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-38'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-39'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.01)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.697672313451767 elapsed=9.468239068984985s, val_policy=2.0773, val_value=0.6204\n",
      "## Searching generation 0 with 18 candidates, including ['learning_rate: 0.005 -> 0.002', 'learning_rate: 0.005 -> 0.01', 'weight_decay: 0.05 -> 0.01', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "Training learning_rate: 0.005 -> 0.002\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 3.11s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.932115077972412s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.6977 elapsed=6.93s, mutation learning_rate: 0.005 -> 0.002\n",
      "## Searching generation 1 with 18 candidates, including ['learning_rate: 0.002 -> 0.005', 'learning_rate: 0.002 -> 0.001', 'weight_decay: 0.05 -> 0.01', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99']\n",
      "## improved: False, loss=2.6977 elapsed=9.47s, mutation learning_rate: 0.002 -> 0.005\n",
      "Training learning_rate: 0.002 -> 0.001\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.001, max_epochs=1000000, max_iters=100, weight_decay=0.05, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0001, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.95s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.765829086303711s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.001, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0001, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.05, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.6977 elapsed=6.77s, mutation learning_rate: 0.002 -> 0.001\n",
      "## Searching generation 2 with 17 candidates, including ['learning_rate: 0.001 -> 0.002', 'weight_decay: 0.05 -> 0.01', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99', 'max_iters: 100 -> 300']\n",
      "## improved: False, loss=2.6977 elapsed=6.93s, mutation learning_rate: 0.001 -> 0.002\n",
      "Training weight_decay: 0.05 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.001, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0001, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.74s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.6013476848602295s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.001, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0001, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.6977 elapsed=6.60s, mutation weight_decay: 0.05 -> 0.01\n",
      "## Searching generation 3 with 16 candidates, including ['learning_rate: 0.001 -> 0.002', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99', 'max_iters: 100 -> 300', 'dropout: 0.0 -> 0.01']\n",
      "Training learning_rate: 0.001 -> 0.002\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.26s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.384593725204468s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: True, loss=2.6977 elapsed=6.38s, mutation learning_rate: 0.001 -> 0.002\n",
      "## Searching generation 4 with 17 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'decay_lr: True -> False', 'beta2: 0.98 -> 0.99', 'max_iters: 100 -> 300']\n",
      "## improved: False, loss=2.6977 elapsed=6.60s, mutation learning_rate: 0.002 -> 0.001\n",
      "Training learning_rate: 0.002 -> 0.005\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.005, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0005, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.37s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.561956167221069s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.005, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0005, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=6.56s, mutation learning_rate: 0.002 -> 0.005\n",
      "Training decay_lr: True -> False\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=False, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.34s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.488303184509277s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': False, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=6.49s, mutation decay_lr: True -> False\n",
      "Training beta2: 0.98 -> 0.99\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.99, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.33s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.482173919677734s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.99, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=6.48s, mutation beta2: 0.98 -> 0.99\n",
      "Training max_iters: 100 -> 300\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=300, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=300, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/300/300: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.26s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 9.266350030899048s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 300, 'max_epochs': 1000000, 'max_iters': 300, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=9.27s, mutation max_iters: 100 -> 300\n",
      "Training dropout: 0.0 -> 0.01\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.01, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6929, policy_loss:2.0722, value_loss:0.6207, time 8.14s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 12.14248514175415s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.01, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=12.14s, mutation dropout: 0.0 -> 0.01\n",
      "Training beta1: 0.9 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.95, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 3.46s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 7.504830837249756s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.95, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=7.50s, mutation beta1: 0.9 -> 0.95\n",
      "Training beta2: 0.98 -> 0.95\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.95, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.33s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.519920825958252s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.95, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=6.52s, mutation beta2: 0.98 -> 0.95\n",
      "Training n_embd: 32 -> 16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=16, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 7,008 parameters\n",
      "num non-decayed parameter tensors: 7, with 90 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.7310, train_policy_loss:2.0919, train_value_loss:0.6391, val:2.7309, val_policy_loss:2.0921, val_value_loss:0.6389\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.7263, policy_loss:2.0908, value_loss:0.6355, time 2.21s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.7309)\n",
      "## train_loss: 2.7309, val_loss: 2.7311, Time taken: 6.487029075622559s, val_policy_loss: 2.0922, val_value_loss: 0.6390, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 16, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.7311 elapsed=6.49s, mutation n_embd: 32 -> 16\n",
      "Training dtype: bfloat16 -> float16\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='float16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodo/src/rgi3-sync/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: losses: train:2.6981, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6985, val_policy_loss:2.0774, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6915, policy_loss:2.0719, value_loss:0.6196, time 2.26s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6985)\n",
      "## train_loss: 2.6973, val_loss: 2.6977, Time taken: 6.518117189407349s, val_policy_loss: 2.0773, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6977 elapsed=6.52s, mutation dtype: bfloat16 -> float16\n",
      "Training batch_size: 16 -> 32\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=32, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6980, train_policy_loss:2.0771, train_value_loss:0.6209, val:2.6981, val_policy_loss:2.0773, val_value_loss:0.6208\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6966, policy_loss:2.0789, value_loss:0.6177, time 3.93s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6981)\n",
      "## train_loss: 2.6972, val_loss: 2.6978, Time taken: 9.075033187866211s, val_policy_loss: 2.0773, val_value_loss: 0.6205, overrides={'batch_size': 32, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=9.08s, mutation batch_size: 16 -> 32\n",
      "Training n_head: 1 -> 2\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=2, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 7, with 170 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.6982, train_policy_loss:2.0772, train_value_loss:0.6210, val:2.6986, val_policy_loss:2.0775, val_value_loss:0.6211\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.6917, policy_loss:2.0720, value_loss:0.6196, time 2.64s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.6986)\n",
      "## train_loss: 2.6974, val_loss: 2.6978, Time taken: 7.084737062454224s, val_policy_loss: 2.0774, val_value_loss: 0.6204, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 2, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.6978 elapsed=7.08s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.6977 elapsed=6.93s, mutation weight_decay: 0.01 -> 0.05\n",
      "Training n_layer: 2 -> 1\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=1, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 7, with 14,016 parameters\n",
      "num non-decayed parameter tensors: 5, with 106 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.8473, train_policy_loss:2.1895, train_value_loss:0.6578, val:2.8478, val_policy_loss:2.1900, val_value_loss:0.6578\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.8523, policy_loss:2.1968, value_loss:0.6555, time 2.20s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.8478)\n",
      "## train_loss: 2.8469, val_loss: 2.8463, Time taken: 5.645396947860718s, val_policy_loss: 2.1889, val_value_loss: 0.6574, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 1, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.8463 elapsed=5.65s, mutation n_layer: 2 -> 1\n",
      "Training n_layer: 2 -> 3\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=3, n_head=1, n_embd=32, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 15, with 38,592 parameters\n",
      "num non-decayed parameter tensors: 9, with 234 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.8263, train_policy_loss:2.1319, train_value_loss:0.6943, val:2.8270, val_policy_loss:2.1324, val_value_loss:0.6946\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.8321, policy_loss:2.1355, value_loss:0.6966, time 2.69s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.8270)\n",
      "## train_loss: 2.8259, val_loss: 2.8261, Time taken: 7.247679948806763s, val_policy_loss: 2.1317, val_value_loss: 0.6944, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 3, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.8261 elapsed=7.25s, mutation n_layer: 2 -> 3\n",
      "Training bias: False -> True\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=32, dropout=0.0, bias=True)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 26,304 parameters\n",
      "num non-decayed parameter tensors: 20, with 906 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.9162, train_policy_loss:2.1842, train_value_loss:0.7320, val:2.9169, val_policy_loss:2.1851, val_value_loss:0.7318\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.9211, policy_loss:2.1888, value_loss:0.7323, time 3.05s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.9169)\n",
      "## train_loss: 2.9168, val_loss: 2.9166, Time taken: 7.1187732219696045s, val_policy_loss: 2.1844, val_value_loss: 0.7321, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': True, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 32, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.9166 elapsed=7.12s, mutation bias: False -> True\n",
      "Training n_embd: 32 -> 64\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=2, n_head=1, n_embd=64, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-smoketest', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=16, learning_rate=0.002, max_epochs=1000000, max_iters=100, weight_decay=0.01, beta1=0.9, beta2=0.98, grad_clip=1.0, decay_lr=True, warmup_iters=0, lr_decay_iters=100, min_lr=0.0002, device='mps', dtype='bfloat16', compile=False, patience=5)\n",
      "num decayed parameter tensors: 11, with 101,760 parameters\n",
      "num non-decayed parameter tensors: 7, with 330 parameters\n",
      "using fused AdamW: False\n",
      "step 0: losses: train:2.9558, train_policy_loss:2.2068, train_value_loss:0.7489, val:2.9568, val_policy_loss:2.2080, val_value_loss:0.7488\n",
      "saving best checkpoint to /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt\n",
      "iter 0/100/100: loss 2.9663, policy_loss:2.2137, value_loss:0.7526, time 6.78s, iter_time: 0.00ms\n",
      "Reloading best model from /Users/rodo/src/rgi3-sync/models/c4-smoketest/0.1/best.pt (val_loss=2.9568)\n",
      "## train_loss: 2.9564, val_loss: 2.9556, Time taken: 11.271440744400024s, val_policy_loss: 2.2070, val_value_loss: 0.7486, overrides={'batch_size': 16, 'beta1': 0.9, 'beta2': 0.98, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'bfloat16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40', 'learning_rate': 0.002, 'lr_decay_iters': 100, 'max_epochs': 1000000, 'max_iters': 100, 'min_lr': 0.0002, 'n_embd': 64, 'n_head': 1, 'n_layer': 2, 'warmup_iters': 0, 'weight_decay': 0.01, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000}\n",
      "## improved: False, loss=2.9556 elapsed=11.27s, mutation n_embd: 32 -> 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 2.697672313451767,\n",
       " 6.384593725204468,\n",
       " {'batch_size': 16,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.98,\n",
       "  'bias': False,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.0,\n",
       "  'dtype': 'bfloat16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40',\n",
       "  'learning_rate': 0.002,\n",
       "  'lr_decay_iters': 100,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 100,\n",
       "  'min_lr': 0.0002,\n",
       "  'n_embd': 32,\n",
       "  'n_head': 1,\n",
       "  'n_layer': 2,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 0,\n",
       "  'weight_decay': 0.01,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-31'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-32'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-33'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-34'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-35'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-36'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-37'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-38'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-39'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using initial model as baseline.\n",
      "## Initial Model, loss=2.697672313451767 elapsed=6.384593725204468s, val_policy=2.0773, val_value=0.6204\n",
      "## Searching generation 0 with 17 candidates, including ['learning_rate: 0.002 -> 0.001', 'learning_rate: 0.002 -> 0.005', 'max_iters: 100 -> 300', 'beta2: 0.98 -> 0.99', 'decay_lr: True -> False']\n",
      "## improved: False, loss=2.6977 elapsed=6.60s, mutation learning_rate: 0.002 -> 0.001\n",
      "## improved: False, loss=2.6977 elapsed=6.56s, mutation learning_rate: 0.002 -> 0.005\n",
      "## improved: False, loss=2.6977 elapsed=9.27s, mutation max_iters: 100 -> 300\n",
      "## improved: False, loss=2.6977 elapsed=6.48s, mutation beta2: 0.98 -> 0.99\n",
      "## improved: False, loss=2.6977 elapsed=6.49s, mutation decay_lr: True -> False\n",
      "## improved: False, loss=2.6977 elapsed=12.14s, mutation dropout: 0.0 -> 0.01\n",
      "## improved: False, loss=2.6977 elapsed=7.50s, mutation beta1: 0.9 -> 0.95\n",
      "## improved: False, loss=2.6977 elapsed=6.93s, mutation weight_decay: 0.01 -> 0.05\n",
      "## improved: False, loss=2.6977 elapsed=6.52s, mutation beta2: 0.98 -> 0.95\n",
      "## improved: False, loss=2.6978 elapsed=7.08s, mutation n_head: 1 -> 2\n",
      "## improved: False, loss=2.7311 elapsed=6.49s, mutation n_embd: 32 -> 16\n",
      "## improved: False, loss=2.6977 elapsed=6.52s, mutation dtype: bfloat16 -> float16\n",
      "## improved: False, loss=2.6978 elapsed=9.08s, mutation batch_size: 16 -> 32\n",
      "## improved: False, loss=2.8463 elapsed=5.65s, mutation n_layer: 2 -> 1\n",
      "## improved: False, loss=2.8261 elapsed=7.25s, mutation n_layer: 2 -> 3\n",
      "## improved: False, loss=2.9166 elapsed=7.12s, mutation bias: False -> True\n",
      "## improved: False, loss=2.9556 elapsed=11.27s, mutation n_embd: 32 -> 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 2.697672313451767,\n",
       " 6.384593725204468,\n",
       " {'batch_size': 16,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.98,\n",
       "  'bias': False,\n",
       "  'decay_lr': True,\n",
       "  'dropout': 0.0,\n",
       "  'dtype': 'bfloat16',\n",
       "  'grad_clip': 1.0,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40',\n",
       "  'learning_rate': 0.002,\n",
       "  'lr_decay_iters': 100,\n",
       "  'max_epochs': 1000000,\n",
       "  'max_iters': 100,\n",
       "  'min_lr': 0.0002,\n",
       "  'n_embd': 32,\n",
       "  'n_head': 1,\n",
       "  'n_layer': 2,\n",
       "  'n_max_context': 44,\n",
       "  'warmup_iters': 0,\n",
       "  'weight_decay': 0.01,\n",
       "  'model_name': 'c4-smoketest',\n",
       "  'model_version': '0.1',\n",
       "  'num_players': 2,\n",
       "  'vocab_size': 8,\n",
       "  'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-31'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-32'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-33'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-34'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-35'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-36'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-37'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-38'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-39'),\n",
       "   PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v3/data/gen-40')),\n",
       "  'eval_iters': 200,\n",
       "  'log_interval': 1000,\n",
       "  'eval_interval': 10000,\n",
       "  'device': 'mps'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.0001)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Skip this...",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSkip this...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Skip this..."
     ]
    }
   ],
   "source": [
    "raise NotImplementedError(\"Skip this...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "\n",
    "tuner_result = tuner.autotune_smart()\n",
    "# print(f'tuner_result={tuner_result}')\n",
    "\n",
    "best_params = tuner.best_params.copy()\n",
    "## Recalculating with best_params = {'batch_size': 512, 'beta1': 0.9, 'beta2': 0.99, 'bias': False, 'decay_lr': True, 'dropout': 0.0, 'dtype': 'float16', 'grad_clip': 1.0, 'gradient_accumulation_steps': 1, 'last_file': '/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-20', 'learning_rate': 0.01, 'lr_decay_iters': 5000, 'max_epochs': 1000000, 'max_iters': 30000, 'min_lr': 0.001, 'n_embd': 64, 'n_head': 8, 'n_layer': 4, 'n_max_context': 44, 'warmup_iters': 1000, 'weight_decay': 0.2, 'model_name': 'c4-smoketest', 'model_version': '0.1', 'num_players': 2, 'vocab_size': 8, 'dataset_paths': (PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-1'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-2'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e/data/gen-3'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-4'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-5'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-6'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-7'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-8'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-9'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-10'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-11'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-12'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-13'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-14'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-15'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-16'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-17'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-18'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-19'), PosixPath('/Users/rodo/src/rgi3-sync/experiments/smoketest-e2e-v2/data/gen-20')), 'eval_iters': 200, 'log_interval': 1000, 'eval_interval': 10000, 'device': 'mps'}\n",
    "## {'train': 2.2821048521995544, 'train_policy_loss': 1.746874241232872, 'train_value_loss': 0.5352306108176709, 'val': 2.324920549112208, 'val_policy_loss': 1.7480337900273941, 'val_value_loss': 0.5768867538255804, 'elapsed': 1651.836928844452, 'param_hash': '03189f0f4cb118a1ec142e488fe3fac12e97c118f60661796f8a5a64fa871d44'}\n",
    "\n",
    "best_params['max_iters'] = 30_000 # {'train': 2.2821048521995544, 'train_policy_loss': 1.746874241232872, 'train_value_loss': 0.5352306108176709, 'val': 2.324920549112208, 'val_policy_loss': 1.7480337900273941, 'val_value_loss': 0.5768867538255804, 'elapsed': 1651.836928844452, 'param_hash': '03189f0f4cb118a1ec142e488fe3fac12e97c118f60661796f8a5a64fa871d44'}\n",
    "# best_params['max_iters'] = 10_000 #{'train': 2.2972692108154296, 'train_policy_loss': 1.7478227978944778, 'train_value_loss': 0.5494464221596718, 'val': 2.3170768583522126, 'val_policy_loss': 1.7486604136579178, 'val_value_loss': 0.5684164271635168, 'elapsed': 529.6186480522156, 'param_hash': 'c81f68b9b00650b83a229a76b93d77d51f7bd1af43148f6c1af75e8f562f2670'}\n",
    "# best_params['max_iters'] = 5000 # {'train': 2.3059648656845093, 'train_policy_loss': 1.749609624147415, 'train_value_loss': 0.5563552376627922, 'val': 2.319357395172119, 'val_policy_loss': 1.7505432332263273, 'val_value_loss': 0.5688141549334806, 'elapsed': 267.94705629348755, 'param_hash': 'a1194e1f289d35c51e5a0f01692109358f947530b50dd54364f01baefdb6bedf'}\n",
    "# best_params['max_iters'] = 3000 # {'train': 2.3192384707927705, 'train_policy_loss': 1.752758464217186, 'train_value_loss': 0.5664800041913987, 'val': 2.326388120651245, 'val_policy_loss': 1.7533490412375505, 'val_value_loss': 0.5730390969444724, 'elapsed': 172.16889691352844, 'param_hash': '9e0204edd0b23fd54025b0c4de66c870a268b95197e0e47c4460ec03875b3dcb'}\n",
    "\n",
    "# best_params['learning_rate'] = 0.01 # {'train': 2.2821048521995544, 'train_policy_loss': 1.746874241232872, 'train_value_loss': 0.5352306108176709, 'val': 2.324920549112208, 'val_policy_loss': 1.7480337900273941, 'val_value_loss': 0.5768867538255804, 'elapsed': 1651.836928844452, 'param_hash': '03189f0f4cb118a1ec142e488fe3fac12e97c118f60661796f8a5a64fa871d44'}\n",
    "best_params['learning_rate'] = 0.0005 # {'train': 2.2302739822864535, 'train_policy_loss': 1.7535288149118424, 'train_value_loss': 0.47674516707658765, 'val': 2.4826266765594482, 'val_policy_loss': 1.755559900227715, 'val_value_loss': 0.7270667658132666, 'elapsed': 1617.1719007492065, 'param_hash': '4364fb3cfa7a3b4d33fe30f70ec9957a0a14bc7d9a195b5a2de2247d2a72a6d1'}\n",
    "\n",
    "print(f'\\n## Recalculating with best_params = {best_params}')\n",
    "best_params = tuner._recalculate_tunable_params(best_params)\n",
    "best_model = tuner.get_model_for_params(best_params)\n",
    "print(tuner.train_and_compute_loss(best_params, reload_model=True)[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = experiment_runner.get_trajectory_paths(NUM_GENERATIONS)\n",
    "print_dataset_stats(dataset_paths, n_max_context, action_vocab, model=best_model, game=game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect training data\n",
    "td_array = [TrajectoryDataset(DATA_DIR, f\"gen-{generation_id}\", block_size=n_max_context) for generation_id in range(1, NUM_GENERATIONS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [td for td in td_array]\n",
    "unrolled = [(generation+1, d) for generation, td in enumerate(td_array) for d in td]\n",
    "\n",
    "# gen, d = unrolled[0], \n",
    "# d.action[:2]\n",
    "# d.value[0]\n",
    "\n",
    "dd = defaultdict(lambda: defaultdict(lambda: torch.tensor([0., 0.])))\n",
    "\n",
    "for gen, d in unrolled:\n",
    "    for g in ['*', gen]:    \n",
    "        # dd[tuple(tuple(d.action[:0].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:1].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:2].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:3].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:4].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:5].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:6].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:7].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:8].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:9].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:10].tolist()))][g] += d.value[0]\n",
    "\n",
    "print(f\"len(dd) = {len(dd)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prefix(model, game, prefix):\n",
    "    serial_evaluator = ActionHistoryTransformerEvaluator(model, device=device, block_size=n_max_context, vocab=action_vocab)\n",
    "    state = game.initial_state()\n",
    "    for action in prefix:\n",
    "        state = game.next_state(state, action)\n",
    "    legal_actions = game.legal_actions(state)\n",
    "    result = serial_evaluator.evaluate(game, state, legal_actions)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Someting is borked? Player1 win percent should be much higher??\n",
    "def compare_model_vs_data(model, game, dd):    \n",
    "    list(dd.items())[10][1]['*'].sum() > 100\n",
    "    top_k = sorted(dd.items(), key=lambda kv: kv[1]['*'].sum(), reverse=True)[:20]\n",
    "    top_k_keys = sorted(k for k, v in top_k)\n",
    "    \n",
    "    prefix_list = top_k_keys\n",
    "\n",
    "    # prefix_list = [\n",
    "    #     (0,), \n",
    "    #     (0,1), (0,2), (0,3), (0,4), (0,5), (0,6), (0,7),\n",
    "    #     (0,1,1), (0,1,2), (0,1,3), (0,1,4), (0,1,5), (0,1,6), (0,1,7),\n",
    "    #     (0,4,1), (0,4,2), (0,4,3), (0,4,4), (0,4,5), (0,4,6), (0,4,7),\n",
    "    # ]\n",
    "\n",
    "    for prefix in prefix_list:\n",
    "        print(f\"\\nprefix={prefix}\")\n",
    "        for gen, counts in dd[prefix].items():\n",
    "            if gen == '*':\n",
    "                print(f\"gen={gen}: {counts}, win_pct={100*counts[0]/sum(counts):.2f}%, sum={sum(counts)}\")\n",
    "        # # assert prefix[0] == 0\n",
    "        actions = prefix[1:]\n",
    "        eval_result = eval_prefix(model, game, actions)\n",
    "        # print(f'legal_policy={eval_result.legal_policy}')\n",
    "        # print(f'player_values={eval_result.player_values}')\n",
    "        print(f'player_probs={(eval_result.player_values+1)/2}')\n",
    "\n",
    "compare_model_vs_data(current_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model\n",
    "model_0 = create_random_model(model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42, device=device)\n",
    "if RUN_GENERATIONS:\n",
    "    model_1 = load_model(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n### Model 0\")\n",
    "print(model_0.action_embedding.weight)\n",
    "compare_model_vs_data(model_0, game, dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GENERATIONS:\n",
    "    print(\"\\n\\n### Model 1\")\n",
    "    print(model_1.action_embedding.weight)\n",
    "    compare_model_vs_data(model_1, game, dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tournament to calcualte ELO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import numpy as np\n",
    "from contextlib import asynccontextmanager\n",
    "from rgi.rgizero.tournament import Tournament\n",
    "from rgi.rgizero.players.alphazero import AlphazeroPlayer\n",
    "from rgi.rgizero.models.action_history_transformer import ActionHistoryTransformerEvaluator, AsyncNetworkEvaluator\n",
    "\n",
    "@asynccontextmanager\n",
    "async def create_player_factory(model, simulations, game, device, block_size, action_vocab, max_batch_size):\n",
    "    \"\"\"\n",
    "    Creates a shared evaluator and returns a factory function that produces \n",
    "    new AlphazeroPlayer instances using that shared evaluator.\n",
    "    \"\"\"\n",
    "    # 1. Setup the shared evaluator\n",
    "    serial_evaluator = ActionHistoryTransformerEvaluator(\n",
    "        model, \n",
    "        device=device, \n",
    "        block_size=n_max_context, \n",
    "        vocab=action_vocab\n",
    "    )\n",
    "    async_evaluator = AsyncNetworkEvaluator(\n",
    "        base_evaluator=serial_evaluator, \n",
    "        max_batch_size=max_batch_size, \n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 2. Start the evaluator background task\n",
    "    await async_evaluator.start()\n",
    "    \n",
    "    try:\n",
    "        # 3. Define the factory. This is called by Tournament for every game.\n",
    "        # It creates a NEW player instance but uses the SHARED async_evaluator.\n",
    "        def player_factory():\n",
    "            # Create a fresh RNG for each game/player instance\n",
    "            rng = np.random.default_rng(np.random.randint(0, 2**31))\n",
    "            return AlphazeroPlayer(\n",
    "                game, \n",
    "                async_evaluator, \n",
    "                rng=rng, \n",
    "                add_noise=True, \n",
    "                simulations=simulations\n",
    "            )\n",
    "            \n",
    "        yield player_factory\n",
    "        \n",
    "    finally:\n",
    "        # 4. Cleanup\n",
    "        await async_evaluator.stop()\n",
    "\n",
    "async def run_tournament_async():\n",
    "    # Use async with to manage the lifecycle of the evaluators\n",
    "    async with (\n",
    "        # create_player_factory(model_dict[0], 100, game, device, block_size, action_vocab, 10) as factory_gen0_100,\n",
    "        # create_player_factory(model_dict[1], 100, game, device, block_size, action_vocab, 10) as factory_gen1_100,\n",
    "        # create_player_factory(model_dict[2], 100, game, device, block_size, action_vocab, 10) as factory_gen2_100,\n",
    "        # create_player_factory(model_dict[3], 100, game, device, block_size, action_vocab, 10) as factory_gen3_100,\n",
    "        # create_player_factory(model_dict[4], 100, game, device, block_size, action_vocab, 10) as factory_gen4_100,\n",
    "        # create_player_factory(model_dict[5], 100, game, device, block_size, action_vocab, 10) as factory_gen5_100,\n",
    "        # create_player_factory(model_dict[10], 100, game, device, block_size, action_vocab, 10) as factory_gen6_100,\n",
    "        # create_player_factory(model_dict[15], 100, game, device, block_size, action_vocab, 10) as factory_gen7_100,\n",
    "        # create_player_factory(model_dict[20], 100, game, device, block_size, action_vocab, 10) as factory_gen8_100,\n",
    "\n",
    "        create_player_factory(model_dict[0], 200, game, device, block_size, action_vocab, 10) as factory_gen0_200,\n",
    "        #create_player_factory(model_dict[1], 200, game, device, block_size, action_vocab, 10) as factory_gen1_200,\n",
    "        #create_player_factory(model_dict[2], 200, game, device, block_size, action_vocab, 10) as factory_gen2_200,\n",
    "        #create_player_factory(model_dict[3], 200, game, device, block_size, action_vocab, 10) as factory_gen3_200,\n",
    "        #create_player_factory(model_dict[4], 200, game, device, block_size, action_vocab, 10) as factory_gen4_200,\n",
    "        create_player_factory(model_dict[5], 200, game, device, block_size, action_vocab, 10) as factory_gen5_200,\n",
    "        #create_player_factory(model_dict[10], 200, game, device, block_size, action_vocab, 10) as factory_gen10_200,\n",
    "        #create_player_factory(model_dict[15], 200, game, device, block_size, action_vocab, 10) as factory_gen15_200,\n",
    "        create_player_factory(model_dict[20], 200, game, device, block_size, action_vocab, 10) as factory_gen20_200,\n",
    "        ):\n",
    "        \n",
    "        # The dictionary now maps names to FACTORIES (Callables), not Player instances\n",
    "        player_factories = {\n",
    "            # \"factory_gen0_100\": factory_gen0_100,\n",
    "            # \"factory_gen1_100\": factory_gen1_100,\n",
    "            # \"factory_gen2_100\": factory_gen2_100,\n",
    "            # \"factory_gen3_100\": factory_gen3_100,\n",
    "            # \"factory_gen4_100\": factory_gen4_100,\n",
    "            # \"factory_gen5_100\": factory_gen5_100,\n",
    "            # \"factory_gen6_100\": factory_gen6_100,\n",
    "            # \"factory_gen7_100\": factory_gen7_100,\n",
    "\n",
    "            \"factory_gen0_200\": factory_gen0_200,\n",
    "            #\"factory_gen1_200\": factory_gen1_200,\n",
    "            #\"factory_gen2_200\": factory_gen2_200,\n",
    "            #\"factory_gen3_200\": factory_gen3_200,\n",
    "            #\"factory_gen4_200\": factory_gen4_200,\n",
    "            \"factory_gen5_200\": factory_gen5_200,\n",
    "            #\"factory_gen10_200\": factory_gen10_200,\n",
    "            #\"factory_gen15_200\": factory_gen15_200,\n",
    "            \"factory_gen20_200\": factory_gen20_200,\n",
    "        }\n",
    "        \n",
    "        tournament = Tournament(game, player_factories, initial_elo=1000)\n",
    "        \n",
    "        print(\"Running tournament...\")\n",
    "        # await tournament.run(num_games=1_000, concurrent_games=2000)\n",
    "        await tournament.run(num_games=100, concurrent_games=2000)\n",
    "        tournament.print_standings()\n",
    "\n",
    "# RUN_TOURNAMENT = True\n",
    "if RUN_TOURNAMENT:\n",
    "    await run_tournament_async()\n",
    "\n",
    "# Running tournament...\n",
    "# Tournament Progress: 100%|██████████| 10000/10000 [1:25:59<00:00,  1.94it/s]\n",
    "\n",
    "# Tournament Standings:\n",
    "# Rank  Player               ELO        Games    W-L-D          \n",
    "# -----------------------------------------------------------------\n",
    "# 1     factory_gen6_200     1140.5     1247     827-419-1      \n",
    "# 2     factory_gen2_200     1100.1     1251     693-554-4      \n",
    "# 3     factory_gen5_100     1074.4     1251     598-652-1      \n",
    "# 4     factory_gen3_200     1029.1     1252     674-573-5      \n",
    "# 5     factory_gen4_200     1027.0     1248     711-536-1      \n",
    "# 6     factory_gen0_200     1020.0     1254     444-810-0      \n",
    "# 7     factory_gen5_200     990.2      1248     742-502-4      \n",
    "# 8     factory_gen7_100     987.5      1250     650-597-3      \n",
    "# 9     factory_gen7_200     979.2      1248     768-476-4      \n",
    "# 10    factory_gen2_100     974.0      1249     522-723-4      \n",
    "# 11    factory_gen6_100     966.6      1248     684-564-0      \n",
    "# 12    factory_gen4_100     964.2      1251     557-693-1      \n",
    "# 13    factory_gen1_100     962.5      1252     547-705-0      \n",
    "# 14    factory_gen3_100     947.0      1251     528-723-0      \n",
    "# 15    factory_gen1_200     941.1      1252     630-620-2      \n",
    "# 16    factory_gen0_100     896.5      1248     410-838-0     \n",
    "\n",
    "\n",
    "## 20 generations.\n",
    "# Running tournament...\n",
    "# Tournament Progress: 100%|██████████| 1000/1000 [08:35<00:00,  1.94it/s]\n",
    "\n",
    "# Tournament Standings:\n",
    "# Rank  Player               ELO        Games    W-L-D          \n",
    "# -----------------------------------------------------------------\n",
    "# 1     factory_gen10_200    1114.2     333      212-120-1      \n",
    "# 2     factory_gen2_200     1032.6     333      190-141-2      \n",
    "# 3     factory_gen1_200     1003.9     334      159-175-0      \n",
    "# 4     factory_gen20_200    1000.9     335      171-164-0      \n",
    "# 5     factory_gen5_200     974.6      331      183-146-2      \n",
    "# 6     factory_gen0_200     873.8      334      82-251-1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model (continued)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.01)\n",
    "tuner.autotune_smart()\n",
    "\n",
    "# Using initial model as baseline.\n",
    "# ## Initial Model, loss=2.1298508644104004 elapsed=171.78943705558777s\n",
    "# ## Searching generation 0 with 22 candidates, including ['bias: False -> True', 'learning_rate: 0.005 -> 0.002', 'learning_rate: 0.005 -> 0.002', 'dtype: bfloat16 -> float16', 'weight_decay: 0.1 -> 0.2']\n",
    "# ## improved: False, loss=2.1332 elapsed=178.64s, mutation bias: False -> True\n",
    "# ## improved: False, loss=2.1395 elapsed=172.03s, mutation learning_rate: 0.005 -> 0.002\n",
    "# ## improved: False, loss=2.1395 elapsed=172.03s, mutation learning_rate: 0.005 -> 0.002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "tuner.autotune_smart()\n",
    "from rgi.rgizero.models.action_history_transformer import ActionHistoryTransformer, ActionHistoryTransformerEvaluator\n",
    "from rgi.rgizero.models.transformer import TransformerConfig\n",
    "\n",
    "tiny_config: TransformerConfig = TransformerConfig(n_max_context=100, n_layer=2, n_head=2, n_embd=8)\n",
    "tiny_model = ActionHistoryTransformer(config=tiny_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0))\n",
    "tiny_model.to(device)\n",
    "tiny_evaluator = ActionHistoryTransformerEvaluator(tiny_model, device=device, block_size=5, vocab=action_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.0001)\n",
    "tuner.autotune_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    initial_params=initial_params.copy(),\n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.0)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "best_model = tuner.load_best_model()\n",
    "compare_model_vs_data(best_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "print(f'tuner.best_loss={tuner.best_loss}')\n",
    "print(f'tuner.best_loss_elapsed={int(tuner.best_loss_elapsed)//60}m{tuner.best_loss_elapsed%60:.0f}s')\n",
    "pprint(tuner.best_params)\n",
    "# best_params = tuner.initial_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print tuner stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    initial_params=initial_params.copy(),\n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "# print stats based on cached results.\n",
    "tuner_stats = tuner.print_hparam_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(k,v['mean_val_delta']) for (k,v) in sorted(tuner_stats.items(), key=lambda x: x[1]['mean_val_delta'], reverse=True)]\n",
    "\n",
    "for x in  sorted([(v['mean_val_delta'], k, v['mean_val_1'], v['mean_val_2']) for (k,v) in tuner_stats.items() if not np.isnan(v['mean_val_delta'])], reverse=True): print(x)\n",
    "# sorted([(v['mean_val_delta'], k) for (k,v) in tuner_stats.items() if not np.isnan(v['mean_val_delta'])], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sorted([(v['std_val_delta'], k, v['mean_val_1'], v['mean_val_2']) for (k,v) in tuner_stats.items() if not np.isnan(v['std_val_delta'])], reverse=True): print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Convergence\n",
    "\n",
    "Synthetic sanity-check: train on a toy 2-step game where the first action strongly determines the winner. This verifies the value head and training loop can learn simple patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"xxx STOP HERE xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_0 = game.initial_state()\n",
    "all_actions_0 = game.all_actions()\n",
    "\n",
    "print(all_actions_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def play_random_game_with_fake_reward(game, max_actions) -> dict:\n",
    "    state = game.initial_state()\n",
    "    action_history = []\n",
    "    legal_policies = []\n",
    "    legal_action_idx_list = []\n",
    "\n",
    "    all_actions = game.all_actions()\n",
    "    all_action_idx_map = {action: idx for idx, action in enumerate(all_actions)}\n",
    "\n",
    "    num_actions = 0\n",
    "    while not game.is_terminal(state) and num_actions < max_actions:\n",
    "        current_player = game.current_player_id(state)\n",
    "        legal_actions = game.legal_actions(state)\n",
    "        action_idx = random.randrange(len(legal_actions))\n",
    "        action = legal_actions[action_idx]\n",
    "\n",
    "        action_history.append(action)\n",
    "        legal_policies.append(np.ones(len(legal_actions))/len(legal_actions))\n",
    "        legal_action_idx = np.array([all_action_idx_map[action] for action in legal_actions])\n",
    "        legal_action_idx_list.append(legal_action_idx)\n",
    "\n",
    "        state = game.next_state(state, action)\n",
    "        num_actions += 1\n",
    "\n",
    "    # Determine outcome\n",
    "    fake_reward = np.mean(action_history) / len(legal_actions)\n",
    "    rewards = np.array([fake_reward, 1.0-fake_reward])\n",
    "    if fake_reward >= 0.5:\n",
    "        winner = 1\n",
    "    else:\n",
    "        winner = 2\n",
    "\n",
    "    return {\n",
    "        \"winner\": winner,\n",
    "        \"rewards\": rewards,\n",
    "        \"action_history\": action_history,\n",
    "        \"legal_policies\": legal_policies,\n",
    "        \"final_state\": state,\n",
    "        \"legal_action_idx\": legal_action_idx_list,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_game_with_fake_reward(game, max_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [play_random_game_with_fake_reward(game, max_actions=2) for _ in range(100_000)]\n",
    "print_game_stats(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_gen_name = \"fake-0\"\n",
    "trajectory_path = write_trajectory_dataset(results, action_vocab, fake_gen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_model_config = model_config_dict[MODEL_SIZE]\n",
    "fake_model_config = model_config_dict[\"large\"]\n",
    "fake_model = create_random_model(fake_model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42, device=device)\n",
    "\n",
    "training_splits = [f'gen-{fake_gen_name}']\n",
    "fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n",
    "save_model(fake_model, fake_trainer, fake_gen_name)\n",
    "\n",
    "## model_size=tiny\n",
    "# num decayed parameter tensors: 11, with 1,968 parameters\n",
    "# num non-decayed parameter tensors: 7, with 50 parameters\n",
    "# using fused AdamW: False\n",
    "# step 0: train loss 2.7817, val loss 2.7816\n",
    "# iter 0/49/488: loss 2.7821, time 2537.56ms\n",
    "# iter 100/147/488: loss 2.6890, time 53.61ms\n",
    "# iter 200/245/488: loss 2.6342, time 63.05ms\n",
    "# iter 300/343/488: loss 2.6187, time 55.31ms\n",
    "# iter 400/441/488: loss 2.6147, time 61.11ms\n",
    "\n",
    "## model_size=large\n",
    "# num decayed parameter tensors: 35, with 1,579,776 parameters\n",
    "# num non-decayed parameter tensors: 19, with 2,186 parameters\n",
    "# using fused AdamW: False\n",
    "# step 0: train loss 2.8087, val loss 2.8088\n",
    "# iter 0/49/488: loss 2.8099, time 11225.20ms\n",
    "# iter 100/147/488: loss 2.6065, time 596.91ms\n",
    "# iter 200/245/488: loss 2.6075, time 618.00ms\n",
    "# iter 300/343/488: loss 2.6080, time 613.63ms\n",
    "# iter 400/441/488: loss 2.6051, time 616.39ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rerun in range(10):\n",
    "#     print(f\"Re-running training for {fake_gen_name} {rerun+1} of 10\")\n",
    "#     fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n",
    "#     save_model(fake_model, fake_trainer, fake_gen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [td for td in td_array]\n",
    "fake_td_array = [TrajectoryDataset(DATA_DIR, split, block_size=n_max_context) for split in training_splits]\n",
    "fake_unrolled = [(generation+1, d) for generation, td in enumerate(fake_td_array) for d in td]\n",
    "\n",
    "# gen, d = unrolled[0], \n",
    "# d.action[:2]\n",
    "# d.value[0]\n",
    "\n",
    "# Inspect training data\n",
    "fake_dd = defaultdict(lambda: defaultdict(lambda: torch.tensor([0., 0.])))\n",
    "\n",
    "for gen, d in fake_unrolled:\n",
    "    for g in ['*', gen]:    \n",
    "        fake_dd[tuple(tuple(d.action[:0].tolist()))][g] += d.value[0]\n",
    "        fake_dd[tuple(tuple(d.action[:1].tolist()))][g] += d.value[0]\n",
    "        fake_dd[tuple(tuple(d.action[:2].tolist()))][g] += d.value[0]\n",
    "        # fake_dd[tuple(tuple(d.action[:3].tolist()))][g] += d.value[0]\n",
    "\n",
    "print(f\"len(fake_dd) = {len(fake_dd)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_model = load_model(fake_gen_name)\n",
    "compare_model_vs_data(fake_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
