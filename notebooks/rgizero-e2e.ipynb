{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step run of alphazero self-play & training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports successful\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import asyncio\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Game and players\n",
    "from rgi.rgizero.games.connect4 import Connect4Game\n",
    "from rgi.rgizero.players.alphazero import AlphazeroPlayer\n",
    "from rgi.rgizero.players.alphazero import play_game\n",
    "\n",
    "from notebook_utils import reload_local_modules\n",
    "\n",
    "print(\"✅ Imports successful\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "assert device in ('cuda', 'mps'), f\"No accelerator available, device={device}\"\n",
    "\n",
    "# Allow asyncio to work with jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Increase numpy print width\n",
    "np.set_printoptions(linewidth=300)\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = True     # Set options to make debugger work properly. Single worker, etc.\n",
    "LOAD_MODEL = False\n",
    "TRAIN_MODEL = True\n",
    "MODEL_SIZE = \"tiny\"  # \"tiny\" or \"small\" or \"large\" or \"xl\"\n",
    "NUM_SIMULATIONS = 200\n",
    "RUN_GENERATIONS = True\n",
    "\n",
    "# If False, we still load previous games from disk.\n",
    "NUM_GAMES = 10_000\n",
    "MAX_TRAINING_EPOCHS = 10\n",
    "TRAIN_BATCH_SIZE = 2048\n",
    "MAX_TRAINING_ITERS = 1_000_000 // TRAIN_BATCH_SIZE\n",
    "CONFIG_ALIAS = f'trajectory_sims-{NUM_SIMULATIONS}_games-{NUM_GAMES}_size-{MODEL_SIZE}_train-{MAX_TRAINING_ITERS}_x1'\n",
    "NUM_GENERATIONS = 7\n",
    "\n",
    "# DEBUG: Update batch_size after config_alias\n",
    "MODEL_SIZE = \"small\"\n",
    "MAX_TRAINING_ITERS = 100_000_000 // TRAIN_BATCH_SIZE\n",
    "MAX_TRAINING_EPOCHS = 10_000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up history-wrapped game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using HistoryTrackingGame from module\n",
      "Game: Connect4Game, Players: 2, Actions: [1, 2, 3, 4, 5, 6, 7]\n",
      "Creating data dir:  /Users/rodo/src/rgi3/data/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1\n",
      "Creating model dir:  /Users/rodo/src/rgi3/models/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1\n"
     ]
    }
   ],
   "source": [
    "from rgi.rgizero.games.history_wrapper import HistoryTrackingGame\n",
    "from rgi.rgizero.data.trajectory_dataset import Vocab\n",
    "from rgi.rgizero.common import TOKENS\n",
    "\n",
    "base_game, max_game_length = Connect4Game(connect_length=4), 7*6\n",
    "\n",
    "game = HistoryTrackingGame(base_game)\n",
    "state_0 = game.initial_state()\n",
    "block_size = max_game_length + 2\n",
    "all_actions = game.all_actions()\n",
    "action_vocab = Vocab(itos=[TOKENS.START_OF_GAME] + list(all_actions))\n",
    "n_max_context = max_game_length + 2\n",
    "game_name = base_game.__class__.__name__\n",
    "\n",
    "print(\"✅ Using HistoryTrackingGame from module\")\n",
    "print(f\"Game: {game_name}, Players: {game.num_players(state_0)}, Actions: {list(game.all_actions())}\")\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data\" / \"rgizero-e2e\" / game_name / CONFIG_ALIAS\n",
    "print(\"Creating data dir: \", DATA_DIR)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_DIR = Path.cwd().parent / \"models\" / \"rgizero-e2e\" / game_name / CONFIG_ALIAS\n",
    "print(\"Creating model dir: \", MODEL_DIR)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create random generation_0 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_stats(dataset_path, split_name):\n",
    "    \"\"\"Print statistics about a loaded trajectory dataset.\"\"\"\n",
    "    td = TrajectoryDataset(dataset_path.parent, split_name, block_size=n_max_context)\n",
    "    \n",
    "    # Calculate basic stats\n",
    "    num_trajectories = len(td)\n",
    "    total_actions = td._num_actions\n",
    "    avg_trajectory_length = total_actions / num_trajectories if num_trajectories > 0 else 0\n",
    "    \n",
    "    # Get trajectory lengths, winners, and first moves\n",
    "    trajectory_lengths = []\n",
    "    winners = []\n",
    "    first_moves = []\n",
    "    \n",
    "    for i in range(num_trajectories):\n",
    "        start_idx = td.boundaries[i]\n",
    "        end_idx = td.boundaries[i + 1]\n",
    "        traj_length = end_idx - start_idx\n",
    "        trajectory_lengths.append(traj_length)\n",
    "        \n",
    "        # Get winner from final values (values are the same throughout trajectory)\n",
    "        # Values are in range [-1, 1] where positive means player 1 advantage\n",
    "        final_values = td.value_data[start_idx]  # shape: (num_players,)\n",
    "        if final_values[0] > final_values[1]:\n",
    "            winners.append(1)\n",
    "        elif final_values[1] > final_values[0]:\n",
    "            winners.append(2)\n",
    "        else:\n",
    "            winners.append(None)  # Draw\n",
    "        \n",
    "        # Get first move (decode from vocab)\n",
    "        first_action_encoded = td.action_data[start_idx]\n",
    "        first_action = action_vocab.decode([first_action_encoded])[0]\n",
    "        first_moves.append(first_action)\n",
    "    \n",
    "    # Print basic stats\n",
    "    print(f\"Dataset Stats:\")\n",
    "    print(f\"  Trajectories: {num_trajectories}\")\n",
    "    print(f\"  Total actions: {total_actions}\")\n",
    "    print(f\"  Avg trajectory length: {avg_trajectory_length:.2f}\")\n",
    "    print(f\"  Trajectory length - min: {min(trajectory_lengths)}, max: {max(trajectory_lengths)}, mean: {np.mean(trajectory_lengths):.2f}\")\n",
    "    \n",
    "    # Print winner stats (similar to print_game_stats)\n",
    "    print(f\"Winner Stats:\")\n",
    "    winner_stats = Counter(winners)\n",
    "    total_games = num_trajectories\n",
    "    win1_pct = 100 * winner_stats[1] / total_games if total_games > 0 else 0\n",
    "    win2_pct = 100 * winner_stats[2] / total_games if total_games > 0 else 0\n",
    "    print(f\"  Winner counts: win[1]={win1_pct:.2f}% win[2]={win2_pct:.2f}%, n={total_games}\")\n",
    "    \n",
    "    # Print stats by initial move\n",
    "    print(f\"Winner Stats by initial move:\")\n",
    "    move_stats = defaultdict(Counter)\n",
    "    for first_move, winner in zip(first_moves, winners):\n",
    "        move_stats[first_move][winner] += 1\n",
    "    \n",
    "    for action in sorted(move_stats.keys()):\n",
    "        counts = move_stats[action]\n",
    "        total = sum(counts.values())\n",
    "        win1_pct = 100 * counts[1] / total if total > 0 else 0\n",
    "        win2_pct = 100 * counts[2] / total if total > 0 else 0\n",
    "        draw_pct = 100 * counts[None] / total if total > 0 else 0\n",
    "        print(f\"  a={action}: n={total:3} win[1]={win1_pct:.2f}% counts={counts}, win[2]={win2_pct:.2f}% draw={draw_pct:.2f}%\")\n",
    "\n",
    "def print_model_stats(model, config_alias=\"\"):\n",
    "    \"\"\"Print statistics about a model.\"\"\"\n",
    "    # Count parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Model Stats:\")\n",
    "    print(f\"  Config: {model.config}\")\n",
    "    print(f\"  Total parameters: {num_params:,}\")\n",
    "    print(f\"  Trainable parameters: {num_trainable:,}\")\n",
    "    if config_alias:\n",
    "        print(f\"  Config alias: {config_alias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "from rgi.rgizero.models.action_history_transformer import ActionHistoryTransformer\n",
    "from rgi.rgizero.models.transformer import TransformerConfig\n",
    "\n",
    "model_config_dict = {\n",
    "    \"tiny\": TransformerConfig(n_max_context=n_max_context, n_layer=2, n_head=2, n_embd=8),\n",
    "    \"small\": TransformerConfig(n_max_context=n_max_context, n_layer=4, n_head=4, n_embd=32),\n",
    "    \"large\": TransformerConfig(n_max_context=n_max_context, n_layer=8, n_head=8, n_embd=128),\n",
    "    \"xl\": TransformerConfig(n_max_context=n_max_context, n_layer=16, n_head=16, n_embd=256),\n",
    "}\n",
    "\n",
    "\n",
    "def create_random_model(config: TransformerConfig, action_vocab_size, num_players,  seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed) # Ensure numpy operations are also seeded\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    model = ActionHistoryTransformer(config=config, action_vocab_size=action_vocab_size, num_players=num_players)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "# Make model initialization deterministic\n",
    "model_config = model_config_dict[MODEL_SIZE]\n",
    "# TODO: Use MODEL_SIZE!\n",
    "# model_config = model_config_dict[\"small\"] # Override to see if we can fit better.\n",
    "model_0 = create_random_model(model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define play & generation code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.rgizero.models.action_history_transformer import AsyncNetworkEvaluator, ActionHistoryTransformerEvaluator\n",
    "from rgi.rgizero.players.alphazero import play_game_async\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "async def play_games_async(num_games: int, player_factory: Callable[[], AlphazeroPlayer], max_concurrent_games: int = 1000):\n",
    "    sem = asyncio.Semaphore(max_concurrent_games)\n",
    "    tasks = []\n",
    "    async def create_player_and_create_game():\n",
    "        async with sem:\n",
    "            t0 = time.time()\n",
    "            player = player_factory()\n",
    "            game_result = await play_game_async(game, [player, player])\n",
    "            t1 = time.time()\n",
    "            game_result['time'] = t1 - t0\n",
    "            return game_result\n",
    "\n",
    "    tasks = [create_player_and_create_game() for _ in range(num_games)]\n",
    "    results = await tqdm.gather(*tasks)   # same as asyncio.gather, but with a progress bar\n",
    "    return results\n",
    "\n",
    "async def play_generation_async(model, num_games, simulations=NUM_SIMULATIONS, max_concurrent_games=1024):\n",
    "    serial_evaluator = ActionHistoryTransformerEvaluator(model, device=device, block_size=block_size, vocab=action_vocab)\n",
    "    async_evaluator = AsyncNetworkEvaluator(base_evaluator=serial_evaluator, max_batch_size=max_concurrent_games, verbose=False)\n",
    "\n",
    "    master_rng = np.random.default_rng(42)\n",
    "    async_player_factory = lambda: AlphazeroPlayer(game, async_evaluator, rng=np.random.default_rng(master_rng.integers(0, 2**31)), add_noise=False, simulations=simulations)\n",
    "\n",
    "    await async_evaluator.start()\n",
    "    results = await play_games_async(num_games=num_games, player_factory=async_player_factory, max_concurrent_games=max_concurrent_games)\n",
    "    await async_evaluator.stop()\n",
    "    return results\n",
    "\n",
    "def print_game_stats(results):\n",
    "    print(\"Winner Stats:\")\n",
    "    winner_stats = Counter(result['winner'] for result in results)\n",
    "    print(f\"Winner counts: win[1]={100*winner_stats[1]/sum(winner_stats.values()):.2f}% win[2]={100*winner_stats[2]/sum(winner_stats.values()):.2f}%, n={sum(winner_stats.values())}, draw={100*winner_stats[None]/sum(winner_stats.values()):.2f}%\")\n",
    "    game_lengths = [len(result['action_history']) for result in results]\n",
    "    print(f\"Game Length min: {min(game_lengths)}, max: {max(game_lengths)}, mean: {np.mean(game_lengths):.2f}\")\n",
    "    print(\"Winner Stats by initial move:\")\n",
    "    dd = defaultdict(Counter)\n",
    "    for result in results:\n",
    "        dd[result['action_history'][0]][result['winner']] += 1\n",
    "    for action, counts in sorted(dd.items()):\n",
    "        print(f\"  a={action}: n={sum(counts.values()):3} win[1]={100*counts[1]/sum(counts.values()):.2f}% counts={counts}, win[2]={100*counts[2]/sum(counts.values()):.2f}% draw={100*counts[None]/sum(counts.values()):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Confirm we can read & write to trajectory_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.rgizero.data.trajectory_dataset import TrajectoryDatasetBuilder, TrajectoryDataset, build_trajectory_loader\n",
    "reload_local_modules(verbose=False)\n",
    "\n",
    "def add_trajectory(game_result, vocab, td_builder):\n",
    "    action_history = game_result['action_history']\n",
    "    trajectory_length = len(action_history)\n",
    "    legal_policies = game_result['legal_policies']\n",
    "    legal_action_idx = game_result['legal_action_idx']\n",
    "    rewards = game_result['rewards']\n",
    "\n",
    "    # Translation key for converting legal_action_ids to vocab_action_idx.\n",
    "    action_idx_to_vocab_idx = vocab.encode(all_actions)\n",
    "\n",
    "    fixed_width_policies = np.zeros((trajectory_length, vocab.vocab_size))\n",
    "    for i in range(trajectory_length):\n",
    "        vocab_action_idx = action_idx_to_vocab_idx[legal_action_idx[i]]\n",
    "        fixed_width_policies[i, vocab_action_idx] = legal_policies[i]\n",
    "\n",
    "    encoded_action_history = vocab.encode(action_history)\n",
    "    tiled_rewards = np.tile(rewards, (trajectory_length, 1))  # shape (num_players,) -> (num_moves, num_players)\n",
    "    \n",
    "    td_builder.add_trajectory(actions=encoded_action_history, fixed_width_policies=fixed_width_policies, values=tiled_rewards)\n",
    "\n",
    "def write_trajectory_dataset(results, action_vocab, generation_id):\n",
    "    td_builder = TrajectoryDatasetBuilder(action_vocab)\n",
    "    for game_result in results:\n",
    "        add_trajectory(game_result, action_vocab, td_builder)\n",
    "\n",
    "    trajectory_path = td_builder.save(DATA_DIR, f\"gen-{generation_id}\")\n",
    "    return trajectory_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.rgizero.train import Trainer, TrainConfig\n",
    "\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    model_name=\"connect4-e2e\",\n",
    "    model_version=\"v1\",\n",
    "\n",
    "    eval_interval = 1000,  # keep frequent because we'll overfit\n",
    "    eval_iters = 20,\n",
    "    log_interval = 100,  # don't print too too often\n",
    "    max_epochs = MAX_TRAINING_EPOCHS,\n",
    "\n",
    "    # we expect to overfit on this small dataset, so only save when val improves\n",
    "    always_save_checkpoint = False,\n",
    "\n",
    "    gradient_accumulation_steps = 1,\n",
    "    batch_size = TRAIN_BATCH_SIZE,\n",
    "\n",
    "    learning_rate = LEARNING_RATE,  # with baby networks can afford to go a bit higher\n",
    "    max_iters = MAX_TRAINING_ITERS,\n",
    "    lr_decay_iters = MAX_TRAINING_ITERS,  # make equal to max_iters usually\n",
    "    min_lr = LEARNING_RATE / 10,  # learning_rate / 10 usually\n",
    "    beta2 = 0.99,  # make a bit bigger because number of tokens per iter is small\n",
    "\n",
    "    warmup_iters = 0,  # not super necessary potentially\n",
    ")\n",
    "\n",
    "def train_model(model, training_splits, train_config):\n",
    "    # Load dataset\n",
    "    num_workers = 0 if DEBUG_MODE else 4\n",
    "\n",
    "    trajectory_loader = build_trajectory_loader(\n",
    "        DATA_DIR, training_splits, block_size=n_max_context, batch_size=train_config.batch_size,\n",
    "        device=device, workers=num_workers, shuffle=True)\n",
    "        \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_config=train_config,\n",
    "        train_loader=trajectory_loader,\n",
    "        val_loader=trajectory_loader,  # TODO: Create separate validation loader\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "def get_model_path(generation_id):\n",
    "    return MODEL_DIR / f\"gen-{generation_id}.pt\"\n",
    "\n",
    "def save_model(model, trainer, generation_id):\n",
    "    # Save model\n",
    "    model_path = get_model_path(generation_id)\n",
    "\n",
    "    checkpoint = {\n",
    "        'model': model.state_dict(),\n",
    "        'model_config': dataclasses.asdict(model.config),\n",
    "        'vocab': action_vocab.to_dict(),\n",
    "        'iter_num': trainer.iter_num,\n",
    "        'best_val_loss': trainer.best_val_loss,\n",
    "        'num_players': game.num_players(state_0),\n",
    "    }\n",
    "    torch.save(checkpoint, model_path)\n",
    "    return model_path\n",
    "\n",
    "def load_model(generation_id):\n",
    "    model_path = get_model_path(generation_id)\n",
    "    loaded_checkpoint = torch.load(model_path)\n",
    "    loaded_model = ActionHistoryTransformer(\n",
    "        config=TransformerConfig(**loaded_checkpoint['model_config']),\n",
    "        action_vocab_size=loaded_checkpoint['vocab']['vocab_size'],\n",
    "        num_players=loaded_checkpoint['num_players']\n",
    "    )\n",
    "    loaded_model.load_state_dict(loaded_checkpoint['model']) \n",
    "    loaded_model.to(device)\n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a single generation of play & train\n",
    "async def run_generation(model, num_games, num_simulations, generation_id):\n",
    "    print(f\"\\n\\n## Running generation {generation_id} for config_alias={CONFIG_ALIAS}\")\n",
    "    split_name = f\"gen-{generation_id}\"\n",
    "    expected_trajectory_path = DATA_DIR / split_name\n",
    "    if not expected_trajectory_path.exists():\n",
    "        print(f\"Playing {num_games} games, simulations={num_simulations}, model_size={MODEL_SIZE}\")\n",
    "        results = await play_generation_async(model, num_games=NUM_GAMES, simulations=NUM_SIMULATIONS)\n",
    "        print_game_stats(results)\n",
    "        trajectory_path = write_trajectory_dataset(results, action_vocab, generation_id)\n",
    "        assert trajectory_path == expected_trajectory_path\n",
    "    else:\n",
    "        print(f\"Loading trajectory from {expected_trajectory_path}\")\n",
    "        print_dataset_stats(expected_trajectory_path, split_name)\n",
    "        trajectory_path = expected_trajectory_path\n",
    "        results = None\n",
    "\n",
    "    model_path = get_model_path(generation_id)\n",
    "    if not model_path.exists():\n",
    "        print(f\"Training model on {split_name}\")\n",
    "        training_splits = [f\"gen-{i}\" for i in range(1, generation_id+1)]\n",
    "        # TODO: We're continuing training on a previosu model here ... should we train a new model from scratch?\n",
    "        print(train_config)\n",
    "        updated_model, trainer = train_model(model, training_splits, train_config)\n",
    "        save_model(updated_model, trainer, generation_id)\n",
    "    else:\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        updated_model = load_model(generation_id)\n",
    "        print_model_stats(updated_model, config_alias=MODEL_SIZE)\n",
    "\n",
    "    return results, trajectory_path, updated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "## Running generation 1 for config_alias=trajectory_sims-200_games-10000_size-tiny_train-488_x1\n",
      "Loading trajectory from /Users/rodo/src/rgi3/data/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-1\n",
      "Dataset Stats:\n",
      "  Trajectories: 10000\n",
      "  Total actions: 140493\n",
      "  Avg trajectory length: 14.05\n",
      "  Trajectory length - min: 7, max: 42, mean: 14.05\n",
      "Winner Stats:\n",
      "  Winner counts: win[1]=61.93% win[2]=38.06%, n=10000\n",
      "Winner Stats by initial move:\n",
      "  a=1: n=1564 win[1]=51.92% counts=Counter({1: 812, 2: 752}), win[2]=48.08% draw=0.00%\n",
      "  a=2: n=1344 win[1]=57.37% counts=Counter({1: 771, 2: 573}), win[2]=42.63% draw=0.00%\n",
      "  a=3: n=1297 win[1]=65.23% counts=Counter({1: 846, 2: 451}), win[2]=34.77% draw=0.00%\n",
      "  a=4: n=1493 win[1]=76.36% counts=Counter({1: 1140, 2: 353}), win[2]=23.64% draw=0.00%\n",
      "  a=5: n=1525 win[1]=66.49% counts=Counter({1: 1014, 2: 511}), win[2]=33.51% draw=0.00%\n",
      "  a=6: n=1401 win[1]=62.03% counts=Counter({1: 869, 2: 532}), win[2]=37.97% draw=0.00%\n",
      "  a=7: n=1376 win[1]=53.85% counts=Counter({1: 741, 2: 634, None: 1}), win[2]=46.08% draw=0.07%\n",
      "Loading model from /Users/rodo/src/rgi3/models/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-1.pt\n",
      "Model Stats:\n",
      "  Config: TransformerConfig(n_max_context=44, n_layer=4, n_head=4, n_embd=32, dropout=0.0, bias=False)\n",
      "  Total parameters: 51,178\n",
      "  Trainable parameters: 51,178\n",
      "  Config alias: small\n",
      "\n",
      "\n",
      "## Running generation 2 for config_alias=trajectory_sims-200_games-10000_size-tiny_train-488_x1\n",
      "Loading trajectory from /Users/rodo/src/rgi3/data/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-2\n",
      "Dataset Stats:\n",
      "  Trajectories: 10000\n",
      "  Total actions: 136161\n",
      "  Avg trajectory length: 13.62\n",
      "  Trajectory length - min: 7, max: 38, mean: 13.62\n",
      "Winner Stats:\n",
      "  Winner counts: win[1]=46.45% win[2]=53.55%, n=10000\n",
      "Winner Stats by initial move:\n",
      "  a=1: n=933 win[1]=34.19% counts=Counter({2: 614, 1: 319}), win[2]=65.81% draw=0.00%\n",
      "  a=2: n=328 win[1]=20.12% counts=Counter({2: 262, 1: 66}), win[2]=79.88% draw=0.00%\n",
      "  a=3: n=1647 win[1]=43.90% counts=Counter({2: 924, 1: 723}), win[2]=56.10% draw=0.00%\n",
      "  a=4: n=4260 win[1]=57.54% counts=Counter({1: 2451, 2: 1809}), win[2]=42.46% draw=0.00%\n",
      "  a=5: n=1508 win[1]=41.71% counts=Counter({2: 879, 1: 629}), win[2]=58.29% draw=0.00%\n",
      "  a=6: n=330 win[1]=26.06% counts=Counter({2: 244, 1: 86}), win[2]=73.94% draw=0.00%\n",
      "  a=7: n=994 win[1]=37.32% counts=Counter({2: 623, 1: 371}), win[2]=62.68% draw=0.00%\n",
      "Loading model from /Users/rodo/src/rgi3/models/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-2.pt\n",
      "Model Stats:\n",
      "  Config: TransformerConfig(n_max_context=44, n_layer=4, n_head=4, n_embd=32, dropout=0.0, bias=False)\n",
      "  Total parameters: 51,178\n",
      "  Trainable parameters: 51,178\n",
      "  Config alias: small\n",
      "\n",
      "\n",
      "## Running generation 3 for config_alias=trajectory_sims-200_games-10000_size-tiny_train-488_x1\n",
      "Loading trajectory from /Users/rodo/src/rgi3/data/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-3\n",
      "Dataset Stats:\n",
      "  Trajectories: 10000\n",
      "  Total actions: 141481\n",
      "  Avg trajectory length: 14.15\n",
      "  Trajectory length - min: 7, max: 42, mean: 14.15\n",
      "Winner Stats:\n",
      "  Winner counts: win[1]=52.01% win[2]=47.96%, n=10000\n",
      "Winner Stats by initial move:\n",
      "  a=1: n= 94 win[1]=43.62% counts=Counter({2: 53, 1: 41}), win[2]=56.38% draw=0.00%\n",
      "  a=2: n=109 win[1]=32.11% counts=Counter({2: 74, 1: 35}), win[2]=67.89% draw=0.00%\n",
      "  a=3: n=103 win[1]=22.33% counts=Counter({2: 80, 1: 23}), win[2]=77.67% draw=0.00%\n",
      "  a=4: n=9218 win[1]=53.38% counts=Counter({1: 4921, 2: 4295, None: 2}), win[2]=46.59% draw=0.02%\n",
      "  a=5: n=132 win[1]=50.00% counts=Counter({1: 66, 2: 65, None: 1}), win[2]=49.24% draw=0.76%\n",
      "  a=6: n=148 win[1]=34.46% counts=Counter({2: 97, 1: 51}), win[2]=65.54% draw=0.00%\n",
      "  a=7: n=196 win[1]=32.65% counts=Counter({2: 132, 1: 64}), win[2]=67.35% draw=0.00%\n",
      "Loading model from /Users/rodo/src/rgi3/models/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-3.pt\n",
      "Model Stats:\n",
      "  Config: TransformerConfig(n_max_context=44, n_layer=4, n_head=4, n_embd=32, dropout=0.0, bias=False)\n",
      "  Total parameters: 51,178\n",
      "  Trainable parameters: 51,178\n",
      "  Config alias: small\n",
      "\n",
      "\n",
      "## Running generation 4 for config_alias=trajectory_sims-200_games-10000_size-tiny_train-488_x1\n",
      "Loading trajectory from /Users/rodo/src/rgi3/data/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-4\n",
      "Dataset Stats:\n",
      "  Trajectories: 10000\n",
      "  Total actions: 139426\n",
      "  Avg trajectory length: 13.94\n",
      "  Trajectory length - min: 7, max: 39, mean: 13.94\n",
      "Winner Stats:\n",
      "  Winner counts: win[1]=45.70% win[2]=54.30%, n=10000\n",
      "Winner Stats by initial move:\n",
      "  a=1: n=139 win[1]=38.85% counts=Counter({2: 85, 1: 54}), win[2]=61.15% draw=0.00%\n",
      "  a=2: n=7686 win[1]=43.98% counts=Counter({2: 4306, 1: 3380}), win[2]=56.02% draw=0.00%\n",
      "  a=3: n=349 win[1]=42.69% counts=Counter({2: 200, 1: 149}), win[2]=57.31% draw=0.00%\n",
      "  a=4: n=882 win[1]=64.06% counts=Counter({1: 565, 2: 317}), win[2]=35.94% draw=0.00%\n",
      "  a=5: n=319 win[1]=57.68% counts=Counter({1: 184, 2: 135}), win[2]=42.32% draw=0.00%\n",
      "  a=6: n= 94 win[1]=39.36% counts=Counter({2: 57, 1: 37}), win[2]=60.64% draw=0.00%\n",
      "  a=7: n=531 win[1]=37.85% counts=Counter({2: 330, 1: 201}), win[2]=62.15% draw=0.00%\n",
      "Loading model from /Users/rodo/src/rgi3/models/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-4.pt\n",
      "Model Stats:\n",
      "  Config: TransformerConfig(n_max_context=44, n_layer=4, n_head=4, n_embd=32, dropout=0.0, bias=False)\n",
      "  Total parameters: 51,178\n",
      "  Trainable parameters: 51,178\n",
      "  Config alias: small\n",
      "\n",
      "\n",
      "## Running generation 5 for config_alias=trajectory_sims-200_games-10000_size-tiny_train-488_x1\n",
      "Loading trajectory from /Users/rodo/src/rgi3/data/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-5\n",
      "Dataset Stats:\n",
      "  Trajectories: 10000\n",
      "  Total actions: 137305\n",
      "  Avg trajectory length: 13.73\n",
      "  Trajectory length - min: 7, max: 42, mean: 13.73\n",
      "Winner Stats:\n",
      "  Winner counts: win[1]=58.39% win[2]=41.61%, n=10000\n",
      "Winner Stats by initial move:\n",
      "  a=1: n=462 win[1]=37.66% counts=Counter({2: 288, 1: 174}), win[2]=62.34% draw=0.00%\n",
      "  a=2: n=1005 win[1]=54.63% counts=Counter({1: 549, 2: 456}), win[2]=45.37% draw=0.00%\n",
      "  a=3: n=1499 win[1]=48.10% counts=Counter({2: 778, 1: 721}), win[2]=51.90% draw=0.00%\n",
      "  a=4: n=5503 win[1]=67.85% counts=Counter({1: 3734, 2: 1769}), win[2]=32.15% draw=0.00%\n",
      "  a=5: n=864 win[1]=41.32% counts=Counter({2: 507, 1: 357}), win[2]=58.68% draw=0.00%\n",
      "  a=6: n=191 win[1]=65.45% counts=Counter({1: 125, 2: 66}), win[2]=34.55% draw=0.00%\n",
      "  a=7: n=476 win[1]=37.61% counts=Counter({2: 297, 1: 179}), win[2]=62.39% draw=0.00%\n",
      "Loading model from /Users/rodo/src/rgi3/models/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1/gen-5.pt\n",
      "Model Stats:\n",
      "  Config: TransformerConfig(n_max_context=44, n_layer=4, n_head=4, n_embd=32, dropout=0.0, bias=False)\n",
      "  Total parameters: 51,178\n",
      "  Trainable parameters: 51,178\n",
      "  Config alias: small\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "trajectory_paths_dict = {}\n",
    "model_dict = {0: model_0}\n",
    "\n",
    "current_model = model_dict[0]\n",
    "if RUN_GENERATIONS:\n",
    "    for generation_id in range(1, NUM_GENERATIONS+1):\n",
    "        current_model = model_dict[generation_id-1]\n",
    "        results_i, trajectory_path_i, model_i = await run_generation(current_model, num_games=NUM_GAMES, num_simulations=NUM_SIMULATIONS, generation_id=generation_id)\n",
    "        results_dict[generation_id] = results_i\n",
    "        trajectory_paths_dict[generation_id] = trajectory_path_i\n",
    "        model_dict[generation_id] = model_i\n",
    "\n",
    "## refactor, learning_rate = 0.05, warmup_iters=0\n",
    "# step 0: train loss 2.7801, val loss 2.7801\n",
    "# iter 0/5/488: loss 2.7801, time 611.02ms\n",
    "# iter 100/105/488: loss 2.5840, time 63.73ms\n",
    "# iter 200/205/488: loss 2.5958, time 62.98ms\n",
    "# iter 300/305/488: loss 2.5835, time 60.15ms\n",
    "# iter 400/405/488: loss 2.5793, time 63.62ms\n",
    "\n",
    "# ## model = small\n",
    "# step 0: train loss 2.7741, val loss 2.7741\n",
    "# iter 0/5/488: loss 2.7743, time 1624.89ms\n",
    "# iter 100/105/488: loss 2.6157, time 141.39ms\n",
    "# iter 200/205/488: loss 2.6120, time 161.22ms\n",
    "# iter 300/305/488: loss 2.5983, time 203.82ms\n",
    "\n",
    "\n",
    "# using fused AdamW: False\n",
    "# step 0: train loss 2.7801, val loss 2.7801\n",
    "# iter 0/5/4882: loss 2.7801, time 1422.53ms\n",
    "# iter 100/105/4882: loss 2.5970, time 110.71ms\n",
    "# iter 200/205/4882: loss 2.5962, time 116.96ms\n",
    "# iter 300/305/4882: loss 2.5917, time 160.95ms\n",
    "# iter 400/405/4882: loss 2.5885, time 63.37ms\n",
    "# iter 500/505/4882: loss 2.5912, time 65.25ms\n",
    "# iter 600/605/4882: loss 2.6000, time 67.49ms\n",
    "# iter 700/705/4882: loss 2.5780, time 61.43ms\n",
    "# iter 800/805/4882: loss 2.5864, time 265.56ms\n",
    "# iter 900/905/4882: loss 2.5857, time 263.09ms\n",
    "# step 1000: train loss 2.5849, val loss 2.5847\n",
    "# saving checkpoint to /Users/rodo/src/rgi3/models/connect4-e2e/v1\n",
    "# iter 1000/1005/4882: loss 2.5844, time 1812.58ms\n",
    "# iter 1100/1105/4882: loss 2.5832, time 62.89ms\n",
    "# iter 1200/1205/4882: loss 2.5743, time 95.25ms\n",
    "# iter 1300/1305/4882: loss 2.5720, time 324.18ms\n",
    "# iter 1400/1405/4882: loss 2.5880, time 73.66ms\n",
    "# iter 1500/1505/4882: loss 2.5745, time 295.39ms\n",
    "# iter 1600/1605/4882: loss 2.5726, time 76.05ms\n",
    "# iter 1700/1705/4882: loss 2.5670, time 63.20ms\n",
    "# iter 1800/1805/4882: loss 2.5720, time 62.66ms\n",
    "# iter 1900/1905/4882: loss 2.5694, time 449.06ms\n",
    "# step 2000: train loss 2.5806, val loss 2.5806\n",
    "# saving checkpoint to /Users/rodo/src/rgi3/models/connect4-e2e/v1\n",
    "# iter 2000/2005/4882: loss 2.5893, time 920.12ms\n",
    "# iter 2100/2105/4882: loss 2.5686, time 430.53ms\n",
    "# iter 2200/2205/4882: loss 2.5741, time 63.05ms\n",
    "# iter 2300/2305/4882: loss 2.5679, time 60.90ms\n",
    "# iter 2400/2405/4882: loss 2.5754, time 69.07ms\n",
    "# iter 2500/2505/4882: loss 2.5673, time 68.33ms\n",
    "# iter 2600/2605/4882: loss 2.5648, time 66.26ms\n",
    "# iter 2700/2705/4882: loss 2.5622, time 69.76ms\n",
    "# iter 2800/2805/4882: loss 2.5541, time 143.65ms\n",
    "# iter 2900/2905/4882: loss 2.5634, time 66.40ms\n",
    "# step 3000: train loss 2.5550, val loss 2.5547\n",
    "# saving checkpoint to /Users/rodo/src/rgi3/models/connect4-e2e/v1\n",
    "# iter 3000/3005/4882: loss 2.5545, time 975.15ms\n",
    "# iter 3100/3105/4882: loss 2.5594, time 63.55ms\n",
    "# iter 3200/3205/4882: loss 2.5499, time 64.17ms\n",
    "# iter 3300/3305/4882: loss 2.5481, time 70.28ms\n",
    "# iter 3400/3405/4882: loss 2.5565, time 73.58ms\n",
    "# iter 3500/3505/4882: loss 2.5602, time 72.22ms\n",
    "# iter 3600/3605/4882: loss 2.5429, time 88.68ms\n",
    "# iter 3700/3705/4882: loss 2.5259, time 63.15ms\n",
    "# iter 3800/3805/4882: loss 2.5346, time 66.07ms\n",
    "# iter 3900/3905/4882: loss 2.5386, time 73.50ms\n",
    "# step 4000: train loss 2.5350, val loss 2.5345\n",
    "# saving checkpoint to /Users/rodo/src/rgi3/models/connect4-e2e/v1\n",
    "# iter 4000/4005/4882: loss 2.5424, time 1217.41ms\n",
    "# iter 4100/4105/4882: loss 2.5290, time 101.01ms\n",
    "# iter 4200/4205/4882: loss 2.5323, time 61.94ms\n",
    "# iter 4300/4305/4882: loss 2.5250, time 72.57ms\n",
    "# iter 4400/4405/4882: loss 2.5243, time 68.38ms\n",
    "# iter 4500/4505/4882: loss 2.5331, time 73.33ms\n",
    "# iter 4600/4605/4882: loss 2.5246, time 101.00ms\n",
    "# iter 4700/4705/4882: loss 2.5336, time 67.27ms\n",
    "# iter 4800/4805/4882: loss 2.5170, time 79.40ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# Play single game\n",
    "result = await play_generation_async(current_model, num_games=1, simulations=NUM_SIMULATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect training data\n",
    "td_array = [TrajectoryDataset(DATA_DIR, f\"gen-{generation_id}\", block_size=n_max_context) for generation_id in range(1, NUM_GENERATIONS+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dd) = 112122\n"
     ]
    }
   ],
   "source": [
    "# [td for td in td_array]\n",
    "unrolled = [(generation+1, d) for generation, td in enumerate(td_array) for d in td]\n",
    "\n",
    "# gen, d = unrolled[0], \n",
    "# d.action[:2]\n",
    "# d.value[0]\n",
    "\n",
    "dd = defaultdict(lambda: defaultdict(lambda: torch.tensor([0., 0.])))\n",
    "\n",
    "for gen, d in unrolled:\n",
    "    for g in ['*', gen]:    \n",
    "        # dd[tuple(tuple(d.action[:0].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:1].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:2].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:3].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:4].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:5].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:6].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:7].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:8].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:9].tolist()))][g] += d.value[0]\n",
    "        dd[tuple(tuple(d.action[:10].tolist()))][g] += d.value[0]\n",
    "\n",
    "print(f\"len(dd) = {len(dd)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prefix(model, game, prefix):\n",
    "    serial_evaluator = ActionHistoryTransformerEvaluator(model, device=device, block_size=block_size, vocab=action_vocab)\n",
    "    state = game.initial_state()\n",
    "    for action in prefix:\n",
    "        state = game.next_state(state, action)\n",
    "    legal_actions = game.legal_actions(state)\n",
    "    result = serial_evaluator.evaluate(game, state, legal_actions)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,),\n",
       " (0, 1),\n",
       " (0, 1, 4),\n",
       " (0, 2),\n",
       " (0, 2, 1),\n",
       " (0, 2, 1, 3),\n",
       " (0, 2, 1, 3, 5),\n",
       " (0, 2, 3),\n",
       " (0, 2, 3, 2),\n",
       " (0, 2, 3, 6),\n",
       " (0, 2, 3, 6, 3),\n",
       " (0, 2, 3, 6, 3, 1),\n",
       " (0, 2, 3, 6, 3, 1, 7),\n",
       " (0, 2, 3, 6, 3, 1, 7, 4),\n",
       " (0, 2, 4),\n",
       " (0, 3),\n",
       " (0, 3, 4),\n",
       " (0, 3, 4, 4),\n",
       " (0, 4),\n",
       " (0, 4, 1),\n",
       " (0, 4, 3),\n",
       " (0, 4, 4),\n",
       " (0, 4, 4, 2),\n",
       " (0, 4, 4, 2, 3),\n",
       " (0, 4, 4, 2, 4),\n",
       " (0, 4, 4, 3),\n",
       " (0, 4, 4, 3, 2),\n",
       " (0, 4, 4, 3, 2, 3),\n",
       " (0, 4, 4, 3, 2, 4),\n",
       " (0, 4, 4, 3, 5),\n",
       " (0, 4, 4, 4),\n",
       " (0, 4, 4, 4, 3),\n",
       " (0, 4, 4, 4, 4),\n",
       " (0, 4, 4, 4, 4, 7),\n",
       " (0, 4, 4, 4, 4, 7, 1),\n",
       " (0, 4, 4, 4, 4, 7, 1, 6),\n",
       " (0, 4, 4, 5),\n",
       " (0, 4, 4, 5, 3),\n",
       " (0, 4, 4, 5, 3, 3),\n",
       " (0, 4, 4, 5, 3, 3, 5),\n",
       " (0, 4, 4, 5, 3, 3, 5, 5),\n",
       " (0, 4, 4, 5, 3, 3, 5, 5, 6),\n",
       " (0, 4, 5),\n",
       " (0, 5),\n",
       " (0, 5, 4),\n",
       " (0, 5, 4, 4),\n",
       " (0, 6),\n",
       " (0, 6, 4),\n",
       " (0, 7),\n",
       " (0, 7, 4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dd.items())[10][1]['*'].sum() > 100\n",
    "top_k = sorted(dd.items(), key=lambda kv: kv[1]['*'].sum(), reverse=True)[:50]\n",
    "top_k_keys = sorted(k for k, v in top_k)\n",
    "top_k_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prefix=(0,)\n",
      "gen=*: tensor([26450., 23550.]), win_pct=52.90%, sum=50000.0\n",
      "gen=1: tensor([6193.5000, 3806.5000]), win_pct=61.94%, sum=10000.0\n",
      "gen=2: tensor([4645., 5355.]), win_pct=46.45%, sum=10000.0\n",
      "gen=3: tensor([5202.5000, 4797.5000]), win_pct=52.03%, sum=10000.0\n",
      "gen=4: tensor([4570., 5430.]), win_pct=45.70%, sum=10000.0\n",
      "gen=5: tensor([5839., 4161.]), win_pct=58.39%, sum=10000.0\n",
      "player_probs=[0.83071816 0.16928178]\n",
      "\n",
      "prefix=(0, 1)\n",
      "gen=*: tensor([1400., 1792.]), win_pct=43.86%, sum=3192.0\n",
      "gen=1: tensor([812., 752.]), win_pct=51.92%, sum=1564.0\n",
      "gen=2: tensor([319., 614.]), win_pct=34.19%, sum=933.0\n",
      "gen=3: tensor([41., 53.]), win_pct=43.62%, sum=94.0\n",
      "gen=4: tensor([54., 85.]), win_pct=38.85%, sum=139.0\n",
      "gen=5: tensor([174., 288.]), win_pct=37.66%, sum=462.0\n",
      "player_probs=[0.64732057 0.35267943]\n",
      "\n",
      "prefix=(0, 1, 4)\n",
      "gen=*: tensor([385., 883.]), win_pct=30.36%, sum=1268.0\n",
      "gen=1: tensor([ 84., 150.]), win_pct=35.90%, sum=234.0\n",
      "gen=2: tensor([ 80., 355.]), win_pct=18.39%, sum=435.0\n",
      "gen=3: tensor([25., 38.]), win_pct=39.68%, sum=63.0\n",
      "gen=4: tensor([48., 81.]), win_pct=37.21%, sum=129.0\n",
      "gen=5: tensor([148., 259.]), win_pct=36.36%, sum=407.0\n",
      "player_probs=[0.42748323 0.5725168 ]\n",
      "\n",
      "prefix=(0, 2)\n",
      "gen=*: tensor([4801., 5671.]), win_pct=45.85%, sum=10472.0\n",
      "gen=1: tensor([771., 573.]), win_pct=57.37%, sum=1344.0\n",
      "gen=2: tensor([ 66., 262.]), win_pct=20.12%, sum=328.0\n",
      "gen=3: tensor([35., 74.]), win_pct=32.11%, sum=109.0\n",
      "gen=4: tensor([3380., 4306.]), win_pct=43.98%, sum=7686.0\n",
      "gen=5: tensor([549., 456.]), win_pct=54.63%, sum=1005.0\n",
      "player_probs=[0.5747395  0.42526045]\n",
      "\n",
      "prefix=(0, 2, 1)\n",
      "gen=*: tensor([1175.,  538.]), win_pct=68.59%, sum=1713.0\n",
      "gen=1: tensor([125.,  60.]), win_pct=67.57%, sum=185.0\n",
      "gen=2: tensor([3., 1.]), win_pct=75.00%, sum=4.0\n",
      "gen=4: tensor([1033.,  474.]), win_pct=68.55%, sum=1507.0\n",
      "gen=5: tensor([14.,  3.]), win_pct=82.35%, sum=17.0\n",
      "player_probs=[0.79529583 0.20470414]\n",
      "\n",
      "prefix=(0, 2, 1, 3)\n",
      "gen=*: tensor([965., 449.]), win_pct=68.25%, sum=1414.0\n",
      "gen=1: tensor([19.,  8.]), win_pct=70.37%, sum=27.0\n",
      "gen=4: tensor([946., 441.]), win_pct=68.20%, sum=1387.0\n",
      "player_probs=[0.85688895 0.14311105]\n",
      "\n",
      "prefix=(0, 2, 1, 3, 5)\n",
      "gen=*: tensor([441., 306.]), win_pct=59.04%, sum=747.0\n",
      "gen=1: tensor([1., 2.]), win_pct=33.33%, sum=3.0\n",
      "gen=4: tensor([440., 304.]), win_pct=59.14%, sum=744.0\n",
      "player_probs=[0.43978012 0.5602199 ]\n",
      "\n",
      "prefix=(0, 2, 3)\n",
      "gen=*: tensor([2574., 4171.]), win_pct=38.16%, sum=6745.0\n",
      "gen=1: tensor([75., 90.]), win_pct=45.45%, sum=165.0\n",
      "gen=2: tensor([ 6., 30.]), win_pct=16.67%, sum=36.0\n",
      "gen=3: tensor([2., 1.]), win_pct=66.67%, sum=3.0\n",
      "gen=4: tensor([2022., 3652.]), win_pct=35.64%, sum=5674.0\n",
      "gen=5: tensor([469., 398.]), win_pct=54.09%, sum=867.0\n",
      "player_probs=[0.58693594 0.41306406]\n",
      "\n",
      "prefix=(0, 2, 3, 2)\n",
      "gen=*: tensor([647., 204.]), win_pct=76.03%, sum=851.0\n",
      "gen=1: tensor([8., 5.]), win_pct=61.54%, sum=13.0\n",
      "gen=2: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=3: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=4: tensor([603., 175.]), win_pct=77.51%, sum=778.0\n",
      "gen=5: tensor([34., 24.]), win_pct=58.62%, sum=58.0\n",
      "player_probs=[0.71330607 0.2866939 ]\n",
      "\n",
      "prefix=(0, 2, 3, 6)\n",
      "gen=*: tensor([1528., 3117.]), win_pct=32.90%, sum=4645.0\n",
      "gen=1: tensor([15., 12.]), win_pct=55.56%, sum=27.0\n",
      "gen=2: tensor([0., 2.]), win_pct=0.00%, sum=2.0\n",
      "gen=4: tensor([1245., 2912.]), win_pct=29.95%, sum=4157.0\n",
      "gen=5: tensor([268., 191.]), win_pct=58.39%, sum=459.0\n",
      "player_probs=[0.5762082  0.42379186]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3)\n",
      "gen=*: tensor([ 714., 2412.]), win_pct=22.84%, sum=3126.0\n",
      "gen=1: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=2: tensor([0., 1.]), win_pct=0.00%, sum=1.0\n",
      "gen=4: tensor([ 705., 2400.]), win_pct=22.71%, sum=3105.0\n",
      "gen=5: tensor([ 8., 11.]), win_pct=42.11%, sum=19.0\n",
      "player_probs=[0.3225519 0.6774481]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1)\n",
      "gen=*: tensor([ 508., 2192.]), win_pct=18.81%, sum=2700.0\n",
      "gen=4: tensor([ 507., 2192.]), win_pct=18.78%, sum=2699.0\n",
      "gen=5: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "player_probs=[0.42336556 0.57663447]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1, 7)\n",
      "gen=*: tensor([ 335., 1977.]), win_pct=14.49%, sum=2312.0\n",
      "gen=4: tensor([ 334., 1977.]), win_pct=14.45%, sum=2311.0\n",
      "gen=5: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "player_probs=[0.39244738 0.60755265]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1, 7, 4)\n",
      "gen=*: tensor([ 202., 1504.]), win_pct=11.84%, sum=1706.0\n",
      "gen=4: tensor([ 202., 1504.]), win_pct=11.84%, sum=1706.0\n",
      "player_probs=[0.04466331 0.9553367 ]\n",
      "\n",
      "prefix=(0, 2, 4)\n",
      "gen=*: tensor([230., 537.]), win_pct=29.99%, sum=767.0\n",
      "gen=1: tensor([ 80., 145.]), win_pct=35.56%, sum=225.0\n",
      "gen=2: tensor([ 52., 224.]), win_pct=18.84%, sum=276.0\n",
      "gen=3: tensor([33., 73.]), win_pct=31.13%, sum=106.0\n",
      "gen=4: tensor([29., 56.]), win_pct=34.12%, sum=85.0\n",
      "gen=5: tensor([36., 39.]), win_pct=48.00%, sum=75.0\n",
      "player_probs=[0.89921165 0.10078835]\n",
      "\n",
      "prefix=(0, 3)\n",
      "gen=*: tensor([2462., 2433.]), win_pct=50.30%, sum=4895.0\n",
      "gen=1: tensor([846., 451.]), win_pct=65.23%, sum=1297.0\n",
      "gen=2: tensor([723., 924.]), win_pct=43.90%, sum=1647.0\n",
      "gen=3: tensor([23., 80.]), win_pct=22.33%, sum=103.0\n",
      "gen=4: tensor([149., 200.]), win_pct=42.69%, sum=349.0\n",
      "gen=5: tensor([721., 778.]), win_pct=48.10%, sum=1499.0\n",
      "player_probs=[0.9008348 0.0991652]\n",
      "\n",
      "prefix=(0, 3, 4)\n",
      "gen=*: tensor([1348., 1917.]), win_pct=41.29%, sum=3265.0\n",
      "gen=1: tensor([ 99., 103.]), win_pct=49.01%, sum=202.0\n",
      "gen=2: tensor([458., 821.]), win_pct=35.81%, sum=1279.0\n",
      "gen=3: tensor([19., 79.]), win_pct=19.39%, sum=98.0\n",
      "gen=4: tensor([116., 168.]), win_pct=40.85%, sum=284.0\n",
      "gen=5: tensor([656., 746.]), win_pct=46.79%, sum=1402.0\n",
      "player_probs=[0.62409097 0.37590906]\n",
      "\n",
      "prefix=(0, 3, 4, 4)\n",
      "gen=*: tensor([779., 807.]), win_pct=49.12%, sum=1586.0\n",
      "gen=1: tensor([14., 11.]), win_pct=56.00%, sum=25.0\n",
      "gen=2: tensor([319., 516.]), win_pct=38.20%, sum=835.0\n",
      "gen=3: tensor([ 4., 19.]), win_pct=17.39%, sum=23.0\n",
      "gen=4: tensor([ 91., 136.]), win_pct=40.09%, sum=227.0\n",
      "gen=5: tensor([351., 125.]), win_pct=73.74%, sum=476.0\n",
      "player_probs=[0.53947014 0.46052986]\n",
      "\n",
      "prefix=(0, 4)\n",
      "gen=*: tensor([12812.,  8544.]), win_pct=59.99%, sum=21356.0\n",
      "gen=1: tensor([1140.,  353.]), win_pct=76.36%, sum=1493.0\n",
      "gen=2: tensor([2451., 1809.]), win_pct=57.54%, sum=4260.0\n",
      "gen=3: tensor([4922., 4296.]), win_pct=53.40%, sum=9218.0\n",
      "gen=4: tensor([565., 317.]), win_pct=64.06%, sum=882.0\n",
      "gen=5: tensor([3734., 1769.]), win_pct=67.85%, sum=5503.0\n",
      "player_probs=[0.8199825  0.18001753]\n",
      "\n",
      "prefix=(0, 4, 1)\n",
      "gen=*: tensor([930., 311.]), win_pct=74.94%, sum=1241.0\n",
      "gen=1: tensor([183.,  44.]), win_pct=80.62%, sum=227.0\n",
      "gen=2: tensor([41.,  8.]), win_pct=83.67%, sum=49.0\n",
      "gen=3: tensor([129.,  23.]), win_pct=84.87%, sum=152.0\n",
      "gen=4: tensor([304., 210.]), win_pct=59.14%, sum=514.0\n",
      "gen=5: tensor([273.,  26.]), win_pct=91.30%, sum=299.0\n",
      "player_probs=[0.83469874 0.16530126]\n",
      "\n",
      "prefix=(0, 4, 3)\n",
      "gen=*: tensor([529., 223.]), win_pct=70.35%, sum=752.0\n",
      "gen=1: tensor([140.,  58.]), win_pct=70.71%, sum=198.0\n",
      "gen=2: tensor([75., 40.]), win_pct=65.22%, sum=115.0\n",
      "gen=3: tensor([67., 75.]), win_pct=47.18%, sum=142.0\n",
      "gen=4: tensor([33.,  7.]), win_pct=82.50%, sum=40.0\n",
      "gen=5: tensor([214.,  43.]), win_pct=83.27%, sum=257.0\n",
      "player_probs=[0.84855497 0.15144506]\n",
      "\n",
      "prefix=(0, 4, 4)\n",
      "gen=*: tensor([9689., 7366.]), win_pct=56.81%, sum=17055.0\n",
      "gen=1: tensor([181.,  55.]), win_pct=76.69%, sum=236.0\n",
      "gen=2: tensor([2176., 1663.]), win_pct=56.68%, sum=3839.0\n",
      "gen=3: tensor([4374., 4039.]), win_pct=51.99%, sum=8413.0\n",
      "gen=4: tensor([33., 18.]), win_pct=64.71%, sum=51.0\n",
      "gen=5: tensor([2925., 1591.]), win_pct=64.77%, sum=4516.0\n",
      "player_probs=[0.49436808 0.5056319 ]\n",
      "\n",
      "prefix=(0, 4, 4, 2)\n",
      "gen=*: tensor([1110.,  587.]), win_pct=65.41%, sum=1697.0\n",
      "gen=1: tensor([14.,  8.]), win_pct=63.64%, sum=22.0\n",
      "gen=2: tensor([175., 219.]), win_pct=44.42%, sum=394.0\n",
      "gen=3: tensor([836., 289.]), win_pct=74.31%, sum=1125.0\n",
      "gen=4: tensor([1., 3.]), win_pct=25.00%, sum=4.0\n",
      "gen=5: tensor([84., 68.]), win_pct=55.26%, sum=152.0\n",
      "player_probs=[0.34724352 0.6527565 ]\n",
      "\n",
      "prefix=(0, 4, 4, 2, 3)\n",
      "gen=*: tensor([377., 426.]), win_pct=46.95%, sum=803.0\n",
      "gen=1: tensor([2., 2.]), win_pct=50.00%, sum=4.0\n",
      "gen=2: tensor([120., 191.]), win_pct=38.59%, sum=311.0\n",
      "gen=3: tensor([189., 163.]), win_pct=53.69%, sum=352.0\n",
      "gen=4: tensor([1., 3.]), win_pct=25.00%, sum=4.0\n",
      "gen=5: tensor([65., 67.]), win_pct=49.24%, sum=132.0\n",
      "player_probs=[0.44259375 0.55740625]\n",
      "\n",
      "prefix=(0, 4, 4, 2, 4)\n",
      "gen=*: tensor([634., 127.]), win_pct=83.31%, sum=761.0\n",
      "gen=1: tensor([2., 2.]), win_pct=50.00%, sum=4.0\n",
      "gen=2: tensor([13., 11.]), win_pct=54.17%, sum=24.0\n",
      "gen=3: tensor([612., 114.]), win_pct=84.30%, sum=726.0\n",
      "gen=5: tensor([7., 0.]), win_pct=100.00%, sum=7.0\n",
      "player_probs=[0.77680856 0.22319138]\n",
      "\n",
      "prefix=(0, 4, 4, 3)\n",
      "gen=*: tensor([3175., 1406.]), win_pct=69.31%, sum=4581.0\n",
      "gen=1: tensor([36.,  3.]), win_pct=92.31%, sum=39.0\n",
      "gen=2: tensor([438., 159.]), win_pct=73.37%, sum=597.0\n",
      "gen=3: tensor([725., 351.]), win_pct=67.38%, sum=1076.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([1974.,  893.]), win_pct=68.85%, sum=2867.0\n",
      "player_probs=[0.8227795 0.1772205]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2)\n",
      "gen=*: tensor([1843., 1014.]), win_pct=64.51%, sum=2857.0\n",
      "gen=1: tensor([7., 1.]), win_pct=87.50%, sum=8.0\n",
      "gen=2: tensor([19., 21.]), win_pct=47.50%, sum=40.0\n",
      "gen=3: tensor([673., 342.]), win_pct=66.31%, sum=1015.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([1142.,  650.]), win_pct=63.73%, sum=1792.0\n",
      "player_probs=[0.6490538  0.35094616]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2, 3)\n",
      "gen=*: tensor([661., 361.]), win_pct=64.68%, sum=1022.0\n",
      "gen=1: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=2: tensor([1., 1.]), win_pct=50.00%, sum=2.0\n",
      "gen=3: tensor([50., 37.]), win_pct=57.47%, sum=87.0\n",
      "gen=5: tensor([608., 323.]), win_pct=65.31%, sum=931.0\n",
      "player_probs=[0.59456956 0.40543047]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2, 4)\n",
      "gen=*: tensor([514., 458.]), win_pct=52.88%, sum=972.0\n",
      "gen=1: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=2: tensor([ 7., 10.]), win_pct=41.18%, sum=17.0\n",
      "gen=3: tensor([ 85., 156.]), win_pct=35.27%, sum=241.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([419., 292.]), win_pct=58.93%, sum=711.0\n",
      "player_probs=[0.4673532 0.5326468]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 5)\n",
      "gen=*: tensor([539., 240.]), win_pct=69.19%, sum=779.0\n",
      "gen=1: tensor([3., 0.]), win_pct=100.00%, sum=3.0\n",
      "gen=2: tensor([26., 18.]), win_pct=59.09%, sum=44.0\n",
      "gen=3: tensor([5., 5.]), win_pct=50.00%, sum=10.0\n",
      "gen=5: tensor([505., 217.]), win_pct=69.94%, sum=722.0\n",
      "player_probs=[0.73831195 0.26168808]\n",
      "\n",
      "prefix=(0, 4, 4, 4)\n",
      "gen=*: tensor([2009., 1557.]), win_pct=56.34%, sum=3566.0\n",
      "gen=1: tensor([30., 12.]), win_pct=71.43%, sum=42.0\n",
      "gen=2: tensor([728., 660.]), win_pct=52.45%, sum=1388.0\n",
      "gen=3: tensor([780., 636.]), win_pct=55.08%, sum=1416.0\n",
      "gen=4: tensor([29., 14.]), win_pct=67.44%, sum=43.0\n",
      "gen=5: tensor([442., 235.]), win_pct=65.29%, sum=677.0\n",
      "player_probs=[0.69787216 0.3021279 ]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 3)\n",
      "gen=*: tensor([839., 735.]), win_pct=53.30%, sum=1574.0\n",
      "gen=1: tensor([5., 1.]), win_pct=83.33%, sum=6.0\n",
      "gen=2: tensor([497., 533.]), win_pct=48.25%, sum=1030.0\n",
      "gen=3: tensor([19., 17.]), win_pct=52.78%, sum=36.0\n",
      "gen=4: tensor([23., 11.]), win_pct=67.65%, sum=34.0\n",
      "gen=5: tensor([295., 173.]), win_pct=63.03%, sum=468.0\n",
      "player_probs=[0.49971813 0.5002819 ]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4)\n",
      "gen=*: tensor([755., 639.]), win_pct=54.16%, sum=1394.0\n",
      "gen=1: tensor([4., 2.]), win_pct=66.67%, sum=6.0\n",
      "gen=2: tensor([9., 7.]), win_pct=56.25%, sum=16.0\n",
      "gen=3: tensor([666., 603.]), win_pct=52.48%, sum=1269.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([74., 27.]), win_pct=73.27%, sum=101.0\n",
      "player_probs=[0.67416346 0.32583654]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7)\n",
      "gen=*: tensor([460., 545.]), win_pct=45.77%, sum=1005.0\n",
      "gen=1: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=2: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=3: tensor([455., 544.]), win_pct=45.55%, sum=999.0\n",
      "gen=5: tensor([2., 1.]), win_pct=66.67%, sum=3.0\n",
      "player_probs=[0.71230745 0.2876925 ]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7, 1)\n",
      "gen=*: tensor([374., 512.]), win_pct=42.21%, sum=886.0\n",
      "gen=3: tensor([374., 512.]), win_pct=42.21%, sum=886.0\n",
      "player_probs=[0.7503351 0.2496649]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7, 1, 6)\n",
      "gen=*: tensor([280., 467.]), win_pct=37.48%, sum=747.0\n",
      "gen=3: tensor([280., 467.]), win_pct=37.48%, sum=747.0\n",
      "player_probs=[0.8865372  0.11346281]\n",
      "\n",
      "prefix=(0, 4, 4, 5)\n",
      "gen=*: tensor([2454., 3073.]), win_pct=44.40%, sum=5527.0\n",
      "gen=1: tensor([22.,  5.]), win_pct=81.48%, sum=27.0\n",
      "gen=2: tensor([255., 182.]), win_pct=58.35%, sum=437.0\n",
      "gen=3: tensor([1793., 2519.]), win_pct=41.58%, sum=4312.0\n",
      "gen=5: tensor([384., 367.]), win_pct=51.13%, sum=751.0\n",
      "player_probs=[0.8073806  0.19261938]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3)\n",
      "gen=*: tensor([1919., 2892.]), win_pct=39.89%, sum=4811.0\n",
      "gen=1: tensor([1., 1.]), win_pct=50.00%, sum=2.0\n",
      "gen=2: tensor([176., 150.]), win_pct=53.99%, sum=326.0\n",
      "gen=3: tensor([1505., 2401.]), win_pct=38.53%, sum=3906.0\n",
      "gen=5: tensor([237., 340.]), win_pct=41.07%, sum=577.0\n",
      "player_probs=[0.71696025 0.28303972]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3)\n",
      "gen=*: tensor([1183., 2101.]), win_pct=36.02%, sum=3284.0\n",
      "gen=2: tensor([15.,  4.]), win_pct=78.95%, sum=19.0\n",
      "gen=3: tensor([1143., 2004.]), win_pct=36.32%, sum=3147.0\n",
      "gen=5: tensor([25., 93.]), win_pct=21.19%, sum=118.0\n",
      "player_probs=[0.72245646 0.27754354]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5)\n",
      "gen=*: tensor([1058., 1883.]), win_pct=35.97%, sum=2941.0\n",
      "gen=2: tensor([11.,  2.]), win_pct=84.62%, sum=13.0\n",
      "gen=3: tensor([1047., 1881.]), win_pct=35.76%, sum=2928.0\n",
      "player_probs=[0.75344205 0.24655798]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5, 5)\n",
      "gen=*: tensor([368., 429.]), win_pct=46.17%, sum=797.0\n",
      "gen=2: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=3: tensor([366., 429.]), win_pct=46.04%, sum=795.0\n",
      "player_probs=[0.79587406 0.20412594]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5, 5, 6)\n",
      "gen=*: tensor([320., 401.]), win_pct=44.38%, sum=721.0\n",
      "gen=3: tensor([320., 401.]), win_pct=44.38%, sum=721.0\n",
      "player_probs=[0.7708943  0.22910574]\n",
      "\n",
      "prefix=(0, 4, 5)\n",
      "gen=*: tensor([501., 260.]), win_pct=65.83%, sum=761.0\n",
      "gen=1: tensor([165.,  66.]), win_pct=71.43%, sum=231.0\n",
      "gen=2: tensor([50., 41.]), win_pct=54.95%, sum=91.0\n",
      "gen=3: tensor([82., 54.]), win_pct=60.29%, sum=136.0\n",
      "gen=4: tensor([42., 26.]), win_pct=61.76%, sum=68.0\n",
      "gen=5: tensor([162.,  73.]), win_pct=68.94%, sum=235.0\n",
      "player_probs=[0.5145642  0.48543578]\n",
      "\n",
      "prefix=(0, 5)\n",
      "gen=*: tensor([2250.5000, 2097.5000]), win_pct=51.76%, sum=4348.0\n",
      "gen=1: tensor([1014.,  511.]), win_pct=66.49%, sum=1525.0\n",
      "gen=2: tensor([629., 879.]), win_pct=41.71%, sum=1508.0\n",
      "gen=3: tensor([66.5000, 65.5000]), win_pct=50.38%, sum=132.0\n",
      "gen=4: tensor([184., 135.]), win_pct=57.68%, sum=319.0\n",
      "gen=5: tensor([357., 507.]), win_pct=41.32%, sum=864.0\n",
      "player_probs=[0.86825055 0.13174945]\n",
      "\n",
      "prefix=(0, 5, 4)\n",
      "gen=*: tensor([1072.5000, 1581.5000]), win_pct=40.41%, sum=2654.0\n",
      "gen=1: tensor([102., 113.]), win_pct=47.44%, sum=215.0\n",
      "gen=2: tensor([450., 802.]), win_pct=35.94%, sum=1252.0\n",
      "gen=3: tensor([62.5000, 64.5000]), win_pct=49.21%, sum=127.0\n",
      "gen=4: tensor([124., 116.]), win_pct=51.67%, sum=240.0\n",
      "gen=5: tensor([334., 486.]), win_pct=40.73%, sum=820.0\n",
      "player_probs=[0.5583842  0.44161585]\n",
      "\n",
      "prefix=(0, 5, 4, 4)\n",
      "gen=*: tensor([631., 929.]), win_pct=40.45%, sum=1560.0\n",
      "gen=1: tensor([16., 12.]), win_pct=57.14%, sum=28.0\n",
      "gen=2: tensor([347., 560.]), win_pct=38.26%, sum=907.0\n",
      "gen=3: tensor([3., 4.]), win_pct=42.86%, sum=7.0\n",
      "gen=4: tensor([3., 6.]), win_pct=33.33%, sum=9.0\n",
      "gen=5: tensor([262., 347.]), win_pct=43.02%, sum=609.0\n",
      "player_probs=[0.43096867 0.5690313 ]\n",
      "\n",
      "prefix=(0, 6)\n",
      "gen=*: tensor([1168.,  996.]), win_pct=53.97%, sum=2164.0\n",
      "gen=1: tensor([869., 532.]), win_pct=62.03%, sum=1401.0\n",
      "gen=2: tensor([ 86., 244.]), win_pct=26.06%, sum=330.0\n",
      "gen=3: tensor([51., 97.]), win_pct=34.46%, sum=148.0\n",
      "gen=4: tensor([37., 57.]), win_pct=39.36%, sum=94.0\n",
      "gen=5: tensor([125.,  66.]), win_pct=65.45%, sum=191.0\n",
      "player_probs=[0.4180837  0.58191633]\n",
      "\n",
      "prefix=(0, 6, 4)\n",
      "gen=*: tensor([321., 516.]), win_pct=38.35%, sum=837.0\n",
      "gen=1: tensor([ 94., 117.]), win_pct=44.55%, sum=211.0\n",
      "gen=2: tensor([ 69., 225.]), win_pct=23.47%, sum=294.0\n",
      "gen=3: tensor([45., 89.]), win_pct=33.58%, sum=134.0\n",
      "gen=4: tensor([24., 46.]), win_pct=34.29%, sum=70.0\n",
      "gen=5: tensor([89., 39.]), win_pct=69.53%, sum=128.0\n",
      "player_probs=[0.29842877 0.7015712 ]\n",
      "\n",
      "prefix=(0, 7)\n",
      "gen=*: tensor([1556.5000, 2016.5000]), win_pct=43.56%, sum=3573.0\n",
      "gen=1: tensor([741.5000, 634.5000]), win_pct=53.89%, sum=1376.0\n",
      "gen=2: tensor([371., 623.]), win_pct=37.32%, sum=994.0\n",
      "gen=3: tensor([ 64., 132.]), win_pct=32.65%, sum=196.0\n",
      "gen=4: tensor([201., 330.]), win_pct=37.85%, sum=531.0\n",
      "gen=5: tensor([179., 297.]), win_pct=37.61%, sum=476.0\n",
      "player_probs=[0.6321651  0.36783493]\n",
      "\n",
      "prefix=(0, 7, 4)\n",
      "gen=*: tensor([ 490., 1099.]), win_pct=30.84%, sum=1589.0\n",
      "gen=1: tensor([ 79., 123.]), win_pct=39.11%, sum=202.0\n",
      "gen=2: tensor([ 95., 295.]), win_pct=24.36%, sum=390.0\n",
      "gen=3: tensor([ 55., 130.]), win_pct=29.73%, sum=185.0\n",
      "gen=4: tensor([124., 301.]), win_pct=29.18%, sum=425.0\n",
      "gen=5: tensor([137., 250.]), win_pct=35.40%, sum=387.0\n",
      "player_probs=[0.5699707  0.43002924]\n"
     ]
    }
   ],
   "source": [
    "## Someting is borked? Player1 win percent should be much higher??\n",
    "def compare_model_vs_data(model, game, dd):\n",
    "    # prefix_list = [\n",
    "    #     (0,), \n",
    "    #     (0,1), (0,2), (0,3), (0,4), (0,5), (0,6), (0,7),\n",
    "    #     (0,1,1), (0,1,2), (0,1,3), (0,1,4), (0,1,5), (0,1,6), (0,1,7),\n",
    "    #     (0,4,1), (0,4,2), (0,4,3), (0,4,4), (0,4,5), (0,4,6), (0,4,7)]\n",
    "    # prefix_list = [k for k in dd.items()]\n",
    "    \n",
    "    list(dd.items())[10][1]['*'].sum() > 100\n",
    "    top_k = sorted(dd.items(), key=lambda kv: kv[1]['*'].sum(), reverse=True)[:50]\n",
    "    top_k_keys = sorted(k for k, v in top_k)\n",
    "    \n",
    "    prefix_list = top_k_keys\n",
    "\n",
    "    for prefix in prefix_list:\n",
    "        print(f\"\\nprefix={prefix}\")\n",
    "        for gen, counts in dd[prefix].items():\n",
    "            print(f\"gen={gen}: {counts}, win_pct={100*counts[0]/sum(counts):.2f}%, sum={sum(counts)}\")\n",
    "        assert prefix[0] == 0\n",
    "        actions = prefix[1:]\n",
    "        eval_result = eval_prefix(model, game, actions)\n",
    "        # print(f'legal_policy={eval_result.legal_policy}')\n",
    "        # print(f'player_values={eval_result.player_values}')\n",
    "        print(f'player_probs={(eval_result.player_values+1)/2}')\n",
    "\n",
    "compare_model_vs_data(current_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model\n",
    "model_0 = create_random_model(model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42)\n",
    "if RUN_GENERATIONS:\n",
    "    model_1 = load_model(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Model 0\n",
      "Parameter containing:\n",
      "tensor([[-0.0504,  0.0093, -0.0226,  0.0165,  0.0072, -0.0277,  0.0177, -0.0237,\n",
      "          0.0188, -0.0143,  0.0269, -0.0013, -0.0198,  0.0144, -0.0243,  0.0237,\n",
      "         -0.0140,  0.0181,  0.0318, -0.0157,  0.0148, -0.0034, -0.0324,  0.0208,\n",
      "         -0.0291, -0.0305,  0.0342, -0.0172,  0.0260, -0.0208, -0.0124,  0.0096],\n",
      "        [-0.0126,  0.0072,  0.0104, -0.0769, -0.0078, -0.0041, -0.0216,  0.0517,\n",
      "          0.0385, -0.0091, -0.0166,  0.0048,  0.0219, -0.0037, -0.0307,  0.0049,\n",
      "         -0.0108,  0.0062,  0.0002, -0.0093, -0.0116, -0.0281, -0.0046, -0.0189,\n",
      "         -0.0464, -0.0034, -0.0101, -0.0152, -0.0383,  0.0229, -0.0058, -0.0105],\n",
      "        [-0.0208, -0.0252,  0.0038, -0.0199, -0.0087, -0.0136, -0.0072,  0.0004,\n",
      "         -0.0083,  0.0022, -0.0049,  0.0290,  0.0091, -0.0186, -0.0067,  0.0133,\n",
      "         -0.0194, -0.0004,  0.0097,  0.0346, -0.0028, -0.0301,  0.0015,  0.0175,\n",
      "         -0.0117,  0.0087,  0.0185, -0.0033,  0.0177,  0.0148,  0.0138,  0.0008],\n",
      "        [ 0.0108,  0.0246,  0.0061,  0.0229,  0.0009, -0.0005, -0.0093,  0.0311,\n",
      "          0.0120,  0.0404, -0.0377, -0.0150,  0.0187, -0.0209,  0.0130, -0.0071,\n",
      "         -0.0059, -0.0070,  0.0242,  0.0173,  0.0340,  0.0052, -0.0227,  0.0163,\n",
      "          0.0290, -0.0299,  0.0063,  0.0577, -0.0285,  0.0299, -0.0042,  0.0182],\n",
      "        [ 0.0079,  0.0110,  0.0027, -0.0343, -0.0018, -0.0030,  0.0095, -0.0341,\n",
      "         -0.0042, -0.0264,  0.0266,  0.0052,  0.0007, -0.0033, -0.0015, -0.0278,\n",
      "          0.0115, -0.0010,  0.0064, -0.0044, -0.0115,  0.0057, -0.0438, -0.0170,\n",
      "          0.0007,  0.0555, -0.0064, -0.0045,  0.0276, -0.0094, -0.0307, -0.0514],\n",
      "        [-0.0523, -0.0152, -0.0220,  0.0133, -0.0118,  0.0202,  0.0215, -0.0226,\n",
      "         -0.0149, -0.0153, -0.0252, -0.0042, -0.0080,  0.0028, -0.0132, -0.0119,\n",
      "         -0.0156, -0.0223,  0.0076,  0.0080, -0.0226, -0.0042, -0.0134, -0.0196,\n",
      "         -0.0076,  0.0077, -0.0115,  0.0192, -0.0142, -0.0291, -0.0335, -0.0355],\n",
      "        [ 0.0327, -0.0035, -0.0089, -0.0022,  0.0108, -0.0225,  0.0273,  0.0042,\n",
      "          0.0252, -0.0067,  0.0078, -0.0050, -0.0320,  0.0053, -0.0220,  0.0217,\n",
      "         -0.0161, -0.0067,  0.0006, -0.0307, -0.0253, -0.0320, -0.0005,  0.0118,\n",
      "          0.0088, -0.0154, -0.0236,  0.0061, -0.0021, -0.0011, -0.0321,  0.0027],\n",
      "        [-0.0200,  0.0198,  0.0210, -0.0304, -0.0015, -0.0245,  0.0166,  0.0256,\n",
      "         -0.0027,  0.0169, -0.0032, -0.0262,  0.0021,  0.0221,  0.0110, -0.0057,\n",
      "          0.0008, -0.0422,  0.0184, -0.0111,  0.0309,  0.0086, -0.0171,  0.0331,\n",
      "         -0.0144, -0.0149,  0.0199, -0.0022,  0.0037, -0.0067, -0.0106, -0.0266]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "\n",
      "prefix=(0,)\n",
      "gen=*: tensor([26450., 23550.]), win_pct=52.90%, sum=50000.0\n",
      "gen=1: tensor([6193.5000, 3806.5000]), win_pct=61.94%, sum=10000.0\n",
      "gen=2: tensor([4645., 5355.]), win_pct=46.45%, sum=10000.0\n",
      "gen=3: tensor([5202.5000, 4797.5000]), win_pct=52.03%, sum=10000.0\n",
      "gen=4: tensor([4570., 5430.]), win_pct=45.70%, sum=10000.0\n",
      "gen=5: tensor([5839., 4161.]), win_pct=58.39%, sum=10000.0\n",
      "player_probs=[0.55144787 0.4485522 ]\n",
      "\n",
      "prefix=(0, 1)\n",
      "gen=*: tensor([1400., 1792.]), win_pct=43.86%, sum=3192.0\n",
      "gen=1: tensor([812., 752.]), win_pct=51.92%, sum=1564.0\n",
      "gen=2: tensor([319., 614.]), win_pct=34.19%, sum=933.0\n",
      "gen=3: tensor([41., 53.]), win_pct=43.62%, sum=94.0\n",
      "gen=4: tensor([54., 85.]), win_pct=38.85%, sum=139.0\n",
      "gen=5: tensor([174., 288.]), win_pct=37.66%, sum=462.0\n",
      "player_probs=[0.55200404 0.4479959 ]\n",
      "\n",
      "prefix=(0, 1, 4)\n",
      "gen=*: tensor([385., 883.]), win_pct=30.36%, sum=1268.0\n",
      "gen=1: tensor([ 84., 150.]), win_pct=35.90%, sum=234.0\n",
      "gen=2: tensor([ 80., 355.]), win_pct=18.39%, sum=435.0\n",
      "gen=3: tensor([25., 38.]), win_pct=39.68%, sum=63.0\n",
      "gen=4: tensor([48., 81.]), win_pct=37.21%, sum=129.0\n",
      "gen=5: tensor([148., 259.]), win_pct=36.36%, sum=407.0\n",
      "player_probs=[0.55244166 0.44755837]\n",
      "\n",
      "prefix=(0, 2)\n",
      "gen=*: tensor([4801., 5671.]), win_pct=45.85%, sum=10472.0\n",
      "gen=1: tensor([771., 573.]), win_pct=57.37%, sum=1344.0\n",
      "gen=2: tensor([ 66., 262.]), win_pct=20.12%, sum=328.0\n",
      "gen=3: tensor([35., 74.]), win_pct=32.11%, sum=109.0\n",
      "gen=4: tensor([3380., 4306.]), win_pct=43.98%, sum=7686.0\n",
      "gen=5: tensor([549., 456.]), win_pct=54.63%, sum=1005.0\n",
      "player_probs=[0.5518051 0.4481949]\n",
      "\n",
      "prefix=(0, 2, 1)\n",
      "gen=*: tensor([1175.,  538.]), win_pct=68.59%, sum=1713.0\n",
      "gen=1: tensor([125.,  60.]), win_pct=67.57%, sum=185.0\n",
      "gen=2: tensor([3., 1.]), win_pct=75.00%, sum=4.0\n",
      "gen=4: tensor([1033.,  474.]), win_pct=68.55%, sum=1507.0\n",
      "gen=5: tensor([14.,  3.]), win_pct=82.35%, sum=17.0\n",
      "player_probs=[0.5524044  0.44759563]\n",
      "\n",
      "prefix=(0, 2, 1, 3)\n",
      "gen=*: tensor([965., 449.]), win_pct=68.25%, sum=1414.0\n",
      "gen=1: tensor([19.,  8.]), win_pct=70.37%, sum=27.0\n",
      "gen=4: tensor([946., 441.]), win_pct=68.20%, sum=1387.0\n",
      "player_probs=[0.55212605 0.44787398]\n",
      "\n",
      "prefix=(0, 2, 1, 3, 5)\n",
      "gen=*: tensor([441., 306.]), win_pct=59.04%, sum=747.0\n",
      "gen=1: tensor([1., 2.]), win_pct=33.33%, sum=3.0\n",
      "gen=4: tensor([440., 304.]), win_pct=59.14%, sum=744.0\n",
      "player_probs=[0.55237895 0.44762102]\n",
      "\n",
      "prefix=(0, 2, 3)\n",
      "gen=*: tensor([2574., 4171.]), win_pct=38.16%, sum=6745.0\n",
      "gen=1: tensor([75., 90.]), win_pct=45.45%, sum=165.0\n",
      "gen=2: tensor([ 6., 30.]), win_pct=16.67%, sum=36.0\n",
      "gen=3: tensor([2., 1.]), win_pct=66.67%, sum=3.0\n",
      "gen=4: tensor([2022., 3652.]), win_pct=35.64%, sum=5674.0\n",
      "gen=5: tensor([469., 398.]), win_pct=54.09%, sum=867.0\n",
      "player_probs=[0.55152726 0.4484728 ]\n",
      "\n",
      "prefix=(0, 2, 3, 2)\n",
      "gen=*: tensor([647., 204.]), win_pct=76.03%, sum=851.0\n",
      "gen=1: tensor([8., 5.]), win_pct=61.54%, sum=13.0\n",
      "gen=2: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=3: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=4: tensor([603., 175.]), win_pct=77.51%, sum=778.0\n",
      "gen=5: tensor([34., 24.]), win_pct=58.62%, sum=58.0\n",
      "player_probs=[0.5521198  0.44788018]\n",
      "\n",
      "prefix=(0, 2, 3, 6)\n",
      "gen=*: tensor([1528., 3117.]), win_pct=32.90%, sum=4645.0\n",
      "gen=1: tensor([15., 12.]), win_pct=55.56%, sum=27.0\n",
      "gen=2: tensor([0., 2.]), win_pct=0.00%, sum=2.0\n",
      "gen=4: tensor([1245., 2912.]), win_pct=29.95%, sum=4157.0\n",
      "gen=5: tensor([268., 191.]), win_pct=58.39%, sum=459.0\n",
      "player_probs=[0.55162776 0.44837227]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3)\n",
      "gen=*: tensor([ 714., 2412.]), win_pct=22.84%, sum=3126.0\n",
      "gen=1: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=2: tensor([0., 1.]), win_pct=0.00%, sum=1.0\n",
      "gen=4: tensor([ 705., 2400.]), win_pct=22.71%, sum=3105.0\n",
      "gen=5: tensor([ 8., 11.]), win_pct=42.11%, sum=19.0\n",
      "player_probs=[0.551348 0.448652]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1)\n",
      "gen=*: tensor([ 508., 2192.]), win_pct=18.81%, sum=2700.0\n",
      "gen=4: tensor([ 507., 2192.]), win_pct=18.78%, sum=2699.0\n",
      "gen=5: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "player_probs=[0.5518547 0.4481453]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1, 7)\n",
      "gen=*: tensor([ 335., 1977.]), win_pct=14.49%, sum=2312.0\n",
      "gen=4: tensor([ 334., 1977.]), win_pct=14.45%, sum=2311.0\n",
      "gen=5: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "player_probs=[0.55255944 0.44744056]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1, 7, 4)\n",
      "gen=*: tensor([ 202., 1504.]), win_pct=11.84%, sum=1706.0\n",
      "gen=4: tensor([ 202., 1504.]), win_pct=11.84%, sum=1706.0\n",
      "player_probs=[0.55309486 0.44690517]\n",
      "\n",
      "prefix=(0, 2, 4)\n",
      "gen=*: tensor([230., 537.]), win_pct=29.99%, sum=767.0\n",
      "gen=1: tensor([ 80., 145.]), win_pct=35.56%, sum=225.0\n",
      "gen=2: tensor([ 52., 224.]), win_pct=18.84%, sum=276.0\n",
      "gen=3: tensor([33., 73.]), win_pct=31.13%, sum=106.0\n",
      "gen=4: tensor([29., 56.]), win_pct=34.12%, sum=85.0\n",
      "gen=5: tensor([36., 39.]), win_pct=48.00%, sum=75.0\n",
      "player_probs=[0.55222726 0.4477727 ]\n",
      "\n",
      "prefix=(0, 3)\n",
      "gen=*: tensor([2462., 2433.]), win_pct=50.30%, sum=4895.0\n",
      "gen=1: tensor([846., 451.]), win_pct=65.23%, sum=1297.0\n",
      "gen=2: tensor([723., 924.]), win_pct=43.90%, sum=1647.0\n",
      "gen=3: tensor([23., 80.]), win_pct=22.33%, sum=103.0\n",
      "gen=4: tensor([149., 200.]), win_pct=42.69%, sum=349.0\n",
      "gen=5: tensor([721., 778.]), win_pct=48.10%, sum=1499.0\n",
      "player_probs=[0.5510513 0.4489487]\n",
      "\n",
      "prefix=(0, 3, 4)\n",
      "gen=*: tensor([1348., 1917.]), win_pct=41.29%, sum=3265.0\n",
      "gen=1: tensor([ 99., 103.]), win_pct=49.01%, sum=202.0\n",
      "gen=2: tensor([458., 821.]), win_pct=35.81%, sum=1279.0\n",
      "gen=3: tensor([19., 79.]), win_pct=19.39%, sum=98.0\n",
      "gen=4: tensor([116., 168.]), win_pct=40.85%, sum=284.0\n",
      "gen=5: tensor([656., 746.]), win_pct=46.79%, sum=1402.0\n",
      "player_probs=[0.55146104 0.44853896]\n",
      "\n",
      "prefix=(0, 3, 4, 4)\n",
      "gen=*: tensor([779., 807.]), win_pct=49.12%, sum=1586.0\n",
      "gen=1: tensor([14., 11.]), win_pct=56.00%, sum=25.0\n",
      "gen=2: tensor([319., 516.]), win_pct=38.20%, sum=835.0\n",
      "gen=3: tensor([ 4., 19.]), win_pct=17.39%, sum=23.0\n",
      "gen=4: tensor([ 91., 136.]), win_pct=40.09%, sum=227.0\n",
      "gen=5: tensor([351., 125.]), win_pct=73.74%, sum=476.0\n",
      "player_probs=[0.5517055  0.44829455]\n",
      "\n",
      "prefix=(0, 4)\n",
      "gen=*: tensor([12812.,  8544.]), win_pct=59.99%, sum=21356.0\n",
      "gen=1: tensor([1140.,  353.]), win_pct=76.36%, sum=1493.0\n",
      "gen=2: tensor([2451., 1809.]), win_pct=57.54%, sum=4260.0\n",
      "gen=3: tensor([4922., 4296.]), win_pct=53.40%, sum=9218.0\n",
      "gen=4: tensor([565., 317.]), win_pct=64.06%, sum=882.0\n",
      "gen=5: tensor([3734., 1769.]), win_pct=67.85%, sum=5503.0\n",
      "player_probs=[0.5517535 0.4482465]\n",
      "\n",
      "prefix=(0, 4, 1)\n",
      "gen=*: tensor([930., 311.]), win_pct=74.94%, sum=1241.0\n",
      "gen=1: tensor([183.,  44.]), win_pct=80.62%, sum=227.0\n",
      "gen=2: tensor([41.,  8.]), win_pct=83.67%, sum=49.0\n",
      "gen=3: tensor([129.,  23.]), win_pct=84.87%, sum=152.0\n",
      "gen=4: tensor([304., 210.]), win_pct=59.14%, sum=514.0\n",
      "gen=5: tensor([273.,  26.]), win_pct=91.30%, sum=299.0\n",
      "player_probs=[0.55234253 0.44765753]\n",
      "\n",
      "prefix=(0, 4, 3)\n",
      "gen=*: tensor([529., 223.]), win_pct=70.35%, sum=752.0\n",
      "gen=1: tensor([140.,  58.]), win_pct=70.71%, sum=198.0\n",
      "gen=2: tensor([75., 40.]), win_pct=65.22%, sum=115.0\n",
      "gen=3: tensor([67., 75.]), win_pct=47.18%, sum=142.0\n",
      "gen=4: tensor([33.,  7.]), win_pct=82.50%, sum=40.0\n",
      "gen=5: tensor([214.,  43.]), win_pct=83.27%, sum=257.0\n",
      "player_probs=[0.5514836  0.44851646]\n",
      "\n",
      "prefix=(0, 4, 4)\n",
      "gen=*: tensor([9689., 7366.]), win_pct=56.81%, sum=17055.0\n",
      "gen=1: tensor([181.,  55.]), win_pct=76.69%, sum=236.0\n",
      "gen=2: tensor([2176., 1663.]), win_pct=56.68%, sum=3839.0\n",
      "gen=3: tensor([4374., 4039.]), win_pct=51.99%, sum=8413.0\n",
      "gen=4: tensor([33., 18.]), win_pct=64.71%, sum=51.0\n",
      "gen=5: tensor([2925., 1591.]), win_pct=64.77%, sum=4516.0\n",
      "player_probs=[0.5521419 0.4478581]\n",
      "\n",
      "prefix=(0, 4, 4, 2)\n",
      "gen=*: tensor([1110.,  587.]), win_pct=65.41%, sum=1697.0\n",
      "gen=1: tensor([14.,  8.]), win_pct=63.64%, sum=22.0\n",
      "gen=2: tensor([175., 219.]), win_pct=44.42%, sum=394.0\n",
      "gen=3: tensor([836., 289.]), win_pct=74.31%, sum=1125.0\n",
      "gen=4: tensor([1., 3.]), win_pct=25.00%, sum=4.0\n",
      "gen=5: tensor([84., 68.]), win_pct=55.26%, sum=152.0\n",
      "player_probs=[0.55274403 0.44725594]\n",
      "\n",
      "prefix=(0, 4, 4, 2, 3)\n",
      "gen=*: tensor([377., 426.]), win_pct=46.95%, sum=803.0\n",
      "gen=1: tensor([2., 2.]), win_pct=50.00%, sum=4.0\n",
      "gen=2: tensor([120., 191.]), win_pct=38.59%, sum=311.0\n",
      "gen=3: tensor([189., 163.]), win_pct=53.69%, sum=352.0\n",
      "gen=4: tensor([1., 3.]), win_pct=25.00%, sum=4.0\n",
      "gen=5: tensor([65., 67.]), win_pct=49.24%, sum=132.0\n",
      "player_probs=[0.5525546  0.44744536]\n",
      "\n",
      "prefix=(0, 4, 4, 2, 4)\n",
      "gen=*: tensor([634., 127.]), win_pct=83.31%, sum=761.0\n",
      "gen=1: tensor([2., 2.]), win_pct=50.00%, sum=4.0\n",
      "gen=2: tensor([13., 11.]), win_pct=54.17%, sum=24.0\n",
      "gen=3: tensor([612., 114.]), win_pct=84.30%, sum=726.0\n",
      "gen=5: tensor([7., 0.]), win_pct=100.00%, sum=7.0\n",
      "player_probs=[0.5529837 0.4470163]\n",
      "\n",
      "prefix=(0, 4, 4, 3)\n",
      "gen=*: tensor([3175., 1406.]), win_pct=69.31%, sum=4581.0\n",
      "gen=1: tensor([36.,  3.]), win_pct=92.31%, sum=39.0\n",
      "gen=2: tensor([438., 159.]), win_pct=73.37%, sum=597.0\n",
      "gen=3: tensor([725., 351.]), win_pct=67.38%, sum=1076.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([1974.,  893.]), win_pct=68.85%, sum=2867.0\n",
      "player_probs=[0.551904 0.448096]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2)\n",
      "gen=*: tensor([1843., 1014.]), win_pct=64.51%, sum=2857.0\n",
      "gen=1: tensor([7., 1.]), win_pct=87.50%, sum=8.0\n",
      "gen=2: tensor([19., 21.]), win_pct=47.50%, sum=40.0\n",
      "gen=3: tensor([673., 342.]), win_pct=66.31%, sum=1015.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([1142.,  650.]), win_pct=63.73%, sum=1792.0\n",
      "player_probs=[0.5524626  0.44753748]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2, 3)\n",
      "gen=*: tensor([661., 361.]), win_pct=64.68%, sum=1022.0\n",
      "gen=1: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=2: tensor([1., 1.]), win_pct=50.00%, sum=2.0\n",
      "gen=3: tensor([50., 37.]), win_pct=57.47%, sum=87.0\n",
      "gen=5: tensor([608., 323.]), win_pct=65.31%, sum=931.0\n",
      "player_probs=[0.5523067  0.44769332]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2, 4)\n",
      "gen=*: tensor([514., 458.]), win_pct=52.88%, sum=972.0\n",
      "gen=1: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=2: tensor([ 7., 10.]), win_pct=41.18%, sum=17.0\n",
      "gen=3: tensor([ 85., 156.]), win_pct=35.27%, sum=241.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([419., 292.]), win_pct=58.93%, sum=711.0\n",
      "player_probs=[0.5528179  0.44718215]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 5)\n",
      "gen=*: tensor([539., 240.]), win_pct=69.19%, sum=779.0\n",
      "gen=1: tensor([3., 0.]), win_pct=100.00%, sum=3.0\n",
      "gen=2: tensor([26., 18.]), win_pct=59.09%, sum=44.0\n",
      "gen=3: tensor([5., 5.]), win_pct=50.00%, sum=10.0\n",
      "gen=5: tensor([505., 217.]), win_pct=69.94%, sum=722.0\n",
      "player_probs=[0.5521999  0.44780007]\n",
      "\n",
      "prefix=(0, 4, 4, 4)\n",
      "gen=*: tensor([2009., 1557.]), win_pct=56.34%, sum=3566.0\n",
      "gen=1: tensor([30., 12.]), win_pct=71.43%, sum=42.0\n",
      "gen=2: tensor([728., 660.]), win_pct=52.45%, sum=1388.0\n",
      "gen=3: tensor([780., 636.]), win_pct=55.08%, sum=1416.0\n",
      "gen=4: tensor([29., 14.]), win_pct=67.44%, sum=43.0\n",
      "gen=5: tensor([442., 235.]), win_pct=65.29%, sum=677.0\n",
      "player_probs=[0.5523664 0.4476336]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 3)\n",
      "gen=*: tensor([839., 735.]), win_pct=53.30%, sum=1574.0\n",
      "gen=1: tensor([5., 1.]), win_pct=83.33%, sum=6.0\n",
      "gen=2: tensor([497., 533.]), win_pct=48.25%, sum=1030.0\n",
      "gen=3: tensor([19., 17.]), win_pct=52.78%, sum=36.0\n",
      "gen=4: tensor([23., 11.]), win_pct=67.65%, sum=34.0\n",
      "gen=5: tensor([295., 173.]), win_pct=63.03%, sum=468.0\n",
      "player_probs=[0.5521728  0.44782725]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4)\n",
      "gen=*: tensor([755., 639.]), win_pct=54.16%, sum=1394.0\n",
      "gen=1: tensor([4., 2.]), win_pct=66.67%, sum=6.0\n",
      "gen=2: tensor([9., 7.]), win_pct=56.25%, sum=16.0\n",
      "gen=3: tensor([666., 603.]), win_pct=52.48%, sum=1269.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([74., 27.]), win_pct=73.27%, sum=101.0\n",
      "player_probs=[0.5525962  0.44740385]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7)\n",
      "gen=*: tensor([460., 545.]), win_pct=45.77%, sum=1005.0\n",
      "gen=1: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=2: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=3: tensor([455., 544.]), win_pct=45.55%, sum=999.0\n",
      "gen=5: tensor([2., 1.]), win_pct=66.67%, sum=3.0\n",
      "player_probs=[0.5534503  0.44654977]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7, 1)\n",
      "gen=*: tensor([374., 512.]), win_pct=42.21%, sum=886.0\n",
      "gen=3: tensor([374., 512.]), win_pct=42.21%, sum=886.0\n",
      "player_probs=[0.55397063 0.4460293 ]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7, 1, 6)\n",
      "gen=*: tensor([280., 467.]), win_pct=37.48%, sum=747.0\n",
      "gen=3: tensor([280., 467.]), win_pct=37.48%, sum=747.0\n",
      "player_probs=[0.55433977 0.44566023]\n",
      "\n",
      "prefix=(0, 4, 4, 5)\n",
      "gen=*: tensor([2454., 3073.]), win_pct=44.40%, sum=5527.0\n",
      "gen=1: tensor([22.,  5.]), win_pct=81.48%, sum=27.0\n",
      "gen=2: tensor([255., 182.]), win_pct=58.35%, sum=437.0\n",
      "gen=3: tensor([1793., 2519.]), win_pct=41.58%, sum=4312.0\n",
      "gen=5: tensor([384., 367.]), win_pct=51.13%, sum=751.0\n",
      "player_probs=[0.5523007  0.44769928]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3)\n",
      "gen=*: tensor([1919., 2892.]), win_pct=39.89%, sum=4811.0\n",
      "gen=1: tensor([1., 1.]), win_pct=50.00%, sum=2.0\n",
      "gen=2: tensor([176., 150.]), win_pct=53.99%, sum=326.0\n",
      "gen=3: tensor([1505., 2401.]), win_pct=38.53%, sum=3906.0\n",
      "gen=5: tensor([237., 340.]), win_pct=41.07%, sum=577.0\n",
      "player_probs=[0.55208945 0.44791058]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3)\n",
      "gen=*: tensor([1183., 2101.]), win_pct=36.02%, sum=3284.0\n",
      "gen=2: tensor([15.,  4.]), win_pct=78.95%, sum=19.0\n",
      "gen=3: tensor([1143., 2004.]), win_pct=36.32%, sum=3147.0\n",
      "gen=5: tensor([25., 93.]), win_pct=21.19%, sum=118.0\n",
      "player_probs=[0.5519148  0.44808522]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5)\n",
      "gen=*: tensor([1058., 1883.]), win_pct=35.97%, sum=2941.0\n",
      "gen=2: tensor([11.,  2.]), win_pct=84.62%, sum=13.0\n",
      "gen=3: tensor([1047., 1881.]), win_pct=35.76%, sum=2928.0\n",
      "player_probs=[0.5520108  0.44798923]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5, 5)\n",
      "gen=*: tensor([368., 429.]), win_pct=46.17%, sum=797.0\n",
      "gen=2: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=3: tensor([366., 429.]), win_pct=46.04%, sum=795.0\n",
      "player_probs=[0.5524621  0.44753793]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5, 5, 6)\n",
      "gen=*: tensor([320., 401.]), win_pct=44.38%, sum=721.0\n",
      "gen=3: tensor([320., 401.]), win_pct=44.38%, sum=721.0\n",
      "player_probs=[0.5526357 0.4473643]\n",
      "\n",
      "prefix=(0, 4, 5)\n",
      "gen=*: tensor([501., 260.]), win_pct=65.83%, sum=761.0\n",
      "gen=1: tensor([165.,  66.]), win_pct=71.43%, sum=231.0\n",
      "gen=2: tensor([50., 41.]), win_pct=54.95%, sum=91.0\n",
      "gen=3: tensor([82., 54.]), win_pct=60.29%, sum=136.0\n",
      "gen=4: tensor([42., 26.]), win_pct=61.76%, sum=68.0\n",
      "gen=5: tensor([162.,  73.]), win_pct=68.94%, sum=235.0\n",
      "player_probs=[0.55190337 0.44809657]\n",
      "\n",
      "prefix=(0, 5)\n",
      "gen=*: tensor([2250.5000, 2097.5000]), win_pct=51.76%, sum=4348.0\n",
      "gen=1: tensor([1014.,  511.]), win_pct=66.49%, sum=1525.0\n",
      "gen=2: tensor([629., 879.]), win_pct=41.71%, sum=1508.0\n",
      "gen=3: tensor([66.5000, 65.5000]), win_pct=50.38%, sum=132.0\n",
      "gen=4: tensor([184., 135.]), win_pct=57.68%, sum=319.0\n",
      "gen=5: tensor([357., 507.]), win_pct=41.32%, sum=864.0\n",
      "player_probs=[0.55149066 0.44850934]\n",
      "\n",
      "prefix=(0, 5, 4)\n",
      "gen=*: tensor([1072.5000, 1581.5000]), win_pct=40.41%, sum=2654.0\n",
      "gen=1: tensor([102., 113.]), win_pct=47.44%, sum=215.0\n",
      "gen=2: tensor([450., 802.]), win_pct=35.94%, sum=1252.0\n",
      "gen=3: tensor([62.5000, 64.5000]), win_pct=49.21%, sum=127.0\n",
      "gen=4: tensor([124., 116.]), win_pct=51.67%, sum=240.0\n",
      "gen=5: tensor([334., 486.]), win_pct=40.73%, sum=820.0\n",
      "player_probs=[0.5518846  0.44811547]\n",
      "\n",
      "prefix=(0, 5, 4, 4)\n",
      "gen=*: tensor([631., 929.]), win_pct=40.45%, sum=1560.0\n",
      "gen=1: tensor([16., 12.]), win_pct=57.14%, sum=28.0\n",
      "gen=2: tensor([347., 560.]), win_pct=38.26%, sum=907.0\n",
      "gen=3: tensor([3., 4.]), win_pct=42.86%, sum=7.0\n",
      "gen=4: tensor([3., 6.]), win_pct=33.33%, sum=9.0\n",
      "gen=5: tensor([262., 347.]), win_pct=43.02%, sum=609.0\n",
      "player_probs=[0.55213076 0.4478692 ]\n",
      "\n",
      "prefix=(0, 6)\n",
      "gen=*: tensor([1168.,  996.]), win_pct=53.97%, sum=2164.0\n",
      "gen=1: tensor([869., 532.]), win_pct=62.03%, sum=1401.0\n",
      "gen=2: tensor([ 86., 244.]), win_pct=26.06%, sum=330.0\n",
      "gen=3: tensor([51., 97.]), win_pct=34.46%, sum=148.0\n",
      "gen=4: tensor([37., 57.]), win_pct=39.36%, sum=94.0\n",
      "gen=5: tensor([125.,  66.]), win_pct=65.45%, sum=191.0\n",
      "player_probs=[0.551355 0.448645]\n",
      "\n",
      "prefix=(0, 6, 4)\n",
      "gen=*: tensor([321., 516.]), win_pct=38.35%, sum=837.0\n",
      "gen=1: tensor([ 94., 117.]), win_pct=44.55%, sum=211.0\n",
      "gen=2: tensor([ 69., 225.]), win_pct=23.47%, sum=294.0\n",
      "gen=3: tensor([45., 89.]), win_pct=33.58%, sum=134.0\n",
      "gen=4: tensor([24., 46.]), win_pct=34.29%, sum=70.0\n",
      "gen=5: tensor([89., 39.]), win_pct=69.53%, sum=128.0\n",
      "player_probs=[0.55175406 0.448246  ]\n",
      "\n",
      "prefix=(0, 7)\n",
      "gen=*: tensor([1556.5000, 2016.5000]), win_pct=43.56%, sum=3573.0\n",
      "gen=1: tensor([741.5000, 634.5000]), win_pct=53.89%, sum=1376.0\n",
      "gen=2: tensor([371., 623.]), win_pct=37.32%, sum=994.0\n",
      "gen=3: tensor([ 64., 132.]), win_pct=32.65%, sum=196.0\n",
      "gen=4: tensor([201., 330.]), win_pct=37.85%, sum=531.0\n",
      "gen=5: tensor([179., 297.]), win_pct=37.61%, sum=476.0\n",
      "player_probs=[0.5521995  0.44780052]\n",
      "\n",
      "prefix=(0, 7, 4)\n",
      "gen=*: tensor([ 490., 1099.]), win_pct=30.84%, sum=1589.0\n",
      "gen=1: tensor([ 79., 123.]), win_pct=39.11%, sum=202.0\n",
      "gen=2: tensor([ 95., 295.]), win_pct=24.36%, sum=390.0\n",
      "gen=3: tensor([ 55., 130.]), win_pct=29.73%, sum=185.0\n",
      "gen=4: tensor([124., 301.]), win_pct=29.18%, sum=425.0\n",
      "gen=5: tensor([137., 250.]), win_pct=35.40%, sum=387.0\n",
      "player_probs=[0.5526532 0.4473468]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n### Model 0\")\n",
    "print(model_0.action_embedding.weight)\n",
    "compare_model_vs_data(model_0, game, dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Model 1\n",
      "Parameter containing:\n",
      "tensor([[ 0.1855, -0.1236,  0.0325, -0.2279, -0.1312,  0.2044, -0.0552,  0.0015,\n",
      "          0.0456, -0.0645, -0.2379,  0.0170,  0.0728,  0.1388, -0.0804,  0.0047,\n",
      "          0.2121, -0.1895,  0.0768,  0.0613,  0.1133, -0.3043,  0.0052, -0.1532,\n",
      "          0.2247,  0.2399,  0.0458,  0.2320,  0.2496, -0.0537, -0.2677, -0.1787],\n",
      "        [ 0.0808, -0.2869,  0.0688, -0.1646,  0.3144,  0.0958,  0.0340, -0.1392,\n",
      "         -0.2065,  0.4270,  0.2191, -0.1682,  0.0057, -0.0339, -0.0352,  0.3426,\n",
      "          0.0628,  0.1943, -0.1348, -0.0467, -0.1249, -0.0522,  0.3732,  0.0999,\n",
      "         -0.0559, -0.1346, -0.1585, -0.2288, -0.0584, -0.0580,  0.0284, -0.2018],\n",
      "        [ 0.3760, -0.0341, -0.0524, -0.1812, -0.2408,  0.1764, -0.0913, -0.1694,\n",
      "         -0.2916, -0.1422, -0.1412, -0.0781,  0.1165,  0.0633,  0.1347, -0.4096,\n",
      "          0.2124, -0.2153, -0.0055, -0.1609, -0.2353,  0.0733, -0.1883, -0.4946,\n",
      "          0.1866,  0.2968,  0.3776,  0.3554,  0.0164, -0.1493, -0.3089, -0.0679],\n",
      "        [ 0.0016, -0.0088, -0.1069,  0.1094, -0.0922,  0.3032,  0.2390,  0.1223,\n",
      "         -0.1586, -0.1466, -0.1003,  0.1502, -0.1688,  0.4107,  0.1677, -0.2314,\n",
      "          0.1650,  0.0888,  0.0102, -0.0915,  0.3839, -0.1758, -0.1703, -0.0917,\n",
      "          0.3358, -0.1317,  0.0204, -0.1294,  0.0792, -0.1334,  0.0147,  0.3009],\n",
      "        [-0.0675, -0.0137,  0.1669,  0.1069,  0.0721,  0.0373, -0.0502,  0.1817,\n",
      "          0.2545,  0.0166,  0.0391,  0.1686, -0.1655, -0.0686, -0.3643,  0.0639,\n",
      "         -0.0690,  0.0546,  0.1317,  0.0649,  0.0386,  0.0211,  0.1857,  0.0489,\n",
      "          0.0365, -0.0658, -0.2632, -0.1984, -0.0332,  0.0578,  0.0674,  0.0343],\n",
      "        [-0.1813, -0.1040,  0.0812, -0.1426,  0.0893,  0.0409, -0.1936,  0.0635,\n",
      "         -0.0032, -0.0580,  0.1889, -0.0017,  0.0574,  0.2297, -0.0126, -0.0326,\n",
      "          0.1255,  0.2326, -0.0110, -0.2326,  0.2620, -0.1879, -0.2292, -0.0136,\n",
      "         -0.0285, -0.1812, -0.0721, -0.2002,  0.0099, -0.0103, -0.1667,  0.1926],\n",
      "        [ 0.1855, -0.1004,  0.1512,  0.0503, -0.1972, -0.1217,  0.1700,  0.2461,\n",
      "         -0.1227,  0.4531, -0.0483,  0.2191, -0.1108,  0.1343, -0.1850,  0.1624,\n",
      "          0.1734,  0.2414, -0.1392,  0.2010,  0.0255, -0.0515,  0.0643,  0.0467,\n",
      "         -0.0635, -0.0821, -0.0450, -0.2129, -0.0438, -0.1449,  0.1395, -0.0261],\n",
      "        [-0.0468, -0.0246, -0.1006, -0.0404, -0.0264, -0.1215,  0.0276, -0.1783,\n",
      "         -0.0440,  0.0440, -0.0851, -0.2108,  0.0533, -0.1030,  0.3216,  0.0568,\n",
      "         -0.1618, -0.0998, -0.1731, -0.0034, -0.0830,  0.1363,  0.0584,  0.1357,\n",
      "         -0.1118,  0.0241,  0.0370,  0.0427, -0.0733, -0.0439,  0.0222, -0.1090]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "\n",
      "prefix=(0,)\n",
      "gen=*: tensor([26450., 23550.]), win_pct=52.90%, sum=50000.0\n",
      "gen=1: tensor([6193.5000, 3806.5000]), win_pct=61.94%, sum=10000.0\n",
      "gen=2: tensor([4645., 5355.]), win_pct=46.45%, sum=10000.0\n",
      "gen=3: tensor([5202.5000, 4797.5000]), win_pct=52.03%, sum=10000.0\n",
      "gen=4: tensor([4570., 5430.]), win_pct=45.70%, sum=10000.0\n",
      "gen=5: tensor([5839., 4161.]), win_pct=58.39%, sum=10000.0\n",
      "player_probs=[0.62489843 0.3751015 ]\n",
      "\n",
      "prefix=(0, 1)\n",
      "gen=*: tensor([1400., 1792.]), win_pct=43.86%, sum=3192.0\n",
      "gen=1: tensor([812., 752.]), win_pct=51.92%, sum=1564.0\n",
      "gen=2: tensor([319., 614.]), win_pct=34.19%, sum=933.0\n",
      "gen=3: tensor([41., 53.]), win_pct=43.62%, sum=94.0\n",
      "gen=4: tensor([54., 85.]), win_pct=38.85%, sum=139.0\n",
      "gen=5: tensor([174., 288.]), win_pct=37.66%, sum=462.0\n",
      "player_probs=[0.6101264  0.38987362]\n",
      "\n",
      "prefix=(0, 1, 4)\n",
      "gen=*: tensor([385., 883.]), win_pct=30.36%, sum=1268.0\n",
      "gen=1: tensor([ 84., 150.]), win_pct=35.90%, sum=234.0\n",
      "gen=2: tensor([ 80., 355.]), win_pct=18.39%, sum=435.0\n",
      "gen=3: tensor([25., 38.]), win_pct=39.68%, sum=63.0\n",
      "gen=4: tensor([48., 81.]), win_pct=37.21%, sum=129.0\n",
      "gen=5: tensor([148., 259.]), win_pct=36.36%, sum=407.0\n",
      "player_probs=[0.36332536 0.6366746 ]\n",
      "\n",
      "prefix=(0, 2)\n",
      "gen=*: tensor([4801., 5671.]), win_pct=45.85%, sum=10472.0\n",
      "gen=1: tensor([771., 573.]), win_pct=57.37%, sum=1344.0\n",
      "gen=2: tensor([ 66., 262.]), win_pct=20.12%, sum=328.0\n",
      "gen=3: tensor([35., 74.]), win_pct=32.11%, sum=109.0\n",
      "gen=4: tensor([3380., 4306.]), win_pct=43.98%, sum=7686.0\n",
      "gen=5: tensor([549., 456.]), win_pct=54.63%, sum=1005.0\n",
      "player_probs=[0.6239609 0.3760391]\n",
      "\n",
      "prefix=(0, 2, 1)\n",
      "gen=*: tensor([1175.,  538.]), win_pct=68.59%, sum=1713.0\n",
      "gen=1: tensor([125.,  60.]), win_pct=67.57%, sum=185.0\n",
      "gen=2: tensor([3., 1.]), win_pct=75.00%, sum=4.0\n",
      "gen=4: tensor([1033.,  474.]), win_pct=68.55%, sum=1507.0\n",
      "gen=5: tensor([14.,  3.]), win_pct=82.35%, sum=17.0\n",
      "player_probs=[0.69045347 0.30954656]\n",
      "\n",
      "prefix=(0, 2, 1, 3)\n",
      "gen=*: tensor([965., 449.]), win_pct=68.25%, sum=1414.0\n",
      "gen=1: tensor([19.,  8.]), win_pct=70.37%, sum=27.0\n",
      "gen=4: tensor([946., 441.]), win_pct=68.20%, sum=1387.0\n",
      "player_probs=[0.7263571 0.2736429]\n",
      "\n",
      "prefix=(0, 2, 1, 3, 5)\n",
      "gen=*: tensor([441., 306.]), win_pct=59.04%, sum=747.0\n",
      "gen=1: tensor([1., 2.]), win_pct=33.33%, sum=3.0\n",
      "gen=4: tensor([440., 304.]), win_pct=59.14%, sum=744.0\n",
      "player_probs=[0.6704786  0.32952142]\n",
      "\n",
      "prefix=(0, 2, 3)\n",
      "gen=*: tensor([2574., 4171.]), win_pct=38.16%, sum=6745.0\n",
      "gen=1: tensor([75., 90.]), win_pct=45.45%, sum=165.0\n",
      "gen=2: tensor([ 6., 30.]), win_pct=16.67%, sum=36.0\n",
      "gen=3: tensor([2., 1.]), win_pct=66.67%, sum=3.0\n",
      "gen=4: tensor([2022., 3652.]), win_pct=35.64%, sum=5674.0\n",
      "gen=5: tensor([469., 398.]), win_pct=54.09%, sum=867.0\n",
      "player_probs=[0.36212772 0.6378722 ]\n",
      "\n",
      "prefix=(0, 2, 3, 2)\n",
      "gen=*: tensor([647., 204.]), win_pct=76.03%, sum=851.0\n",
      "gen=1: tensor([8., 5.]), win_pct=61.54%, sum=13.0\n",
      "gen=2: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=3: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=4: tensor([603., 175.]), win_pct=77.51%, sum=778.0\n",
      "gen=5: tensor([34., 24.]), win_pct=58.62%, sum=58.0\n",
      "player_probs=[0.38271245 0.6172875 ]\n",
      "\n",
      "prefix=(0, 2, 3, 6)\n",
      "gen=*: tensor([1528., 3117.]), win_pct=32.90%, sum=4645.0\n",
      "gen=1: tensor([15., 12.]), win_pct=55.56%, sum=27.0\n",
      "gen=2: tensor([0., 2.]), win_pct=0.00%, sum=2.0\n",
      "gen=4: tensor([1245., 2912.]), win_pct=29.95%, sum=4157.0\n",
      "gen=5: tensor([268., 191.]), win_pct=58.39%, sum=459.0\n",
      "player_probs=[0.3920964 0.6079036]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3)\n",
      "gen=*: tensor([ 714., 2412.]), win_pct=22.84%, sum=3126.0\n",
      "gen=1: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=2: tensor([0., 1.]), win_pct=0.00%, sum=1.0\n",
      "gen=4: tensor([ 705., 2400.]), win_pct=22.71%, sum=3105.0\n",
      "gen=5: tensor([ 8., 11.]), win_pct=42.11%, sum=19.0\n",
      "player_probs=[0.3669417  0.63305837]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1)\n",
      "gen=*: tensor([ 508., 2192.]), win_pct=18.81%, sum=2700.0\n",
      "gen=4: tensor([ 507., 2192.]), win_pct=18.78%, sum=2699.0\n",
      "gen=5: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "player_probs=[0.36791328 0.6320867 ]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1, 7)\n",
      "gen=*: tensor([ 335., 1977.]), win_pct=14.49%, sum=2312.0\n",
      "gen=4: tensor([ 334., 1977.]), win_pct=14.45%, sum=2311.0\n",
      "gen=5: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "player_probs=[0.49129507 0.5087049 ]\n",
      "\n",
      "prefix=(0, 2, 3, 6, 3, 1, 7, 4)\n",
      "gen=*: tensor([ 202., 1504.]), win_pct=11.84%, sum=1706.0\n",
      "gen=4: tensor([ 202., 1504.]), win_pct=11.84%, sum=1706.0\n",
      "player_probs=[0.5066782  0.49332178]\n",
      "\n",
      "prefix=(0, 2, 4)\n",
      "gen=*: tensor([230., 537.]), win_pct=29.99%, sum=767.0\n",
      "gen=1: tensor([ 80., 145.]), win_pct=35.56%, sum=225.0\n",
      "gen=2: tensor([ 52., 224.]), win_pct=18.84%, sum=276.0\n",
      "gen=3: tensor([33., 73.]), win_pct=31.13%, sum=106.0\n",
      "gen=4: tensor([29., 56.]), win_pct=34.12%, sum=85.0\n",
      "gen=5: tensor([36., 39.]), win_pct=48.00%, sum=75.0\n",
      "player_probs=[0.30622894 0.69377106]\n",
      "\n",
      "prefix=(0, 3)\n",
      "gen=*: tensor([2462., 2433.]), win_pct=50.30%, sum=4895.0\n",
      "gen=1: tensor([846., 451.]), win_pct=65.23%, sum=1297.0\n",
      "gen=2: tensor([723., 924.]), win_pct=43.90%, sum=1647.0\n",
      "gen=3: tensor([23., 80.]), win_pct=22.33%, sum=103.0\n",
      "gen=4: tensor([149., 200.]), win_pct=42.69%, sum=349.0\n",
      "gen=5: tensor([721., 778.]), win_pct=48.10%, sum=1499.0\n",
      "player_probs=[0.6251088  0.37489122]\n",
      "\n",
      "prefix=(0, 3, 4)\n",
      "gen=*: tensor([1348., 1917.]), win_pct=41.29%, sum=3265.0\n",
      "gen=1: tensor([ 99., 103.]), win_pct=49.01%, sum=202.0\n",
      "gen=2: tensor([458., 821.]), win_pct=35.81%, sum=1279.0\n",
      "gen=3: tensor([19., 79.]), win_pct=19.39%, sum=98.0\n",
      "gen=4: tensor([116., 168.]), win_pct=40.85%, sum=284.0\n",
      "gen=5: tensor([656., 746.]), win_pct=46.79%, sum=1402.0\n",
      "player_probs=[0.38535753 0.61464244]\n",
      "\n",
      "prefix=(0, 3, 4, 4)\n",
      "gen=*: tensor([779., 807.]), win_pct=49.12%, sum=1586.0\n",
      "gen=1: tensor([14., 11.]), win_pct=56.00%, sum=25.0\n",
      "gen=2: tensor([319., 516.]), win_pct=38.20%, sum=835.0\n",
      "gen=3: tensor([ 4., 19.]), win_pct=17.39%, sum=23.0\n",
      "gen=4: tensor([ 91., 136.]), win_pct=40.09%, sum=227.0\n",
      "gen=5: tensor([351., 125.]), win_pct=73.74%, sum=476.0\n",
      "player_probs=[0.5532971  0.44670287]\n",
      "\n",
      "prefix=(0, 4)\n",
      "gen=*: tensor([12812.,  8544.]), win_pct=59.99%, sum=21356.0\n",
      "gen=1: tensor([1140.,  353.]), win_pct=76.36%, sum=1493.0\n",
      "gen=2: tensor([2451., 1809.]), win_pct=57.54%, sum=4260.0\n",
      "gen=3: tensor([4922., 4296.]), win_pct=53.40%, sum=9218.0\n",
      "gen=4: tensor([565., 317.]), win_pct=64.06%, sum=882.0\n",
      "gen=5: tensor([3734., 1769.]), win_pct=67.85%, sum=5503.0\n",
      "player_probs=[0.72290945 0.27709052]\n",
      "\n",
      "prefix=(0, 4, 1)\n",
      "gen=*: tensor([930., 311.]), win_pct=74.94%, sum=1241.0\n",
      "gen=1: tensor([183.,  44.]), win_pct=80.62%, sum=227.0\n",
      "gen=2: tensor([41.,  8.]), win_pct=83.67%, sum=49.0\n",
      "gen=3: tensor([129.,  23.]), win_pct=84.87%, sum=152.0\n",
      "gen=4: tensor([304., 210.]), win_pct=59.14%, sum=514.0\n",
      "gen=5: tensor([273.,  26.]), win_pct=91.30%, sum=299.0\n",
      "player_probs=[0.8271125 0.1728875]\n",
      "\n",
      "prefix=(0, 4, 3)\n",
      "gen=*: tensor([529., 223.]), win_pct=70.35%, sum=752.0\n",
      "gen=1: tensor([140.,  58.]), win_pct=70.71%, sum=198.0\n",
      "gen=2: tensor([75., 40.]), win_pct=65.22%, sum=115.0\n",
      "gen=3: tensor([67., 75.]), win_pct=47.18%, sum=142.0\n",
      "gen=4: tensor([33.,  7.]), win_pct=82.50%, sum=40.0\n",
      "gen=5: tensor([214.,  43.]), win_pct=83.27%, sum=257.0\n",
      "player_probs=[0.68034434 0.31965563]\n",
      "\n",
      "prefix=(0, 4, 4)\n",
      "gen=*: tensor([9689., 7366.]), win_pct=56.81%, sum=17055.0\n",
      "gen=1: tensor([181.,  55.]), win_pct=76.69%, sum=236.0\n",
      "gen=2: tensor([2176., 1663.]), win_pct=56.68%, sum=3839.0\n",
      "gen=3: tensor([4374., 4039.]), win_pct=51.99%, sum=8413.0\n",
      "gen=4: tensor([33., 18.]), win_pct=64.71%, sum=51.0\n",
      "gen=5: tensor([2925., 1591.]), win_pct=64.77%, sum=4516.0\n",
      "player_probs=[0.6434554 0.3565446]\n",
      "\n",
      "prefix=(0, 4, 4, 2)\n",
      "gen=*: tensor([1110.,  587.]), win_pct=65.41%, sum=1697.0\n",
      "gen=1: tensor([14.,  8.]), win_pct=63.64%, sum=22.0\n",
      "gen=2: tensor([175., 219.]), win_pct=44.42%, sum=394.0\n",
      "gen=3: tensor([836., 289.]), win_pct=74.31%, sum=1125.0\n",
      "gen=4: tensor([1., 3.]), win_pct=25.00%, sum=4.0\n",
      "gen=5: tensor([84., 68.]), win_pct=55.26%, sum=152.0\n",
      "player_probs=[0.66879356 0.3312064 ]\n",
      "\n",
      "prefix=(0, 4, 4, 2, 3)\n",
      "gen=*: tensor([377., 426.]), win_pct=46.95%, sum=803.0\n",
      "gen=1: tensor([2., 2.]), win_pct=50.00%, sum=4.0\n",
      "gen=2: tensor([120., 191.]), win_pct=38.59%, sum=311.0\n",
      "gen=3: tensor([189., 163.]), win_pct=53.69%, sum=352.0\n",
      "gen=4: tensor([1., 3.]), win_pct=25.00%, sum=4.0\n",
      "gen=5: tensor([65., 67.]), win_pct=49.24%, sum=132.0\n",
      "player_probs=[0.33076906 0.66923094]\n",
      "\n",
      "prefix=(0, 4, 4, 2, 4)\n",
      "gen=*: tensor([634., 127.]), win_pct=83.31%, sum=761.0\n",
      "gen=1: tensor([2., 2.]), win_pct=50.00%, sum=4.0\n",
      "gen=2: tensor([13., 11.]), win_pct=54.17%, sum=24.0\n",
      "gen=3: tensor([612., 114.]), win_pct=84.30%, sum=726.0\n",
      "gen=5: tensor([7., 0.]), win_pct=100.00%, sum=7.0\n",
      "player_probs=[0.5413588  0.45864123]\n",
      "\n",
      "prefix=(0, 4, 4, 3)\n",
      "gen=*: tensor([3175., 1406.]), win_pct=69.31%, sum=4581.0\n",
      "gen=1: tensor([36.,  3.]), win_pct=92.31%, sum=39.0\n",
      "gen=2: tensor([438., 159.]), win_pct=73.37%, sum=597.0\n",
      "gen=3: tensor([725., 351.]), win_pct=67.38%, sum=1076.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([1974.,  893.]), win_pct=68.85%, sum=2867.0\n",
      "player_probs=[0.3821403  0.61785966]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2)\n",
      "gen=*: tensor([1843., 1014.]), win_pct=64.51%, sum=2857.0\n",
      "gen=1: tensor([7., 1.]), win_pct=87.50%, sum=8.0\n",
      "gen=2: tensor([19., 21.]), win_pct=47.50%, sum=40.0\n",
      "gen=3: tensor([673., 342.]), win_pct=66.31%, sum=1015.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([1142.,  650.]), win_pct=63.73%, sum=1792.0\n",
      "player_probs=[0.4313092  0.56869084]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2, 3)\n",
      "gen=*: tensor([661., 361.]), win_pct=64.68%, sum=1022.0\n",
      "gen=1: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=2: tensor([1., 1.]), win_pct=50.00%, sum=2.0\n",
      "gen=3: tensor([50., 37.]), win_pct=57.47%, sum=87.0\n",
      "gen=5: tensor([608., 323.]), win_pct=65.31%, sum=931.0\n",
      "player_probs=[0.4823747 0.5176253]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 2, 4)\n",
      "gen=*: tensor([514., 458.]), win_pct=52.88%, sum=972.0\n",
      "gen=1: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=2: tensor([ 7., 10.]), win_pct=41.18%, sum=17.0\n",
      "gen=3: tensor([ 85., 156.]), win_pct=35.27%, sum=241.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([419., 292.]), win_pct=58.93%, sum=711.0\n",
      "player_probs=[0.5518462 0.4481538]\n",
      "\n",
      "prefix=(0, 4, 4, 3, 5)\n",
      "gen=*: tensor([539., 240.]), win_pct=69.19%, sum=779.0\n",
      "gen=1: tensor([3., 0.]), win_pct=100.00%, sum=3.0\n",
      "gen=2: tensor([26., 18.]), win_pct=59.09%, sum=44.0\n",
      "gen=3: tensor([5., 5.]), win_pct=50.00%, sum=10.0\n",
      "gen=5: tensor([505., 217.]), win_pct=69.94%, sum=722.0\n",
      "player_probs=[0.45597488 0.5440251 ]\n",
      "\n",
      "prefix=(0, 4, 4, 4)\n",
      "gen=*: tensor([2009., 1557.]), win_pct=56.34%, sum=3566.0\n",
      "gen=1: tensor([30., 12.]), win_pct=71.43%, sum=42.0\n",
      "gen=2: tensor([728., 660.]), win_pct=52.45%, sum=1388.0\n",
      "gen=3: tensor([780., 636.]), win_pct=55.08%, sum=1416.0\n",
      "gen=4: tensor([29., 14.]), win_pct=67.44%, sum=43.0\n",
      "gen=5: tensor([442., 235.]), win_pct=65.29%, sum=677.0\n",
      "player_probs=[0.56860834 0.4313917 ]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 3)\n",
      "gen=*: tensor([839., 735.]), win_pct=53.30%, sum=1574.0\n",
      "gen=1: tensor([5., 1.]), win_pct=83.33%, sum=6.0\n",
      "gen=2: tensor([497., 533.]), win_pct=48.25%, sum=1030.0\n",
      "gen=3: tensor([19., 17.]), win_pct=52.78%, sum=36.0\n",
      "gen=4: tensor([23., 11.]), win_pct=67.65%, sum=34.0\n",
      "gen=5: tensor([295., 173.]), win_pct=63.03%, sum=468.0\n",
      "player_probs=[0.4649858 0.5350142]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4)\n",
      "gen=*: tensor([755., 639.]), win_pct=54.16%, sum=1394.0\n",
      "gen=1: tensor([4., 2.]), win_pct=66.67%, sum=6.0\n",
      "gen=2: tensor([9., 7.]), win_pct=56.25%, sum=16.0\n",
      "gen=3: tensor([666., 603.]), win_pct=52.48%, sum=1269.0\n",
      "gen=4: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=5: tensor([74., 27.]), win_pct=73.27%, sum=101.0\n",
      "player_probs=[0.66533345 0.33466652]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7)\n",
      "gen=*: tensor([460., 545.]), win_pct=45.77%, sum=1005.0\n",
      "gen=1: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=2: tensor([1., 0.]), win_pct=100.00%, sum=1.0\n",
      "gen=3: tensor([455., 544.]), win_pct=45.55%, sum=999.0\n",
      "gen=5: tensor([2., 1.]), win_pct=66.67%, sum=3.0\n",
      "player_probs=[0.53309023 0.46690977]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7, 1)\n",
      "gen=*: tensor([374., 512.]), win_pct=42.21%, sum=886.0\n",
      "gen=3: tensor([374., 512.]), win_pct=42.21%, sum=886.0\n",
      "player_probs=[0.54642683 0.45357314]\n",
      "\n",
      "prefix=(0, 4, 4, 4, 4, 7, 1, 6)\n",
      "gen=*: tensor([280., 467.]), win_pct=37.48%, sum=747.0\n",
      "gen=3: tensor([280., 467.]), win_pct=37.48%, sum=747.0\n",
      "player_probs=[0.53294265 0.46705735]\n",
      "\n",
      "prefix=(0, 4, 4, 5)\n",
      "gen=*: tensor([2454., 3073.]), win_pct=44.40%, sum=5527.0\n",
      "gen=1: tensor([22.,  5.]), win_pct=81.48%, sum=27.0\n",
      "gen=2: tensor([255., 182.]), win_pct=58.35%, sum=437.0\n",
      "gen=3: tensor([1793., 2519.]), win_pct=41.58%, sum=4312.0\n",
      "gen=5: tensor([384., 367.]), win_pct=51.13%, sum=751.0\n",
      "player_probs=[0.46351972 0.5364803 ]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3)\n",
      "gen=*: tensor([1919., 2892.]), win_pct=39.89%, sum=4811.0\n",
      "gen=1: tensor([1., 1.]), win_pct=50.00%, sum=2.0\n",
      "gen=2: tensor([176., 150.]), win_pct=53.99%, sum=326.0\n",
      "gen=3: tensor([1505., 2401.]), win_pct=38.53%, sum=3906.0\n",
      "gen=5: tensor([237., 340.]), win_pct=41.07%, sum=577.0\n",
      "player_probs=[0.39295295 0.607047  ]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3)\n",
      "gen=*: tensor([1183., 2101.]), win_pct=36.02%, sum=3284.0\n",
      "gen=2: tensor([15.,  4.]), win_pct=78.95%, sum=19.0\n",
      "gen=3: tensor([1143., 2004.]), win_pct=36.32%, sum=3147.0\n",
      "gen=5: tensor([25., 93.]), win_pct=21.19%, sum=118.0\n",
      "player_probs=[0.38941118 0.61058885]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5)\n",
      "gen=*: tensor([1058., 1883.]), win_pct=35.97%, sum=2941.0\n",
      "gen=2: tensor([11.,  2.]), win_pct=84.62%, sum=13.0\n",
      "gen=3: tensor([1047., 1881.]), win_pct=35.76%, sum=2928.0\n",
      "player_probs=[0.35909155 0.6409084 ]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5, 5)\n",
      "gen=*: tensor([368., 429.]), win_pct=46.17%, sum=797.0\n",
      "gen=2: tensor([2., 0.]), win_pct=100.00%, sum=2.0\n",
      "gen=3: tensor([366., 429.]), win_pct=46.04%, sum=795.0\n",
      "player_probs=[0.3538727  0.64612734]\n",
      "\n",
      "prefix=(0, 4, 4, 5, 3, 3, 5, 5, 6)\n",
      "gen=*: tensor([320., 401.]), win_pct=44.38%, sum=721.0\n",
      "gen=3: tensor([320., 401.]), win_pct=44.38%, sum=721.0\n",
      "player_probs=[0.33669427 0.6633057 ]\n",
      "\n",
      "prefix=(0, 4, 5)\n",
      "gen=*: tensor([501., 260.]), win_pct=65.83%, sum=761.0\n",
      "gen=1: tensor([165.,  66.]), win_pct=71.43%, sum=231.0\n",
      "gen=2: tensor([50., 41.]), win_pct=54.95%, sum=91.0\n",
      "gen=3: tensor([82., 54.]), win_pct=60.29%, sum=136.0\n",
      "gen=4: tensor([42., 26.]), win_pct=61.76%, sum=68.0\n",
      "gen=5: tensor([162.,  73.]), win_pct=68.94%, sum=235.0\n",
      "player_probs=[0.6791567  0.32084334]\n",
      "\n",
      "prefix=(0, 5)\n",
      "gen=*: tensor([2250.5000, 2097.5000]), win_pct=51.76%, sum=4348.0\n",
      "gen=1: tensor([1014.,  511.]), win_pct=66.49%, sum=1525.0\n",
      "gen=2: tensor([629., 879.]), win_pct=41.71%, sum=1508.0\n",
      "gen=3: tensor([66.5000, 65.5000]), win_pct=50.38%, sum=132.0\n",
      "gen=4: tensor([184., 135.]), win_pct=57.68%, sum=319.0\n",
      "gen=5: tensor([357., 507.]), win_pct=41.32%, sum=864.0\n",
      "player_probs=[0.6570532 0.3429469]\n",
      "\n",
      "prefix=(0, 5, 4)\n",
      "gen=*: tensor([1072.5000, 1581.5000]), win_pct=40.41%, sum=2654.0\n",
      "gen=1: tensor([102., 113.]), win_pct=47.44%, sum=215.0\n",
      "gen=2: tensor([450., 802.]), win_pct=35.94%, sum=1252.0\n",
      "gen=3: tensor([62.5000, 64.5000]), win_pct=49.21%, sum=127.0\n",
      "gen=4: tensor([124., 116.]), win_pct=51.67%, sum=240.0\n",
      "gen=5: tensor([334., 486.]), win_pct=40.73%, sum=820.0\n",
      "player_probs=[0.28507188 0.7149281 ]\n",
      "\n",
      "prefix=(0, 5, 4, 4)\n",
      "gen=*: tensor([631., 929.]), win_pct=40.45%, sum=1560.0\n",
      "gen=1: tensor([16., 12.]), win_pct=57.14%, sum=28.0\n",
      "gen=2: tensor([347., 560.]), win_pct=38.26%, sum=907.0\n",
      "gen=3: tensor([3., 4.]), win_pct=42.86%, sum=7.0\n",
      "gen=4: tensor([3., 6.]), win_pct=33.33%, sum=9.0\n",
      "gen=5: tensor([262., 347.]), win_pct=43.02%, sum=609.0\n",
      "player_probs=[0.51110727 0.48889273]\n",
      "\n",
      "prefix=(0, 6)\n",
      "gen=*: tensor([1168.,  996.]), win_pct=53.97%, sum=2164.0\n",
      "gen=1: tensor([869., 532.]), win_pct=62.03%, sum=1401.0\n",
      "gen=2: tensor([ 86., 244.]), win_pct=26.06%, sum=330.0\n",
      "gen=3: tensor([51., 97.]), win_pct=34.46%, sum=148.0\n",
      "gen=4: tensor([37., 57.]), win_pct=39.36%, sum=94.0\n",
      "gen=5: tensor([125.,  66.]), win_pct=65.45%, sum=191.0\n",
      "player_probs=[0.60984075 0.39015922]\n",
      "\n",
      "prefix=(0, 6, 4)\n",
      "gen=*: tensor([321., 516.]), win_pct=38.35%, sum=837.0\n",
      "gen=1: tensor([ 94., 117.]), win_pct=44.55%, sum=211.0\n",
      "gen=2: tensor([ 69., 225.]), win_pct=23.47%, sum=294.0\n",
      "gen=3: tensor([45., 89.]), win_pct=33.58%, sum=134.0\n",
      "gen=4: tensor([24., 46.]), win_pct=34.29%, sum=70.0\n",
      "gen=5: tensor([89., 39.]), win_pct=69.53%, sum=128.0\n",
      "player_probs=[0.31274298 0.687257  ]\n",
      "\n",
      "prefix=(0, 7)\n",
      "gen=*: tensor([1556.5000, 2016.5000]), win_pct=43.56%, sum=3573.0\n",
      "gen=1: tensor([741.5000, 634.5000]), win_pct=53.89%, sum=1376.0\n",
      "gen=2: tensor([371., 623.]), win_pct=37.32%, sum=994.0\n",
      "gen=3: tensor([ 64., 132.]), win_pct=32.65%, sum=196.0\n",
      "gen=4: tensor([201., 330.]), win_pct=37.85%, sum=531.0\n",
      "gen=5: tensor([179., 297.]), win_pct=37.61%, sum=476.0\n",
      "player_probs=[0.5766261 0.4233739]\n",
      "\n",
      "prefix=(0, 7, 4)\n",
      "gen=*: tensor([ 490., 1099.]), win_pct=30.84%, sum=1589.0\n",
      "gen=1: tensor([ 79., 123.]), win_pct=39.11%, sum=202.0\n",
      "gen=2: tensor([ 95., 295.]), win_pct=24.36%, sum=390.0\n",
      "gen=3: tensor([ 55., 130.]), win_pct=29.73%, sum=185.0\n",
      "gen=4: tensor([124., 301.]), win_pct=29.18%, sum=425.0\n",
      "gen=5: tensor([137., 250.]), win_pct=35.40%, sum=387.0\n",
      "player_probs=[0.4214237  0.57857627]\n"
     ]
    }
   ],
   "source": [
    "if RUN_GENERATIONS:\n",
    "    print(\"\\n\\n### Model 1\")\n",
    "    print(model_1.action_embedding.weight)\n",
    "    compare_model_vs_data(model_1, game, dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Convergence\n",
    "\n",
    "Synthetic sanity-check: train on a toy 2-step game where the first action strongly determines the winner. This verifies the value head and training loop can learn simple patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3998300578.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mxxx STOP HERE xxx\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "xxx STOP HERE xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_0 = game.initial_state()\n",
    "all_actions_0 = game.all_actions()\n",
    "\n",
    "print(all_actions_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def play_random_game_with_fake_reward(game, max_actions) -> dict:\n",
    "    state = game.initial_state()\n",
    "    action_history = []\n",
    "    legal_policies = []\n",
    "    legal_action_idx_list = []\n",
    "\n",
    "    all_actions = game.all_actions()\n",
    "    all_action_idx_map = {action: idx for idx, action in enumerate(all_actions)}\n",
    "\n",
    "    num_actions = 0\n",
    "    while not game.is_terminal(state) and num_actions < max_actions:\n",
    "        current_player = game.current_player_id(state)\n",
    "        legal_actions = game.legal_actions(state)\n",
    "        action_idx = random.randrange(len(legal_actions))\n",
    "        action = legal_actions[action_idx]\n",
    "\n",
    "        action_history.append(action)\n",
    "        legal_policies.append(np.ones(len(legal_actions))/len(legal_actions))\n",
    "        legal_action_idx = np.array([all_action_idx_map[action] for action in legal_actions])\n",
    "        legal_action_idx_list.append(legal_action_idx)\n",
    "\n",
    "        state = game.next_state(state, action)\n",
    "        num_actions += 1\n",
    "\n",
    "    # Determine outcome\n",
    "    fake_reward = np.mean(action_history) / len(legal_actions)\n",
    "    rewards = np.array([fake_reward, 1.0-fake_reward])\n",
    "    if fake_reward >= 0.5:\n",
    "        winner = 1\n",
    "    else:\n",
    "        winner = 2\n",
    "\n",
    "    return {\n",
    "        \"winner\": winner,\n",
    "        \"rewards\": rewards,\n",
    "        \"action_history\": action_history,\n",
    "        \"legal_policies\": legal_policies,\n",
    "        \"final_state\": state,\n",
    "        \"legal_action_idx\": legal_action_idx_list,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_random_game_with_fake_reward(game, max_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [play_random_game_with_fake_reward(game, max_actions=2) for _ in range(100_000)]\n",
    "print_game_stats(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_gen_name = \"fake-0\"\n",
    "trajectory_path = write_trajectory_dataset(results, action_vocab, fake_gen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_model_config = model_config_dict[MODEL_SIZE]\n",
    "fake_model_config = model_config_dict[\"large\"]\n",
    "fake_model = create_random_model(fake_model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42)\n",
    "\n",
    "training_splits = [f'gen-{fake_gen_name}']\n",
    "fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n",
    "save_model(fake_model, fake_trainer, fake_gen_name)\n",
    "\n",
    "## model_size=tiny\n",
    "# num decayed parameter tensors: 11, with 1,968 parameters\n",
    "# num non-decayed parameter tensors: 7, with 50 parameters\n",
    "# using fused AdamW: False\n",
    "# step 0: train loss 2.7817, val loss 2.7816\n",
    "# iter 0/49/488: loss 2.7821, time 2537.56ms\n",
    "# iter 100/147/488: loss 2.6890, time 53.61ms\n",
    "# iter 200/245/488: loss 2.6342, time 63.05ms\n",
    "# iter 300/343/488: loss 2.6187, time 55.31ms\n",
    "# iter 400/441/488: loss 2.6147, time 61.11ms\n",
    "\n",
    "## model_size=large\n",
    "# num decayed parameter tensors: 35, with 1,579,776 parameters\n",
    "# num non-decayed parameter tensors: 19, with 2,186 parameters\n",
    "# using fused AdamW: False\n",
    "# step 0: train loss 2.8087, val loss 2.8088\n",
    "# iter 0/49/488: loss 2.8099, time 11225.20ms\n",
    "# iter 100/147/488: loss 2.6065, time 596.91ms\n",
    "# iter 200/245/488: loss 2.6075, time 618.00ms\n",
    "# iter 300/343/488: loss 2.6080, time 613.63ms\n",
    "# iter 400/441/488: loss 2.6051, time 616.39ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rerun in range(10):\n",
    "#     print(f\"Re-running training for {fake_gen_name} {rerun+1} of 10\")\n",
    "#     fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n",
    "#     save_model(fake_model, fake_trainer, fake_gen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [td for td in td_array]\n",
    "fake_td_array = [TrajectoryDataset(DATA_DIR, split, block_size=n_max_context) for split in training_splits]\n",
    "fake_unrolled = [(generation+1, d) for generation, td in enumerate(fake_td_array) for d in td]\n",
    "\n",
    "# gen, d = unrolled[0], \n",
    "# d.action[:2]\n",
    "# d.value[0]\n",
    "\n",
    "# Inspect training data\n",
    "fake_dd = defaultdict(lambda: defaultdict(lambda: torch.tensor([0., 0.])))\n",
    "\n",
    "for gen, d in fake_unrolled:\n",
    "    for g in ['*', gen]:    \n",
    "        fake_dd[tuple(tuple(d.action[:0].tolist()))][g] += d.value[0]\n",
    "        fake_dd[tuple(tuple(d.action[:1].tolist()))][g] += d.value[0]\n",
    "        fake_dd[tuple(tuple(d.action[:2].tolist()))][g] += d.value[0]\n",
    "        # fake_dd[tuple(tuple(d.action[:3].tolist()))][g] += d.value[0]\n",
    "\n",
    "print(f\"len(fake_dd) = {len(fake_dd)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_model = load_model(fake_gen_name)\n",
    "compare_model_vs_data(fake_model, game, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_model, fake_trainer = train_model(fake_model, training_splits, train_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
