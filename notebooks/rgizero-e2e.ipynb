{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step run of alphazero self-play & training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports successful\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Game and players\n",
    "from rgi.rgizero.games.connect4 import Connect4Game\n",
    "from rgi.rgizero.players.alphazero import AlphazeroPlayer\n",
    "from rgi.rgizero.players.alphazero import play_game\n",
    "\n",
    "from notebook_utils import reload_local_modules\n",
    "\n",
    "print(\"✅ Imports successful\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "assert device in ('cuda', 'mps'), f\"No accelerator available, device={device}\"\n",
    "\n",
    "# Allow asyncio to work with jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Increase numpy print width\n",
    "np.set_printoptions(linewidth=300)\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data\" / \"rgizero-e2e\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = True     # Set options to make debugger work properly. Single worker, etc.\n",
    "LOAD_MODEL = False\n",
    "MODEL_SIZE = \"small\"  # \"tiny\" or \"small\" or\"large\" or \"xl\"\n",
    "NUM_SIMULATIONS = 50\n",
    "\n",
    "# If False, we still load previous games from disk.\n",
    "PLAY_GAMES = False\n",
    "NUM_GAMES = 1000\n",
    "SAVE_FILE_NAME = f'train_{NUM_GAMES}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up history-wrapped game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using HistoryTrackingGame from module\n",
      "Game: Connect4Game, Players: 2, Actions: [1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "from rgi.rgizero.games.history_wrapper import HistoryTrackingGame\n",
    "from rgi.rgizero.data.trajectory_dataset import Vocab\n",
    "from rgi.rgizero.common import TOKENS\n",
    "\n",
    "base_game, max_game_length = Connect4Game(connect_length=4), 7*6\n",
    "\n",
    "game = HistoryTrackingGame(base_game)\n",
    "state_0 = game.initial_state()\n",
    "block_size = max_game_length + 2\n",
    "action_vocab = Vocab(itos=[TOKENS.START_OF_GAME] + list(base_game.all_actions()))\n",
    "n_max_context = max_game_length + 2\n",
    "\n",
    "print(\"✅ Using HistoryTrackingGame from module\")\n",
    "print(f\"Game: {base_game.__class__.__name__}, Players: {game.num_players(state_0)}, Actions: {list(game.all_actions())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create or load model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "from rgi.rgizero.models.action_history_transformer import ActionHistoryTransformer, ActionHistoryTransformerEvaluator\n",
    "from rgi.rgizero.models.transformer import TransformerConfig\n",
    "\n",
    "model_config_dict = {\n",
    "    \"tiny\": TransformerConfig(n_max_context=n_max_context, n_layer=2, n_head=2, n_embd=8),\n",
    "    \"small\": TransformerConfig(n_max_context=n_max_context, n_layer=4, n_head=4, n_embd=32),\n",
    "    \"large\": TransformerConfig(n_max_context=n_max_context, n_layer=8, n_head=8, n_embd=128),\n",
    "    \"xl\": TransformerConfig(n_max_context=n_max_context, n_layer=16, n_head=16, n_embd=256),\n",
    "}\n",
    "\n",
    "\n",
    "def create_random_model(config: TransformerConfig, action_vocab_size, num_players,  seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed) # Ensure numpy operations are also seeded\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    model = ActionHistoryTransformer(config=config, action_vocab_size=action_vocab_size, num_players=num_players)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "# Make model initialization deterministic\n",
    "model_config = model_config_dict[MODEL_SIZE]\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    raise NotImplementedError(\"Model loading not implemented\")\n",
    "else:\n",
    "    model = create_random_model(model_config, action_vocab_size=action_vocab.vocab_size, num_players=game.num_players(state_0), seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Play games to generate training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "from rgi.rgizero.models.action_history_transformer import AsyncNetworkEvaluator, QueuedNetworkEvaluator, ActionHistoryTransformerEvaluator\n",
    "from rgi.rgizero.players.alphazero import play_game_async\n",
    "\n",
    "async def play_games_async(num_games: int, player_factory):\n",
    "    tasks = []\n",
    "    async def create_player_and_create_game():\n",
    "        t0 = time.time()\n",
    "        player = player_factory()\n",
    "        game_result = await play_game_async(game, [player, player])\n",
    "        t1 = time.time()\n",
    "        game_result['time'] = t1 - t0\n",
    "        return game_result\n",
    "\n",
    "    tasks = [create_player_and_create_game() for _ in range(num_games)]\n",
    "    results = await tqdm.gather(*tasks)   # same as asyncio.gather, but with a progress bar\n",
    "    return results\n",
    "\n",
    "\n",
    "serial_evaluator = ActionHistoryTransformerEvaluator(model, device=device, block_size=block_size, vocab=action_vocab)\n",
    "async_evaluator = AsyncNetworkEvaluator(base_evaluator=serial_evaluator, max_batch_size=1024, verbose=False)\n",
    "\n",
    "master_rng = np.random.default_rng(42)\n",
    "async_evaluator_factory = lambda: AsyncNetworkEvaluator(base_evaluator=serial_evaluator, max_batch_size=1024, verbose=False)\n",
    "async_player_factory = lambda: AlphazeroPlayer(game, async_evaluator, rng=np.random.default_rng(master_rng.integers(0, 2**31)), add_noise=False, simulations=NUM_SIMULATIONS)\n",
    "\n",
    "if PLAY_GAMES:\n",
    "    print(f\"Playing {NUM_GAMES} games, simulations={NUM_SIMULATIONS}, model_size={MODEL_SIZE}\")\n",
    "    await async_evaluator.start()\n",
    "    results = asyncio.run(play_games_async(num_games=NUM_GAMES, player_factory=async_player_factory)) # 50 games, 4.3s\n",
    "    await async_evaluator.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "if PLAY_GAMES:\n",
    "    print(\"Winner by initial move:\")\n",
    "    dd = defaultdict(Counter)\n",
    "    for result in results:\n",
    "        dd[result['action_history'][0]][result['winner']] += 1\n",
    "    for action, counts in sorted(dd.items()):\n",
    "        print(f\"  a={action}: n={sum(counts.values()):3} win[1]={100*counts[1]/sum(counts.values()):.2f}% counts={counts}\")\n",
    "\n",
    "## Resunts from 1000 connect4 games with random model.\n",
    "# Winner by initial move:\n",
    "#   a=1: n=121 win[1]=59.50% counts=Counter({1: 72, 2: 49})\n",
    "#   a=2: n=139 win[1]=58.99% counts=Counter({1: 82, 2: 57})\n",
    "#   a=3: n= 95 win[1]=63.16% counts=Counter({1: 60, 2: 35})\n",
    "#   a=4: n=160 win[1]=78.75% counts=Counter({1: 126, 2: 34})\n",
    "#   a=5: n=146 win[1]=65.07% counts=Counter({1: 95, 2: 51})\n",
    "#   a=6: n=176 win[1]=61.36% counts=Counter({1: 108, 2: 68})\n",
    "#   a=7: n=163 win[1]=53.37% counts=Counter({1: 87, 2: 76})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Confirm we can read & write to trajectory_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: Vocab(vocab_size=8, itos=['START_OF_GAME', 1, 2, 3, 4, 5, 6, 7], stoi={'START_OF_GAME': 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7})\n"
     ]
    }
   ],
   "source": [
    "all_actions = game.all_actions()\n",
    "# num_players = game.num_players(state_0)\n",
    "print(f\"Vocab: {action_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.rgizero.data.trajectory_dataset import TrajectoryDatasetBuilder, TrajectoryDataset, build_trajectory_loader\n",
    "reload_local_modules(verbose=False)\n",
    "\n",
    "def add_trajectory(game_result, vocab, td_builder):\n",
    "    action_history = game_result['action_history']\n",
    "    trajectory_length = len(action_history)\n",
    "    legal_policies = game_result['legal_policies']\n",
    "    legal_action_idx = game_result['legal_action_idx']\n",
    "    rewards = game_result['rewards']\n",
    "\n",
    "    # Translation key for converting legal_action_ids to vocab_action_idx.\n",
    "    action_idx_to_vocab_idx = vocab.encode(all_actions)\n",
    "\n",
    "    fixed_width_policies = np.zeros((trajectory_length, vocab.vocab_size))\n",
    "    for i in range(trajectory_length):\n",
    "        vocab_action_idx = action_idx_to_vocab_idx[legal_action_idx[i]]\n",
    "        fixed_width_policies[i, vocab_action_idx] = legal_policies[i]\n",
    "\n",
    "    encoded_action_history = vocab.encode(action_history)\n",
    "    tiled_rewards = np.tile(rewards, (trajectory_length, 1))  # shape (num_players,) -> (num_moves, num_players)\n",
    "    \n",
    "    td_builder.add_trajectory(actions=encoded_action_history, fixed_width_policies=fixed_width_policies, values=tiled_rewards)\n",
    "\n",
    "if PLAY_GAMES:\n",
    "    td_builder = TrajectoryDatasetBuilder(action_vocab)\n",
    "    for game_result in results:\n",
    "        add_trajectory(game_result, action_vocab, td_builder)\n",
    "\n",
    "    td_builder.save(DATA_DIR, SAVE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner by initial move:\n",
      "  a=1: n=121 win[1]=59.50% counts=Counter({1: 72, 0: 49})\n",
      "  a=2: n=139 win[1]=58.99% counts=Counter({1: 82, 0: 57})\n",
      "  a=3: n= 95 win[1]=63.16% counts=Counter({1: 60, 0: 35})\n",
      "  a=4: n=160 win[1]=78.75% counts=Counter({1: 126, 0: 34})\n",
      "  a=5: n=146 win[1]=65.07% counts=Counter({1: 95, 0: 51})\n",
      "  a=6: n=176 win[1]=61.36% counts=Counter({1: 108, 0: 68})\n",
      "  a=7: n=163 win[1]=53.37% counts=Counter({1: 87, 0: 76})\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "td = TrajectoryDataset(DATA_DIR, SAVE_FILE_NAME, block_size=n_max_context)\n",
    "\n",
    "# Confirm results are the same as the saved result\n",
    "print(\"Winner by initial move:\")\n",
    "dd = defaultdict(Counter)\n",
    "for _td in td:\n",
    "    action, winner = int(_td.action[0]), int(_td.value[0][0])\n",
    "    dd[action][winner] += 1\n",
    "for action, counts in sorted(dd.items()):\n",
    "    print(f\"  a={action}: n={sum(counts.values()):3} win[1]={100*counts[1]/sum(counts.values()):.2f}% counts={counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[6, 2, 2, 5, 4, 5, 6, 7, 3, 7, 2, 4, 6, 4, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='mps:0'), tensor([[[0.0000, 0.1200, 0.1600, 0.1000, 0.1600, 0.1400, 0.1600, 0.1600],\n",
      "         [0.0000, 0.1400, 0.1600, 0.1600, 0.1200, 0.1400, 0.1400, 0.1400],\n",
      "         [0.0000, 0.1400, 0.1800, 0.1000, 0.1600, 0.1400, 0.1400, 0.1400],\n",
      "         [0.0000, 0.1400, 0.1800, 0.1600, 0.1200, 0.1200, 0.1200, 0.1600],\n",
      "         [0.0000, 0.1200, 0.1400, 0.1000, 0.1600, 0.1800, 0.1600, 0.1400],\n",
      "         [0.0000, 0.1200, 0.1400, 0.1400, 0.1800, 0.1400, 0.1200, 0.1600],\n",
      "         [0.0000, 0.1200, 0.1400, 0.1000, 0.1800, 0.1800, 0.1400, 0.1400],\n",
      "         [0.0000, 0.1400, 0.1600, 0.1600, 0.1200, 0.1400, 0.1400, 0.1400],\n",
      "         [0.0000, 0.1400, 0.1400, 0.1200, 0.1600, 0.1200, 0.1400, 0.1800],\n",
      "         [0.0000, 0.1400, 0.1600, 0.2000, 0.1000, 0.1400, 0.1200, 0.1400],\n",
      "         [0.0000, 0.1400, 0.1400, 0.1200, 0.1600, 0.1400, 0.1200, 0.1800],\n",
      "         [0.0000, 0.1400, 0.1800, 0.1600, 0.1200, 0.1200, 0.1200, 0.1600],\n",
      "         [0.0000, 0.1200, 0.1400, 0.0600, 0.2200, 0.1600, 0.1600, 0.1400],\n",
      "         [0.0000, 0.1400, 0.1600, 0.1600, 0.1200, 0.1400, 0.1400, 0.1400],\n",
      "         [0.0000, 0.0200, 0.0200, 0.0200, 0.0600, 0.0400, 0.8000, 0.0400],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       device='mps:0'), tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]], device='mps:0'))\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0 if DEBUG_MODE else 4\n",
    "trajectory_loader = build_trajectory_loader(\n",
    "    DATA_DIR, 'train_1000', block_size=n_max_context, batch_size=1,\n",
    "    device=device, workers=num_workers)\n",
    "\n",
    "for batch in trajectory_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 19, with 50,880 parameters\n",
      "num non-decayed parameter tensors: 11, with 298 parameters\n",
      "using fused AdamW: False\n",
      "Training epoch 0 of 10\n",
      "step 0: train loss 0.8128, val loss 0.8128\n",
      "iter 0: loss 0.7794, time 792.16ms\n",
      "iter 1: loss 1.6183, time 7.74ms\n",
      "iter 2: loss 0.4326, time 6.95ms\n",
      "iter 3: loss 1.3040, time 6.40ms\n",
      "iter 4: loss 1.0372, time 6.58ms\n",
      "iter 5: loss 1.4384, time 7.12ms\n",
      "iter 6: loss 1.3079, time 8.08ms\n",
      "iter 7: loss 0.9865, time 8.16ms\n",
      "iter 8: loss 0.3495, time 7.12ms\n",
      "iter 9: loss 1.1092, time 6.55ms\n",
      "iter 10: loss 1.0887, time 6.86ms\n",
      "iter 11: loss 0.4655, time 6.50ms\n",
      "iter 12: loss 0.8519, time 6.39ms\n",
      "iter 13: loss 1.5544, time 6.48ms\n",
      "iter 14: loss 0.3656, time 6.58ms\n",
      "iter 15: loss 0.5265, time 6.70ms\n",
      "iter 16: loss 0.5587, time 6.67ms\n",
      "iter 17: loss 0.7661, time 7.34ms\n",
      "iter 18: loss 0.3337, time 7.52ms\n",
      "iter 19: loss 0.7274, time 7.84ms\n",
      "iter 20: loss 1.4903, time 6.89ms\n",
      "iter 21: loss 1.4640, time 6.62ms\n",
      "iter 22: loss 2.0755, time 7.19ms\n",
      "iter 23: loss 0.8484, time 6.47ms\n",
      "iter 24: loss 0.8645, time 6.52ms\n",
      "iter 25: loss 1.2074, time 7.24ms\n",
      "iter 26: loss 1.1854, time 7.52ms\n",
      "iter 27: loss 0.5371, time 7.09ms\n",
      "iter 28: loss 0.6644, time 6.90ms\n",
      "iter 29: loss 1.0052, time 7.62ms\n",
      "iter 30: loss 1.1478, time 6.69ms\n",
      "iter 31: loss 1.4111, time 6.58ms\n",
      "iter 32: loss 0.6522, time 6.48ms\n",
      "iter 33: loss 0.5807, time 6.65ms\n",
      "iter 34: loss 0.4369, time 6.50ms\n",
      "iter 35: loss 0.4336, time 6.45ms\n",
      "iter 36: loss 0.8764, time 6.54ms\n",
      "iter 37: loss 2.3020, time 6.55ms\n",
      "iter 38: loss 0.8563, time 6.51ms\n",
      "iter 39: loss 1.0303, time 6.58ms\n",
      "iter 40: loss 0.7586, time 6.50ms\n",
      "iter 41: loss 0.3513, time 6.57ms\n",
      "iter 42: loss 0.4846, time 6.49ms\n",
      "iter 43: loss 1.5611, time 6.93ms\n",
      "iter 44: loss 0.8921, time 6.93ms\n",
      "iter 45: loss 0.5388, time 6.45ms\n",
      "iter 46: loss 1.3159, time 6.49ms\n",
      "iter 47: loss 0.3386, time 6.38ms\n",
      "iter 48: loss 0.6058, time 6.45ms\n",
      "iter 49: loss 1.5737, time 6.47ms\n",
      "iter 50: loss 0.9759, time 6.88ms\n",
      "iter 51: loss 0.5341, time 8.21ms\n",
      "iter 52: loss 0.9892, time 7.33ms\n",
      "iter 53: loss 1.2617, time 6.69ms\n",
      "iter 54: loss 0.9023, time 6.78ms\n",
      "iter 55: loss 0.5609, time 7.37ms\n",
      "iter 56: loss 0.4710, time 6.88ms\n",
      "iter 57: loss 0.5481, time 6.60ms\n",
      "iter 58: loss 0.3536, time 6.52ms\n",
      "iter 59: loss 1.3087, time 6.78ms\n",
      "iter 60: loss 0.4576, time 6.58ms\n",
      "iter 61: loss 0.4613, time 6.78ms\n",
      "iter 62: loss 1.2891, time 6.69ms\n",
      "iter 63: loss 0.8596, time 7.19ms\n",
      "iter 64: loss 1.2795, time 6.90ms\n",
      "iter 65: loss 0.9752, time 6.66ms\n",
      "iter 66: loss 1.4822, time 6.69ms\n",
      "iter 67: loss 0.5546, time 7.57ms\n",
      "iter 68: loss 0.6481, time 6.62ms\n",
      "iter 69: loss 1.4308, time 7.14ms\n",
      "iter 70: loss 0.7619, time 6.54ms\n",
      "iter 71: loss 0.5154, time 7.35ms\n",
      "iter 72: loss 0.4316, time 6.85ms\n",
      "iter 73: loss 0.7289, time 6.96ms\n",
      "iter 74: loss 0.9873, time 6.87ms\n",
      "iter 75: loss 0.9633, time 8.39ms\n",
      "iter 76: loss 0.9844, time 6.86ms\n",
      "iter 77: loss 1.1612, time 6.84ms\n",
      "iter 78: loss 0.9976, time 7.34ms\n",
      "iter 79: loss 0.8744, time 8.03ms\n",
      "iter 80: loss 0.8677, time 6.67ms\n",
      "iter 81: loss 1.0846, time 6.78ms\n",
      "iter 82: loss 0.7670, time 6.88ms\n",
      "iter 83: loss 0.6580, time 6.71ms\n",
      "iter 84: loss 1.0857, time 6.55ms\n",
      "iter 85: loss 0.4588, time 6.44ms\n",
      "iter 86: loss 1.5289, time 7.09ms\n",
      "iter 87: loss 0.6484, time 7.04ms\n",
      "iter 88: loss 0.8991, time 6.77ms\n",
      "iter 89: loss 0.5145, time 6.73ms\n",
      "iter 90: loss 0.5947, time 6.85ms\n",
      "iter 91: loss 0.7616, time 6.95ms\n",
      "iter 92: loss 0.6644, time 6.87ms\n",
      "iter 93: loss 0.3483, time 6.91ms\n",
      "iter 94: loss 0.8855, time 7.18ms\n",
      "iter 95: loss 1.2651, time 7.79ms\n",
      "iter 96: loss 0.3506, time 7.14ms\n",
      "iter 97: loss 0.5617, time 7.30ms\n",
      "iter 98: loss 0.3637, time 7.16ms\n",
      "iter 99: loss 0.7657, time 7.85ms\n",
      "iter 100: loss 0.5647, time 7.82ms\n",
      "iter 101: loss 1.2820, time 7.06ms\n",
      "iter 102: loss 0.8742, time 7.30ms\n",
      "iter 103: loss 1.1887, time 7.42ms\n",
      "iter 104: loss 0.9463, time 7.16ms\n",
      "iter 105: loss 0.7520, time 6.94ms\n",
      "iter 106: loss 0.7431, time 7.30ms\n",
      "iter 107: loss 0.3569, time 7.23ms\n",
      "iter 108: loss 0.5488, time 7.28ms\n",
      "iter 109: loss 0.8465, time 6.76ms\n",
      "iter 110: loss 0.6805, time 6.94ms\n",
      "iter 111: loss 0.5557, time 6.87ms\n",
      "iter 112: loss 0.4638, time 6.94ms\n",
      "iter 113: loss 0.8337, time 6.86ms\n",
      "iter 114: loss 0.9689, time 6.78ms\n",
      "iter 115: loss 0.7285, time 7.77ms\n",
      "iter 116: loss 0.8585, time 6.86ms\n",
      "iter 117: loss 0.4545, time 7.52ms\n",
      "iter 118: loss 0.4843, time 6.76ms\n",
      "iter 119: loss 0.5477, time 7.65ms\n",
      "iter 120: loss 0.9484, time 6.65ms\n",
      "iter 121: loss 1.0102, time 6.67ms\n",
      "iter 122: loss 1.1799, time 6.85ms\n",
      "iter 123: loss 0.8511, time 7.38ms\n",
      "iter 124: loss 0.4324, time 7.57ms\n",
      "iter 125: loss 0.8986, time 7.21ms\n",
      "iter 126: loss 0.3464, time 7.21ms\n",
      "iter 127: loss 1.0407, time 7.05ms\n",
      "iter 128: loss 0.9492, time 6.74ms\n",
      "iter 129: loss 1.4014, time 6.60ms\n",
      "iter 130: loss 0.7414, time 6.58ms\n",
      "iter 131: loss 0.5332, time 6.20ms\n",
      "iter 132: loss 0.5870, time 6.11ms\n",
      "iter 133: loss 0.3414, time 6.18ms\n",
      "iter 134: loss 0.4409, time 6.01ms\n",
      "iter 135: loss 0.3370, time 6.21ms\n",
      "iter 136: loss 1.1624, time 6.05ms\n",
      "iter 137: loss 1.0004, time 6.05ms\n",
      "iter 138: loss 1.3866, time 6.21ms\n",
      "iter 139: loss 0.3281, time 6.39ms\n",
      "iter 140: loss 0.3450, time 6.30ms\n",
      "iter 141: loss 0.4474, time 6.22ms\n",
      "iter 142: loss 0.7407, time 6.13ms\n",
      "iter 143: loss 0.8233, time 6.23ms\n",
      "iter 144: loss 1.3235, time 6.20ms\n",
      "iter 145: loss 1.0451, time 6.36ms\n",
      "iter 146: loss 0.9522, time 6.20ms\n",
      "iter 147: loss 0.8298, time 6.01ms\n",
      "iter 148: loss 0.4484, time 6.39ms\n",
      "iter 149: loss 1.2944, time 6.25ms\n",
      "iter 150: loss 1.3274, time 7.44ms\n",
      "iter 151: loss 0.3450, time 6.24ms\n",
      "iter 152: loss 0.6626, time 6.17ms\n",
      "iter 153: loss 2.0466, time 6.57ms\n",
      "iter 154: loss 0.5191, time 6.55ms\n",
      "iter 155: loss 0.7247, time 6.16ms\n",
      "iter 156: loss 0.6745, time 6.32ms\n",
      "iter 157: loss 0.6489, time 6.05ms\n",
      "iter 158: loss 0.3464, time 6.29ms\n",
      "iter 159: loss 0.8079, time 6.17ms\n",
      "iter 160: loss 0.5648, time 6.48ms\n",
      "iter 161: loss 0.5040, time 6.29ms\n",
      "iter 162: loss 0.7592, time 6.30ms\n",
      "iter 163: loss 0.5654, time 6.12ms\n",
      "iter 164: loss 1.4522, time 6.30ms\n",
      "iter 165: loss 1.2390, time 6.20ms\n",
      "iter 166: loss 0.6882, time 6.39ms\n",
      "iter 167: loss 0.4082, time 6.28ms\n",
      "iter 168: loss 0.9300, time 6.09ms\n",
      "iter 169: loss 0.4865, time 6.09ms\n",
      "iter 170: loss 1.6971, time 6.13ms\n",
      "iter 171: loss 1.0126, time 6.37ms\n",
      "iter 172: loss 0.8139, time 6.10ms\n",
      "iter 173: loss 0.5138, time 6.19ms\n",
      "iter 174: loss 1.0124, time 6.29ms\n",
      "iter 175: loss 1.0356, time 6.40ms\n",
      "iter 176: loss 0.3675, time 7.22ms\n",
      "iter 177: loss 0.6808, time 7.25ms\n",
      "iter 178: loss 0.7863, time 6.57ms\n",
      "iter 179: loss 0.3411, time 6.48ms\n",
      "iter 180: loss 0.8263, time 6.47ms\n",
      "iter 181: loss 0.6689, time 6.43ms\n",
      "iter 182: loss 0.3928, time 6.22ms\n",
      "iter 183: loss 0.7595, time 6.15ms\n",
      "iter 184: loss 0.5511, time 6.51ms\n",
      "iter 185: loss 0.3935, time 6.19ms\n",
      "iter 186: loss 0.8534, time 6.40ms\n",
      "iter 187: loss 1.0801, time 6.34ms\n",
      "iter 188: loss 0.3713, time 6.34ms\n",
      "iter 189: loss 0.4482, time 6.22ms\n",
      "iter 190: loss 0.4294, time 6.09ms\n",
      "iter 191: loss 0.7816, time 6.48ms\n",
      "iter 192: loss 0.5389, time 6.26ms\n",
      "iter 193: loss 0.3471, time 6.13ms\n",
      "iter 194: loss 0.4393, time 6.18ms\n",
      "iter 195: loss 0.6410, time 6.49ms\n",
      "iter 196: loss 0.5216, time 6.19ms\n",
      "iter 197: loss 0.5197, time 6.19ms\n",
      "iter 198: loss 0.3415, time 6.13ms\n",
      "iter 199: loss 1.1479, time 6.13ms\n",
      "iter 200: loss 0.3396, time 6.49ms\n",
      "iter 201: loss 1.1227, time 6.50ms\n",
      "iter 202: loss 0.7141, time 8.84ms\n",
      "iter 203: loss 0.8223, time 7.69ms\n",
      "iter 204: loss 0.7148, time 6.46ms\n",
      "iter 205: loss 0.5665, time 6.64ms\n",
      "iter 206: loss 1.7549, time 6.45ms\n",
      "iter 207: loss 1.2230, time 6.09ms\n",
      "iter 208: loss 0.4352, time 6.57ms\n",
      "iter 209: loss 0.8915, time 6.49ms\n",
      "iter 210: loss 0.6756, time 6.42ms\n",
      "iter 211: loss 0.8666, time 6.36ms\n",
      "iter 212: loss 0.9306, time 6.20ms\n",
      "iter 213: loss 0.6857, time 6.63ms\n",
      "iter 214: loss 0.9451, time 6.62ms\n",
      "iter 215: loss 0.4289, time 7.08ms\n",
      "iter 216: loss 0.8463, time 7.27ms\n",
      "iter 217: loss 1.1793, time 6.97ms\n",
      "iter 218: loss 0.8194, time 6.56ms\n",
      "iter 219: loss 1.0065, time 6.82ms\n",
      "iter 220: loss 1.6536, time 7.15ms\n",
      "iter 221: loss 0.7293, time 6.87ms\n",
      "iter 222: loss 1.4484, time 6.66ms\n",
      "iter 223: loss 1.0908, time 7.11ms\n",
      "iter 224: loss 0.7876, time 7.65ms\n",
      "iter 225: loss 0.7861, time 7.05ms\n",
      "iter 226: loss 0.9737, time 6.94ms\n",
      "iter 227: loss 0.9437, time 7.72ms\n",
      "iter 228: loss 2.1092, time 7.37ms\n",
      "iter 229: loss 1.2779, time 7.69ms\n",
      "iter 230: loss 0.5425, time 6.40ms\n",
      "iter 231: loss 1.4948, time 7.13ms\n",
      "iter 232: loss 1.3903, time 6.64ms\n",
      "iter 233: loss 0.3502, time 7.49ms\n",
      "iter 234: loss 0.3407, time 7.03ms\n",
      "iter 235: loss 0.5623, time 6.54ms\n",
      "iter 236: loss 0.6666, time 6.43ms\n",
      "iter 237: loss 1.2050, time 6.29ms\n",
      "iter 238: loss 1.6296, time 6.50ms\n",
      "iter 239: loss 0.3413, time 7.16ms\n",
      "iter 240: loss 1.1828, time 8.34ms\n",
      "iter 241: loss 0.4513, time 7.39ms\n",
      "iter 242: loss 1.4600, time 6.71ms\n",
      "iter 243: loss 1.6668, time 7.64ms\n",
      "iter 244: loss 1.4034, time 6.44ms\n",
      "iter 245: loss 0.3437, time 6.28ms\n",
      "iter 246: loss 0.9709, time 6.37ms\n",
      "iter 247: loss 0.6524, time 6.46ms\n",
      "iter 248: loss 1.3294, time 6.08ms\n",
      "iter 249: loss 1.4427, time 6.29ms\n",
      "step 250: train loss 0.8168, val loss 0.8168\n",
      "iter 250: loss 0.7730, time 716.05ms\n",
      "iter 251: loss 1.5866, time 7.90ms\n",
      "iter 252: loss 0.9997, time 6.90ms\n",
      "iter 253: loss 0.4573, time 7.00ms\n",
      "iter 254: loss 0.5638, time 6.81ms\n",
      "iter 255: loss 1.0732, time 6.62ms\n",
      "iter 256: loss 0.3438, time 6.68ms\n",
      "iter 257: loss 0.4614, time 7.58ms\n",
      "iter 258: loss 0.9949, time 7.12ms\n",
      "iter 259: loss 1.4408, time 6.97ms\n",
      "iter 260: loss 0.8611, time 7.08ms\n",
      "iter 261: loss 0.3526, time 6.94ms\n",
      "iter 262: loss 0.9481, time 7.00ms\n",
      "iter 263: loss 0.4619, time 7.80ms\n",
      "iter 264: loss 0.8713, time 7.16ms\n",
      "iter 265: loss 0.7788, time 6.68ms\n",
      "iter 266: loss 0.9042, time 6.98ms\n",
      "iter 267: loss 0.6563, time 7.55ms\n",
      "iter 268: loss 0.7752, time 7.89ms\n",
      "iter 269: loss 1.5995, time 7.56ms\n",
      "iter 270: loss 0.7638, time 7.91ms\n",
      "iter 271: loss 0.3499, time 7.53ms\n",
      "iter 272: loss 0.8849, time 7.49ms\n",
      "iter 273: loss 0.9375, time 7.84ms\n",
      "iter 274: loss 1.1573, time 7.69ms\n",
      "iter 275: loss 0.3547, time 7.38ms\n",
      "iter 276: loss 0.5466, time 7.75ms\n",
      "iter 277: loss 0.5572, time 7.14ms\n",
      "iter 278: loss 1.0544, time 7.10ms\n",
      "iter 279: loss 0.4370, time 7.44ms\n",
      "iter 280: loss 0.5901, time 7.67ms\n",
      "iter 281: loss 1.1445, time 7.79ms\n",
      "iter 282: loss 1.6238, time 6.96ms\n",
      "iter 283: loss 0.3459, time 7.34ms\n",
      "iter 284: loss 1.2205, time 7.61ms\n",
      "iter 285: loss 0.9412, time 7.84ms\n",
      "iter 286: loss 0.8713, time 7.92ms\n",
      "iter 287: loss 1.7552, time 7.46ms\n",
      "iter 288: loss 0.7501, time 7.99ms\n",
      "iter 289: loss 1.4903, time 8.32ms\n",
      "iter 290: loss 1.1943, time 7.59ms\n",
      "iter 291: loss 1.5859, time 7.67ms\n",
      "iter 292: loss 0.6789, time 7.64ms\n",
      "iter 293: loss 1.5235, time 7.07ms\n",
      "iter 294: loss 1.1742, time 7.28ms\n",
      "iter 295: loss 0.5683, time 8.28ms\n",
      "iter 296: loss 1.4485, time 7.76ms\n",
      "iter 297: loss 1.4360, time 7.57ms\n",
      "iter 298: loss 0.8816, time 7.81ms\n",
      "iter 299: loss 1.1277, time 7.66ms\n",
      "iter 300: loss 0.5566, time 7.02ms\n",
      "iter 301: loss 0.4640, time 6.86ms\n",
      "iter 302: loss 1.1354, time 7.54ms\n",
      "iter 303: loss 0.4616, time 7.55ms\n",
      "iter 304: loss 1.2115, time 7.03ms\n",
      "iter 305: loss 0.6498, time 7.18ms\n",
      "iter 306: loss 1.0860, time 8.02ms\n",
      "iter 307: loss 0.9381, time 7.70ms\n",
      "iter 308: loss 0.7830, time 6.74ms\n",
      "iter 309: loss 0.3601, time 7.81ms\n",
      "iter 310: loss 0.9188, time 7.20ms\n",
      "iter 311: loss 0.7503, time 6.63ms\n",
      "iter 312: loss 1.1546, time 6.98ms\n",
      "iter 313: loss 0.9977, time 7.51ms\n",
      "iter 314: loss 1.6754, time 7.19ms\n",
      "iter 315: loss 0.5701, time 6.80ms\n",
      "iter 316: loss 0.9985, time 6.85ms\n",
      "iter 317: loss 1.2358, time 7.10ms\n",
      "iter 318: loss 0.4584, time 7.61ms\n",
      "iter 319: loss 0.6812, time 7.25ms\n",
      "iter 320: loss 1.3927, time 7.32ms\n",
      "iter 321: loss 0.8017, time 7.67ms\n",
      "iter 322: loss 1.1306, time 6.87ms\n",
      "iter 323: loss 0.4669, time 6.78ms\n",
      "iter 324: loss 0.5596, time 6.50ms\n",
      "iter 325: loss 0.9292, time 6.35ms\n",
      "iter 326: loss 1.7757, time 6.31ms\n",
      "iter 327: loss 0.9408, time 6.60ms\n",
      "iter 328: loss 0.9855, time 6.54ms\n",
      "iter 329: loss 0.7055, time 6.63ms\n",
      "iter 330: loss 0.6708, time 6.47ms\n",
      "iter 331: loss 1.9569, time 6.46ms\n",
      "iter 332: loss 1.5529, time 6.51ms\n",
      "iter 333: loss 1.7356, time 6.70ms\n",
      "iter 334: loss 0.3564, time 8.00ms\n",
      "iter 335: loss 0.8443, time 7.01ms\n",
      "iter 336: loss 0.7886, time 6.19ms\n",
      "iter 337: loss 0.9323, time 6.42ms\n",
      "iter 338: loss 0.9095, time 6.86ms\n",
      "iter 339: loss 0.5050, time 6.61ms\n",
      "iter 340: loss 0.6711, time 6.30ms\n",
      "iter 341: loss 0.6861, time 6.46ms\n",
      "iter 342: loss 1.0510, time 6.45ms\n",
      "iter 343: loss 1.0102, time 6.76ms\n",
      "iter 344: loss 1.2794, time 6.70ms\n",
      "iter 345: loss 0.4613, time 7.14ms\n",
      "iter 346: loss 1.1946, time 7.65ms\n",
      "iter 347: loss 0.8598, time 7.44ms\n",
      "iter 348: loss 0.9806, time 6.68ms\n",
      "iter 349: loss 1.1269, time 6.74ms\n",
      "iter 350: loss 1.0752, time 6.67ms\n",
      "iter 351: loss 0.7744, time 6.84ms\n",
      "iter 352: loss 1.4005, time 6.74ms\n",
      "iter 353: loss 0.7259, time 6.85ms\n",
      "iter 354: loss 1.0937, time 6.83ms\n",
      "iter 355: loss 1.1378, time 7.04ms\n",
      "iter 356: loss 0.5742, time 6.77ms\n",
      "iter 357: loss 0.7027, time 6.80ms\n",
      "iter 358: loss 0.8168, time 6.43ms\n",
      "iter 359: loss 1.1066, time 6.30ms\n",
      "iter 360: loss 1.3524, time 6.27ms\n",
      "iter 361: loss 0.6838, time 6.57ms\n",
      "iter 362: loss 1.1617, time 6.48ms\n",
      "iter 363: loss 0.8142, time 6.49ms\n",
      "iter 364: loss 0.7977, time 6.36ms\n",
      "iter 365: loss 0.5810, time 6.75ms\n",
      "iter 366: loss 1.1148, time 7.23ms\n",
      "iter 367: loss 0.4854, time 6.80ms\n",
      "iter 368: loss 0.8076, time 6.41ms\n",
      "iter 369: loss 0.7963, time 6.49ms\n",
      "iter 370: loss 1.5295, time 6.73ms\n",
      "iter 371: loss 0.7900, time 6.96ms\n",
      "iter 372: loss 0.5776, time 6.92ms\n",
      "iter 373: loss 0.5754, time 6.45ms\n",
      "iter 374: loss 0.8144, time 6.33ms\n",
      "iter 375: loss 0.4605, time 6.41ms\n",
      "iter 376: loss 1.3849, time 6.45ms\n",
      "iter 377: loss 1.1026, time 6.29ms\n",
      "iter 378: loss 0.3575, time 6.39ms\n",
      "iter 379: loss 0.8713, time 6.28ms\n",
      "iter 380: loss 1.2498, time 6.21ms\n",
      "iter 381: loss 1.2842, time 6.13ms\n",
      "iter 382: loss 0.8949, time 6.38ms\n",
      "iter 383: loss 1.5675, time 6.12ms\n",
      "iter 384: loss 1.5979, time 6.24ms\n",
      "iter 385: loss 1.6527, time 6.33ms\n",
      "iter 386: loss 0.6637, time 7.47ms\n",
      "iter 387: loss 0.8299, time 8.04ms\n",
      "iter 388: loss 1.5062, time 7.01ms\n",
      "iter 389: loss 0.4646, time 7.01ms\n",
      "iter 390: loss 0.9755, time 7.16ms\n",
      "iter 391: loss 0.9708, time 6.52ms\n",
      "iter 392: loss 1.9449, time 6.23ms\n",
      "iter 393: loss 0.9757, time 6.76ms\n",
      "iter 394: loss 0.6959, time 6.87ms\n",
      "iter 395: loss 1.0970, time 7.33ms\n",
      "iter 396: loss 0.6710, time 6.61ms\n",
      "iter 397: loss 0.5141, time 7.46ms\n",
      "iter 398: loss 0.6764, time 6.96ms\n",
      "iter 399: loss 0.6732, time 6.31ms\n",
      "iter 400: loss 2.1686, time 6.42ms\n",
      "iter 401: loss 1.5990, time 6.47ms\n",
      "iter 402: loss 1.1091, time 6.51ms\n",
      "iter 403: loss 0.4520, time 6.54ms\n",
      "iter 404: loss 0.9202, time 6.63ms\n",
      "iter 405: loss 0.9883, time 6.70ms\n",
      "iter 406: loss 0.5713, time 6.67ms\n",
      "iter 407: loss 0.4860, time 6.85ms\n",
      "iter 408: loss 1.1557, time 7.38ms\n",
      "iter 409: loss 1.0646, time 6.96ms\n",
      "iter 410: loss 1.1825, time 6.71ms\n",
      "iter 411: loss 0.4449, time 6.87ms\n",
      "iter 412: loss 0.4567, time 7.45ms\n",
      "iter 413: loss 0.3542, time 6.74ms\n",
      "iter 414: loss 0.8786, time 6.48ms\n",
      "iter 415: loss 0.7651, time 6.61ms\n",
      "iter 416: loss 0.4384, time 6.90ms\n",
      "iter 417: loss 1.4348, time 6.81ms\n",
      "iter 418: loss 0.7575, time 6.89ms\n",
      "iter 419: loss 0.6382, time 6.63ms\n",
      "iter 420: loss 0.7667, time 6.43ms\n",
      "iter 421: loss 1.3971, time 7.16ms\n",
      "iter 422: loss 0.5502, time 6.95ms\n",
      "iter 423: loss 1.3712, time 6.28ms\n",
      "iter 424: loss 1.1282, time 6.32ms\n",
      "iter 425: loss 0.3281, time 6.47ms\n",
      "iter 426: loss 1.0534, time 6.56ms\n",
      "iter 427: loss 0.4441, time 6.46ms\n",
      "iter 428: loss 0.8169, time 6.30ms\n",
      "iter 429: loss 0.5399, time 6.30ms\n",
      "iter 430: loss 1.3944, time 6.29ms\n",
      "iter 431: loss 0.5424, time 6.29ms\n",
      "iter 432: loss 0.4416, time 6.53ms\n",
      "iter 433: loss 1.0792, time 6.56ms\n",
      "iter 434: loss 0.4402, time 6.34ms\n",
      "iter 435: loss 0.8010, time 6.20ms\n",
      "iter 436: loss 0.3401, time 6.26ms\n",
      "iter 437: loss 0.5386, time 6.17ms\n",
      "iter 438: loss 0.8357, time 6.18ms\n",
      "iter 439: loss 1.4191, time 6.12ms\n",
      "iter 440: loss 0.6052, time 6.09ms\n",
      "iter 441: loss 0.9713, time 6.10ms\n",
      "iter 442: loss 1.6110, time 6.21ms\n",
      "iter 443: loss 0.8336, time 6.24ms\n",
      "iter 444: loss 0.5388, time 8.57ms\n",
      "iter 445: loss 0.4390, time 8.24ms\n",
      "iter 446: loss 0.5390, time 8.81ms\n",
      "iter 447: loss 0.9347, time 9.45ms\n",
      "iter 448: loss 1.0277, time 7.71ms\n",
      "iter 449: loss 0.5236, time 8.97ms\n",
      "iter 450: loss 1.2293, time 8.82ms\n",
      "iter 451: loss 1.8522, time 7.05ms\n",
      "iter 452: loss 0.7383, time 9.07ms\n",
      "iter 453: loss 0.6387, time 8.47ms\n",
      "iter 454: loss 0.9466, time 8.62ms\n",
      "iter 455: loss 0.9651, time 8.40ms\n",
      "iter 456: loss 0.8204, time 8.47ms\n",
      "iter 457: loss 1.3450, time 8.44ms\n",
      "iter 458: loss 0.8322, time 8.46ms\n",
      "iter 459: loss 0.7180, time 9.01ms\n",
      "iter 460: loss 0.8372, time 8.57ms\n",
      "iter 461: loss 0.5301, time 8.40ms\n",
      "iter 462: loss 0.6158, time 8.51ms\n",
      "iter 463: loss 1.1430, time 8.38ms\n",
      "iter 464: loss 0.4217, time 8.62ms\n",
      "iter 465: loss 0.6313, time 8.75ms\n",
      "iter 466: loss 0.5297, time 8.97ms\n",
      "iter 467: loss 0.4317, time 8.56ms\n",
      "iter 468: loss 0.5738, time 7.34ms\n",
      "iter 469: loss 0.9779, time 6.74ms\n",
      "iter 470: loss 1.1483, time 6.42ms\n",
      "iter 471: loss 1.1386, time 6.82ms\n",
      "iter 472: loss 0.5150, time 6.70ms\n",
      "iter 473: loss 1.1173, time 6.72ms\n",
      "iter 474: loss 0.9264, time 9.00ms\n",
      "iter 475: loss 0.4327, time 7.75ms\n",
      "iter 476: loss 0.7353, time 13.35ms\n",
      "iter 477: loss 1.4970, time 8.68ms\n",
      "iter 478: loss 0.8322, time 9.10ms\n",
      "iter 479: loss 0.9978, time 36.89ms\n",
      "iter 480: loss 1.6258, time 13.98ms\n",
      "iter 481: loss 1.3326, time 7.42ms\n",
      "iter 482: loss 1.4758, time 7.91ms\n",
      "iter 483: loss 1.4453, time 7.83ms\n",
      "iter 484: loss 0.4399, time 8.62ms\n",
      "iter 485: loss 1.5509, time 8.59ms\n",
      "iter 486: loss 1.0474, time 7.81ms\n",
      "iter 487: loss 0.9305, time 8.63ms\n",
      "iter 488: loss 0.5986, time 8.41ms\n",
      "iter 489: loss 0.4464, time 8.18ms\n",
      "iter 490: loss 0.9170, time 8.55ms\n",
      "iter 491: loss 1.1400, time 8.17ms\n",
      "iter 492: loss 1.5226, time 8.30ms\n",
      "iter 493: loss 0.5462, time 8.02ms\n",
      "iter 494: loss 0.8505, time 8.29ms\n",
      "iter 495: loss 0.4419, time 8.41ms\n",
      "iter 496: loss 0.4505, time 7.63ms\n",
      "iter 497: loss 0.5475, time 7.15ms\n",
      "iter 498: loss 0.6479, time 6.97ms\n",
      "iter 499: loss 1.0160, time 7.03ms\n",
      "step 500: train loss 0.8209, val loss 0.8209\n",
      "iter 500: loss 0.5479, time 936.81ms\n",
      "iter 501: loss 0.5652, time 8.29ms\n",
      "iter 502: loss 0.6105, time 8.19ms\n",
      "iter 503: loss 0.5340, time 7.63ms\n",
      "iter 504: loss 0.6807, time 7.35ms\n",
      "iter 505: loss 0.9358, time 7.48ms\n",
      "iter 506: loss 1.1485, time 7.82ms\n",
      "iter 507: loss 0.6381, time 7.15ms\n",
      "iter 508: loss 0.5675, time 6.90ms\n",
      "iter 509: loss 0.7370, time 7.00ms\n",
      "iter 510: loss 0.3414, time 7.97ms\n",
      "iter 511: loss 0.5399, time 7.54ms\n",
      "iter 512: loss 1.5302, time 7.88ms\n",
      "iter 513: loss 0.6341, time 7.91ms\n",
      "iter 514: loss 0.6410, time 8.00ms\n",
      "iter 515: loss 0.9964, time 7.97ms\n",
      "iter 516: loss 0.5749, time 8.11ms\n",
      "iter 517: loss 1.4352, time 7.41ms\n",
      "iter 518: loss 0.3411, time 7.23ms\n",
      "iter 519: loss 0.7257, time 6.95ms\n",
      "iter 520: loss 0.6085, time 6.91ms\n",
      "iter 521: loss 1.3740, time 7.44ms\n",
      "iter 522: loss 0.8539, time 7.25ms\n",
      "iter 523: loss 1.5662, time 7.62ms\n",
      "iter 524: loss 0.9210, time 7.17ms\n",
      "iter 525: loss 0.6065, time 7.51ms\n",
      "iter 526: loss 0.5414, time 7.33ms\n",
      "iter 527: loss 1.4512, time 6.69ms\n",
      "iter 528: loss 0.4444, time 6.62ms\n",
      "iter 529: loss 0.6405, time 6.72ms\n",
      "iter 530: loss 0.6199, time 6.59ms\n",
      "iter 531: loss 0.6420, time 6.46ms\n",
      "iter 532: loss 0.9919, time 6.68ms\n",
      "iter 533: loss 0.9454, time 6.58ms\n",
      "iter 534: loss 0.5354, time 6.70ms\n",
      "iter 535: loss 0.7793, time 6.42ms\n",
      "iter 536: loss 1.2011, time 6.60ms\n",
      "iter 537: loss 1.1723, time 6.34ms\n",
      "iter 538: loss 0.5018, time 6.31ms\n",
      "iter 539: loss 0.8547, time 7.61ms\n",
      "iter 540: loss 0.4305, time 7.59ms\n",
      "iter 541: loss 0.5295, time 7.44ms\n",
      "iter 542: loss 0.8337, time 7.55ms\n",
      "iter 543: loss 0.5470, time 7.97ms\n",
      "iter 544: loss 0.7311, time 7.93ms\n",
      "iter 545: loss 0.3471, time 7.64ms\n",
      "iter 546: loss 0.9511, time 8.19ms\n",
      "iter 547: loss 0.6434, time 7.91ms\n",
      "iter 548: loss 1.1461, time 7.37ms\n",
      "iter 549: loss 2.0192, time 7.81ms\n",
      "iter 550: loss 1.7291, time 8.23ms\n",
      "iter 551: loss 1.2099, time 8.07ms\n",
      "iter 552: loss 0.3421, time 6.67ms\n",
      "iter 553: loss 1.1592, time 7.04ms\n",
      "iter 554: loss 0.5497, time 6.66ms\n",
      "iter 555: loss 0.4483, time 6.73ms\n",
      "iter 556: loss 1.3795, time 6.61ms\n",
      "iter 557: loss 0.7926, time 6.48ms\n",
      "iter 558: loss 1.0074, time 6.31ms\n",
      "iter 559: loss 0.3495, time 6.28ms\n",
      "iter 560: loss 0.9575, time 6.35ms\n",
      "iter 561: loss 0.3446, time 6.34ms\n",
      "iter 562: loss 0.4458, time 6.51ms\n",
      "iter 563: loss 1.0405, time 7.21ms\n",
      "iter 564: loss 0.7825, time 7.02ms\n",
      "iter 565: loss 1.0811, time 7.16ms\n",
      "iter 566: loss 0.5757, time 6.77ms\n",
      "iter 567: loss 0.4441, time 6.94ms\n",
      "iter 568: loss 1.3875, time 6.53ms\n",
      "iter 569: loss 0.8704, time 6.87ms\n",
      "iter 570: loss 0.7328, time 7.13ms\n",
      "iter 571: loss 0.5477, time 6.53ms\n",
      "iter 572: loss 0.4512, time 6.72ms\n",
      "iter 573: loss 0.3337, time 6.49ms\n",
      "iter 574: loss 1.1578, time 6.93ms\n",
      "iter 575: loss 0.4316, time 7.67ms\n",
      "iter 576: loss 0.7384, time 6.85ms\n",
      "iter 577: loss 0.5370, time 6.59ms\n",
      "iter 578: loss 0.4937, time 6.88ms\n",
      "iter 579: loss 1.0149, time 6.51ms\n",
      "iter 580: loss 0.5536, time 6.38ms\n",
      "iter 581: loss 0.6582, time 6.75ms\n",
      "iter 582: loss 0.4754, time 6.35ms\n",
      "iter 583: loss 1.0663, time 6.74ms\n",
      "iter 584: loss 1.1807, time 6.46ms\n",
      "iter 585: loss 0.6839, time 6.48ms\n",
      "iter 586: loss 1.0651, time 6.48ms\n",
      "iter 587: loss 0.9708, time 6.34ms\n",
      "iter 588: loss 0.5953, time 6.22ms\n",
      "iter 589: loss 0.9500, time 6.29ms\n",
      "iter 590: loss 0.5468, time 6.14ms\n",
      "iter 591: loss 1.1104, time 6.27ms\n",
      "iter 592: loss 1.1616, time 6.90ms\n",
      "iter 593: loss 1.1349, time 6.24ms\n",
      "iter 594: loss 1.4761, time 6.39ms\n",
      "iter 595: loss 0.3459, time 6.26ms\n",
      "iter 596: loss 1.5445, time 6.99ms\n",
      "iter 597: loss 0.6603, time 7.90ms\n",
      "iter 598: loss 1.0508, time 8.39ms\n",
      "iter 599: loss 0.6376, time 8.99ms\n",
      "iter 600: loss 1.0827, time 7.41ms\n",
      "iter 601: loss 0.4382, time 7.23ms\n",
      "iter 602: loss 0.9177, time 7.51ms\n",
      "iter 603: loss 0.4293, time 9.14ms\n",
      "iter 604: loss 0.4435, time 7.99ms\n",
      "iter 605: loss 0.9214, time 7.86ms\n",
      "iter 606: loss 1.0935, time 7.93ms\n",
      "iter 607: loss 0.3432, time 7.90ms\n",
      "iter 608: loss 1.1327, time 7.55ms\n",
      "iter 609: loss 1.4360, time 8.82ms\n",
      "iter 610: loss 0.6750, time 8.48ms\n",
      "iter 611: loss 0.5224, time 8.24ms\n",
      "iter 612: loss 1.0773, time 8.40ms\n",
      "iter 613: loss 0.9258, time 8.67ms\n",
      "iter 614: loss 0.8151, time 8.90ms\n",
      "iter 615: loss 1.1507, time 9.09ms\n",
      "iter 616: loss 1.1056, time 8.34ms\n",
      "iter 617: loss 1.8538, time 8.49ms\n",
      "iter 618: loss 0.7140, time 8.64ms\n",
      "iter 619: loss 1.3568, time 8.11ms\n",
      "iter 620: loss 0.5274, time 7.97ms\n",
      "iter 621: loss 0.5271, time 7.26ms\n",
      "iter 622: loss 0.5238, time 7.19ms\n",
      "iter 623: loss 1.1634, time 6.78ms\n",
      "iter 624: loss 1.6772, time 7.01ms\n",
      "iter 625: loss 0.7249, time 7.85ms\n",
      "iter 626: loss 0.3312, time 7.18ms\n",
      "iter 627: loss 0.7138, time 6.63ms\n",
      "iter 628: loss 0.3291, time 6.55ms\n",
      "iter 629: loss 1.2200, time 6.64ms\n",
      "iter 630: loss 0.8951, time 6.64ms\n",
      "iter 631: loss 0.6062, time 6.51ms\n",
      "iter 632: loss 1.2481, time 7.20ms\n",
      "iter 633: loss 0.8852, time 7.06ms\n",
      "iter 634: loss 0.9631, time 7.14ms\n",
      "iter 635: loss 0.4059, time 6.68ms\n",
      "iter 636: loss 1.0714, time 6.89ms\n",
      "iter 637: loss 0.5096, time 6.68ms\n",
      "iter 638: loss 0.5078, time 9.88ms\n",
      "iter 639: loss 0.7104, time 8.47ms\n",
      "iter 640: loss 1.4397, time 12.33ms\n",
      "iter 641: loss 0.5173, time 7.77ms\n",
      "iter 642: loss 0.9975, time 38.87ms\n",
      "iter 643: loss 0.8061, time 14.83ms\n",
      "iter 644: loss 0.3207, time 8.70ms\n",
      "iter 645: loss 1.8046, time 7.65ms\n",
      "iter 646: loss 1.2242, time 7.95ms\n",
      "iter 647: loss 0.4230, time 7.20ms\n",
      "iter 648: loss 2.3238, time 7.80ms\n",
      "iter 649: loss 1.5918, time 7.23ms\n",
      "iter 650: loss 1.2951, time 7.08ms\n",
      "iter 651: loss 0.6824, time 6.94ms\n",
      "iter 652: loss 1.4492, time 7.15ms\n",
      "iter 653: loss 0.4744, time 7.32ms\n",
      "iter 654: loss 0.9493, time 7.05ms\n",
      "iter 655: loss 1.0955, time 7.13ms\n",
      "iter 656: loss 0.4260, time 7.07ms\n",
      "iter 657: loss 0.9113, time 7.02ms\n",
      "iter 658: loss 0.4809, time 7.04ms\n"
     ]
    }
   ],
   "source": [
    "from rgi.rgizero.train import Trainer, TrainConfig\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    model_name=\"connect4-e2e\",\n",
    "    model_version=\"v1\",\n",
    "\n",
    "    eval_interval = 250,  # keep frequent because we'll overfit\n",
    "    eval_iters = 200,\n",
    "    log_interval = 10_000,  # don't print too too often\n",
    "\n",
    "    # we expect to overfit on this small dataset, so only save when val improves\n",
    "    always_save_checkpoint = False,\n",
    "\n",
    "    gradient_accumulation_steps = 1,\n",
    "    batch_size = 64,\n",
    "\n",
    "    learning_rate = 1e-3,  # with baby networks can afford to go a bit higher\n",
    "    max_iters = 5000,\n",
    "    lr_decay_iters = 5000,  # make equal to max_iters usually\n",
    "    min_lr = 1e-4,  # learning_rate / 10 usually\n",
    "    beta2 = 0.99,  # make a bit bigger because number of tokens per iter is small\n",
    "\n",
    "    warmup_iters = 100,  # not super necessary potentially\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_config=train_config,\n",
    "    train_loader=trajectory_loader,\n",
    "    val_loader=trajectory_loader,  # TODO: Create separate validation loader\n",
    "    device=device\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
