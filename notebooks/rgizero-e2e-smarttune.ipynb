{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step run of alphazero self-play & training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports successful\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import asyncio\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Game and players\n",
    "from rgi.rgizero.games.connect4 import Connect4Game\n",
    "from rgi.rgizero.players.alphazero import AlphazeroPlayer\n",
    "from rgi.rgizero.players.alphazero import play_game\n",
    "\n",
    "from notebook_utils import reload_local_modules\n",
    "\n",
    "print(\"✅ Imports successful\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "assert device in ('cuda', 'mps'), f\"No accelerator available, device={device}\"\n",
    "\n",
    "# Allow asyncio to work with jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Increase numpy print width\n",
    "np.set_printoptions(linewidth=300)\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = True     # Set options to make debugger work properly. Single worker, etc.\n",
    "LOAD_MODEL = False\n",
    "TRAIN_MODEL = True\n",
    "MODEL_SIZE = \"tiny\"  # \"tiny\" or \"small\" or \"large\" or \"xl\"\n",
    "NUM_SIMULATIONS = 200\n",
    "RUN_GENERATIONS = True\n",
    "RUN_TOURNAMENT = False\n",
    "\n",
    "# If False, we still load previous games from disk.\n",
    "NUM_GAMES = 10_000\n",
    "MAX_TRAINING_EPOCHS = 10\n",
    "TRAIN_BATCH_SIZE = 2048\n",
    "MAX_TRAINING_ITERS = 1_000_000 // TRAIN_BATCH_SIZE\n",
    "CONFIG_ALIAS = f'trajectory_sims-{NUM_SIMULATIONS}_games-{NUM_GAMES}_size-{MODEL_SIZE}_train-{MAX_TRAINING_ITERS}_x1'\n",
    "NUM_GENERATIONS = 20\n",
    "\n",
    "# DEBUG: Update batch_size after config_alias\n",
    "MODEL_SIZE = \"small\"\n",
    "MAX_TRAINING_ITERS = 100_000_000 // TRAIN_BATCH_SIZE\n",
    "MAX_TRAINING_EPOCHS = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up history-wrapped game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using HistoryTrackingGame from module\n",
      "Game: Connect4Game, Players: 2, Actions: [1, 2, 3, 4, 5, 6, 7]\n",
      "Creating data dir:  /Users/rodo/src/rgi3/data/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1\n",
      "Creating model dir:  /Users/rodo/src/rgi3/models/rgizero-e2e/Connect4Game/trajectory_sims-200_games-10000_size-tiny_train-488_x1\n"
     ]
    }
   ],
   "source": [
    "from rgi.rgizero.games.history_wrapper import HistoryTrackingGame\n",
    "from rgi.rgizero.data.trajectory_dataset import Vocab\n",
    "from rgi.rgizero.common import TOKENS\n",
    "\n",
    "base_game, max_game_length = Connect4Game(connect_length=4), 7*6\n",
    "\n",
    "game = HistoryTrackingGame(base_game)\n",
    "state_0 = game.initial_state()\n",
    "block_size = max_game_length + 2\n",
    "all_actions = game.all_actions()\n",
    "action_vocab = Vocab(itos=[TOKENS.START_OF_GAME] + list(all_actions))\n",
    "n_max_context = max_game_length + 2\n",
    "game_name = base_game.__class__.__name__\n",
    "\n",
    "print(\"✅ Using HistoryTrackingGame from module\")\n",
    "print(f\"Game: {game_name}, Players: {game.num_players(state_0)}, Actions: {list(game.all_actions())}\")\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data\" / \"rgizero-e2e\" / game_name / CONFIG_ALIAS\n",
    "print(\"Creating data dir: \", DATA_DIR)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_DIR = Path.cwd().parent / \"models\" / \"rgizero-e2e\" / game_name / CONFIG_ALIAS\n",
    "print(\"Creating model dir: \", MODEL_DIR)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create random generation_0 model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_config_fields: {'n_embd', 'bias', 'n_layer', 'n_max_context', 'dropout', 'n_head'}\n",
      "train_config_fields: {'always_save_checkpoint', 'max_iters', 'weight_decay', 'decay_lr', 'batch_size', 'eval_only', 'learning_rate', 'max_epochs', 'lr_decay_iters', 'model_version', 'beta2', 'warmup_iters', 'wandb_log', 'dtype', 'gradient_accumulation_steps', 'min_lr', 'log_interval', 'compile', 'beta1', 'device', 'eval_interval', 'eval_iters', 'model_name', 'grad_clip'}\n",
      "Training initial model as baseline.\n",
      "## Initial Model, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'dropout=0.0'\n",
      "## Model dropout=0.0, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'beta2=0.99'\n",
      "## Model beta2=0.99, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'decay_lr=False'\n",
      "## Model decay_lr=False, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'learning_rate=0.1'\n",
      "## Model learning_rate=0.1, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'bias=True'\n",
      "## Model bias=True, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'max_iters=300'\n",
      "## Model max_iters=300, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'batch_size=16'\n",
      "## Model batch_size=16, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'n_embd=16'\n",
      "## Model n_embd=16, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'dropout=0.05'\n",
      "## Model dropout=0.05, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'dtype=float16'\n",
      "## Model dtype=float16, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'n_head=1'\n",
      "## Model n_head=1, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'batch_size=64'\n",
      "## Model batch_size=64, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'n_layer=3'\n",
      "## Model n_layer=3, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'weight_decay=0.1'\n",
      "## Model weight_decay=0.1, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'n_head=4'\n",
      "## Model n_head=4, loss=2.4571030139923096 elapsed=6.595702886581421s\n",
      "Attempting channge 'learning_rate=0.01'\n",
      "## Model learning_rate=0.01, loss=2.4571030139923096 elapsed=6.595702886581421s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_local_modules(verbose=False)\n",
    "\n",
    "# Parameters which will never be used for tuning.\n",
    "fixed_params = dict(\n",
    "    model_name='c4-tuning',\n",
    "    model_version='0.1',\n",
    "    num_players = game.num_players(state_0),\n",
    "    vocab_size = action_vocab.vocab_size,\n",
    "    num_genrations = NUM_GENERATIONS,\n",
    "    data_dir = DATA_DIR,\n",
    "\n",
    "    eval_iters = 200,\n",
    "    log_interval = 1000,\n",
    "    eval_interval = 10_000,\n",
    "\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "INITIAL_LEARNING_RATE = 0.05\n",
    "\n",
    "initial_params = dict(\n",
    "    n_layer=2,\n",
    "    n_head=2,\n",
    "    n_embd=8,  # tiny model\n",
    "\n",
    "    n_max_context=n_max_context,\n",
    "    batch_size = 32,\n",
    "    gradient_accumulation_steps = 1,\n",
    "\n",
    "    max_iters=100,\n",
    "    max_epochs=1_000_000, # Make max_epoch high, rely on max_iters to stop.\n",
    "        \n",
    "    learning_rate = INITIAL_LEARNING_RATE,    \n",
    "    decay_lr = True,  # whether to decay the learning rate\n",
    "    lr_decay_iters = 100,  # make equal to max_iters usually\n",
    "    min_lr = INITIAL_LEARNING_RATE / 10,  # learning_rate / 10 usually\n",
    "    warmup_iters = 0,  # not super necessary potentially\n",
    "\n",
    "    weight_decay = 1e-1,\n",
    "    beta1 = 0.9,\n",
    "    beta2 = 0.95,\n",
    "    grad_clip = 1.0,  # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "    dtype = \"float16\",\n",
    "\n",
    "    dropout = 0.0,\n",
    "    bias = False,  # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    ")\n",
    "\n",
    "tune_options = dict(\n",
    "    n_layer = [2, 3, 4, 5, 6, 8, 10, 12, 16, 32],\n",
    "    # n_head = [1, 2, 4, 8, 16, 32],   # Needs to be calcualted to ensure n_embed % n_head == 0\n",
    "    n_embd = [8, 16, 32, 64, 128, 256, 512, 1024],\n",
    "\n",
    "    n_max_context = [initial_params['n_max_context']],\n",
    "    batch_size = [16, 32, 64, 128, 256, 512, 1024],\n",
    "    gradient_accumulation_steps = [1],  # TODO: We only support 1 for now. This fails is we don't have an exact multiple of the batch size per epoch.\n",
    "\n",
    "    max_iters = [100, 300, 1_000, 3_000, 10_000, 30_000, 100_000, 300_000],\n",
    "    max_epochs = [1_000_000], # Make max_epoch high, rely on max_iters to stop.\n",
    "    \n",
    "    learning_rate = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "    decay_lr = [False, True],\n",
    "\n",
    "    beta1 = [0.9],\n",
    "    beta2 = [0.95, 0.99],\n",
    "\n",
    "    weight_decay = [0.01, 0.1],\n",
    "    grad_clip = [0,0, 1.0],  # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "    dtype = [\"bfloat16\", \"float16\"],\n",
    "    dropout = [0.0, 0.01, 0.05, 0.1],\n",
    "    bias = [True, False],    \n",
    ")\n",
    "\n",
    "_n_head_options = [1, 2, 4, 8, 16, 32]\n",
    "computed_tune_options = dict(\n",
    "    min_lr = lambda opt: [opt['learning_rate'] / 10],\n",
    "    lr_decay_iters = lambda opt: [opt['max_iters']],\n",
    "    warmup_iters = lambda opt: [x for x in [0, 100, 1000] if x < opt['lr_decay_iters']] if opt['decay_lr'] else [0],\n",
    "    n_head = lambda opt: [n for n in _n_head_options if opt['n_embd'] % n == 0],\n",
    ")\n",
    "\n",
    "TUNER_VERSION = \"0.0.3-smart\"\n",
    "\n",
    "from rgi.rgizero.models.tuner import Tuner\n",
    "\n",
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=1.00)\n",
    "tuner.autotune_smart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initial model as baseline.\n",
      "## Initial Model, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Expected score ('n_embd', 32) -> 2.391762519116495\n",
      "Expected score ('batch_size', 256) -> 2.412680541113729\n",
      "Expected score ('batch_size', 64) -> 2.4138263496808836\n",
      "Expected score ('lr_decay_iters', 1000) -> 2.4145058044348007\n",
      "Expected score ('max_iters', 1000) -> 2.4145058044348007\n",
      "Expected score ('n_head', 1) -> 2.421457539399465\n",
      "Expected score ('n_embd', 64) -> 2.4241771759113333\n",
      "Expected score ('learning_rate', 0.001) -> 2.4325078189373017\n",
      "Expected score ('min_lr', 0.0001) -> 2.4325078189373017\n",
      "Expected score ('n_embd', 16) -> 2.4335869294239414\n",
      "Expected score ('bias', True) -> 2.439599448499225\n",
      "Expected score ('batch_size', 128) -> 2.4508042148749034\n",
      "Expected score ('beta2', 0.99) -> 2.453751447673197\n",
      "Expected score ('lr_decay_iters', 300) -> 2.4581626067675795\n",
      "Expected score ('max_iters', 300) -> 2.4581626067675795\n",
      "Expected score ('n_head', 2) -> 2.4609193782188274\n",
      "Expected score ('warmup_iters', 100) -> 2.462061220626036\n",
      "Expected score ('batch_size', 512) -> 2.4628858879322313\n",
      "Expected score ('batch_size', 32) -> 2.4648077904690737\n",
      "Expected score ('dropout', 0.0) -> 2.465355165976233\n",
      "Expected score ('weight_decay', 0.01) -> 2.474131735466622\n",
      "Expected score ('n_head', 32) -> 2.4746965421570675\n",
      "Expected score ('n_embd', 8) -> 2.4759383319989103\n",
      "Expected score ('warmup_iters', 0) -> 2.478218598728843\n",
      "Expected score ('grad_clip', 1.0) -> 2.4833055130640664\n",
      "Expected score ('dropout', 0.1) -> 2.4852451531092328\n",
      "Expected score ('learning_rate', 0.05) -> 2.4891377662618956\n",
      "Expected score ('min_lr', 0.005) -> 2.4891377662618956\n",
      "Expected score ('lr_decay_iters', 100) -> 2.49125063725784\n",
      "Expected score ('max_iters', 100) -> 2.49125063725784\n",
      "Expected score ('learning_rate', 0.1) -> 2.4913401743828083\n",
      "Expected score ('min_lr', 0.01) -> 2.4913401743828083\n",
      "Expected score ('n_layer', 10) -> 2.492179251909256\n",
      "Expected score ('n_layer', 12) -> 2.4957417106628417\n",
      "Expected score ('batch_size', 16) -> 2.49807139141219\n",
      "Expected score ('dtype', 'float16') -> 2.513429921555432\n",
      "Expected score ('learning_rate', 0.5) -> 2.5145410390032663\n",
      "Expected score ('min_lr', 0.05) -> 2.5145410390032663\n",
      "Expected score ('decay_lr', False) -> 2.5183435072898868\n",
      "Expected score ('n_layer', 2) -> 2.5368939989381563\n",
      "Expected score ('learning_rate', 0.005) -> 2.5502153278200814\n",
      "Expected score ('min_lr', 0.0005) -> 2.5502153278200814\n",
      "Expected score ALL -> 2.5519824046381125\n",
      "Expected score ('beta1', 0.9) -> 2.5519824046381125\n",
      "Expected score ('gradient_accumulation_steps', 1) -> 2.5519824046381125\n",
      "Expected score ('max_epochs', 1000000) -> 2.5519824046381125\n",
      "Expected score ('n_max_context', 44) -> 2.5519824046381125\n",
      "Expected score ('grad_clip', 0) -> 2.5523190560673967\n",
      "Expected score ('decay_lr', True) -> 2.5551220350572796\n",
      "Expected score ('dtype', 'bfloat16') -> 2.5629801349218857\n",
      "Expected score ('weight_decay', 0.1) -> 2.5691280877294522\n",
      "Expected score ('lr_decay_iters', 3000) -> 2.5732864219901943\n",
      "Expected score ('max_iters', 3000) -> 2.5732864219901943\n",
      "Expected score ('bias', False) -> 2.5751200720784713\n",
      "Expected score ('n_layer', 3) -> 2.582228527829403\n",
      "Expected score ('learning_rate', 0.01) -> 2.58387135077117\n",
      "Expected score ('min_lr', 0.001) -> 2.58387135077117\n",
      "Expected score ('n_head', 4) -> 2.590869908972698\n",
      "Expected score ('n_layer', 4) -> 2.5940749103934677\n",
      "Expected score ('n_embd', 128) -> 2.6209731094904662\n",
      "Expected score ('n_head', 16) -> 2.6238856861491997\n",
      "Expected score ('warmup_iters', 1000) -> 2.6261456276813018\n",
      "Expected score ('beta2', 0.95) -> 2.6288588057410887\n",
      "Expected score ('n_head', 8) -> 2.653068730678964\n",
      "Expected score ('dropout', 0.05) -> 2.700555063991836\n",
      "Expected score ('dropout', 0.01) -> 2.7091335288359795\n",
      "Expected score ('batch_size', 1024) -> 3.062939420634625\n",
      "Expected score ('n_embd', 256) -> 3.268540717088259\n",
      "Expected score ('lr_decay_iters', 10000) -> 3.3118874250991004\n",
      "Expected score ('max_iters', 10000) -> 3.3118874250991004\n",
      "Expected score ('n_embd', 512) -> 5.14505460302035\n",
      "Attempting channge 'max_iters=1000'\n",
      "## Model max_iters=1000, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'learning_rate=0.05'\n",
      "## Model learning_rate=0.05, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'decay_lr=False'\n",
      "## Model decay_lr=False, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'warmup_iters=100'\n",
      "## Model warmup_iters=100, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'bias=True'\n",
      "## Model bias=True, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'weight_decay=0.01'\n",
      "## Model weight_decay=0.01, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'learning_rate=0.005'\n",
      "## Model learning_rate=0.005, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'n_head=4'\n",
      "## Model n_head=4, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'dtype=float16'\n",
      "## Model dtype=float16, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'n_embd=32'\n",
      "## Model n_embd=32, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'n_head=16'\n",
      "## Model n_head=16, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'batch_size=128'\n",
      "## Model batch_size=128, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'n_layer=3'\n",
      "## Model n_layer=3, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'batch_size=512'\n",
      "## Model batch_size=512, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'beta2=0.95'\n",
      "## Model beta2=0.95, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'n_embd=128'\n",
      "## Model n_embd=128, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'dropout=0.01'\n",
      "## Model dropout=0.01, loss=2.1770522594451904 elapsed=74.7136869430542s\n",
      "Attempting channge 'max_iters=10000'\n",
      "## Model max_iters=10000, loss=2.1770522594451904 elapsed=74.7136869430542s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.10)\n",
    "tuner.autotune_smart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initial model as baseline.\n",
      "## Initial Model, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'learning_rate=0.005'\n",
      "## Model learning_rate=0.005, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'dtype=float16'\n",
      "## Model dtype=float16, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'bias=True'\n",
      "## Model bias=True, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'beta2=0.99'\n",
      "## Model beta2=0.99, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'n_layer=4'\n",
      "## Model n_layer=4, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'dropout=0.05'\n",
      "## Model dropout=0.05, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'n_head=8'\n",
      "## Model n_head=8, loss=2.119516372680664 elapsed=419.40264201164246s\n",
      "Attempting channge 'dropout=0.0'\n",
      "model_config=TransformerConfig(n_max_context=44, n_layer=3, n_head=4, n_embd=128, dropout=0.0, bias=False)\n",
      "train_config=TrainConfig(model_name='c4-tuning', model_version='0.1', eval_interval=10000, log_interval=1000, eval_iters=200, eval_only=False, always_save_checkpoint=True, wandb_log=False, gradient_accumulation_steps=1, batch_size=1024, learning_rate=0.01, max_epochs=1000000, max_iters=3000, weight_decay=0.1, beta1=0.9, beta2=0.95, grad_clip=0, decay_lr=True, warmup_iters=1000, lr_decay_iters=3000, min_lr=0.001, device='mps', dtype='bfloat16', compile=False)\n",
      "num decayed parameter tensors: 15, with 596,736 parameters\n",
      "num non-decayed parameter tensors: 9, with 906 parameters\n",
      "using fused AdamW: False\n",
      "step 0: train loss 2.8567, val loss 2.8557\n",
      "iter 0/176/3000: loss 2.8540, time 14.10s, iter_time: 0.00ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m tuner = Tuner(\n\u001b[32m      2\u001b[39m     fixed_params=fixed_params.copy(),\n\u001b[32m      3\u001b[39m     initial_params=initial_params.copy(),\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     cache_version=TUNER_VERSION,\n\u001b[32m      7\u001b[39m     target_improvement_per_minute=\u001b[32m0.001\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautotune_smart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/models/tuner.py:347\u001b[39m, in \u001b[36mTuner.autotune_smart\u001b[39m\u001b[34m(self, max_generations)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m generation < max_generations:\n\u001b[32m    346\u001b[39m     candidate_params_list = \u001b[38;5;28mself\u001b[39m.select_candidate_params()\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_find_improvement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params_list\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    348\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    349\u001b[39m     generation += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/models/tuner.py:357\u001b[39m, in \u001b[36mTuner._find_improvement\u001b[39m\u001b[34m(self, candidate_params_list)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, params \u001b[38;5;129;01min\u001b[39;00m candidate_params_list:\n\u001b[32m    356\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting channge \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     loss, elapsed, loss_dict, model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_and_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m     is_improved = \u001b[38;5;28mself\u001b[39m.maybe_update_best_param(loss, elapsed, params, loss_dict)\n\u001b[32m    359\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m## Model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.best_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elapsed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.best_loss_elapsed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/models/tuner.py:207\u001b[39m, in \u001b[36mTuner.train_and_compute_loss\u001b[39m\u001b[34m(self, params, reload_model)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m         loss_dict, elapsed, model = \u001b[43mtrain_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m         loss_dict[\u001b[33m'\u001b[39m\u001b[33melapsed\u001b[39m\u001b[33m'\u001b[39m] = elapsed\n\u001b[32m    209\u001b[39m         loss_dict[\u001b[33m'\u001b[39m\u001b[33mparam_hash\u001b[39m\u001b[33m'\u001b[39m] = param_key_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/models/tuner.py:102\u001b[39m, in \u001b[36mtrain_with\u001b[39m\u001b[34m(vocab_size, num_players, num_genrations, device, n_max_context, data_dir, **overrides)\u001b[39m\n\u001b[32m     98\u001b[39m model = create_random_model(model_config, action_vocab_size=vocab_size, num_players=num_players, seed=\u001b[32m42\u001b[39m, device=device)\n\u001b[32m    100\u001b[39m training_splits = [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mgen-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m generation_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_genrations+\u001b[32m1\u001b[39m)]\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m model, trainer = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_max_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_max_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m loss_dict = trainer.estimate_loss()\n\u001b[32m    104\u001b[39m loss_dict = {k: \u001b[38;5;28mfloat\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loss_dict.items()}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/models/tuner.py:76\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, training_splits, train_config, device, n_max_context, data_dir, num_workers)\u001b[39m\n\u001b[32m     64\u001b[39m train_loader, val_loader = build_trajectory_loader(\n\u001b[32m     65\u001b[39m     data_dir, training_splits, block_size=n_max_context, batch_size=train_config.batch_size,\n\u001b[32m     66\u001b[39m     device=device, workers=num_workers, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     68\u001b[39m trainer = Trainer(\n\u001b[32m     69\u001b[39m     model=model,\n\u001b[32m     70\u001b[39m     train_config=train_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     device=device\n\u001b[32m     74\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, trainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/train.py:133\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_config.max_epochs):\n\u001b[32m    132\u001b[39m         \u001b[38;5;66;03m# print(f\"Training epoch {epoch_id} of {self.train_config.max_epochs}\")\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m         \u001b[38;5;66;03m# termination conditions\u001b[39;00m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_num > \u001b[38;5;28mself\u001b[39m.train_config.max_iters:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/train.py:181\u001b[39m, in \u001b[36mTrainer.train_epoch\u001b[39m\u001b[34m(self, epoch_id)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx:\n\u001b[32m    180\u001b[39m     batch_id, data_batch = \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     logits, loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     loss = (\n\u001b[32m    183\u001b[39m         loss / \u001b[38;5;28mself\u001b[39m.train_config.gradient_accumulation_steps\n\u001b[32m    184\u001b[39m     )  \u001b[38;5;66;03m# scale the loss to account for gradient accumulation\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# backward pass, with gradient scaling if training in fp16\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/models/action_history_transformer.py:106\u001b[39m, in \u001b[36mActionHistoryTransformer.forward\u001b[39m\u001b[34m(self, idx, policy_target, value_target, padding_mask)\u001b[39m\n\u001b[32m    104\u001b[39m     flat_policy_logits = flat_policy_logits[flat_padding_mask]\n\u001b[32m    105\u001b[39m     flat_policy_target = flat_policy_target[flat_padding_mask]\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[43mvalidate_probabilities_or_die\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_policy_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Calcualte the average loss per unpadded tokens.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# note: We may want to experiment with average per batch?\u001b[39;00m\n\u001b[32m    109\u001b[39m policy_loss = F.cross_entropy(flat_policy_logits, flat_policy_target, reduction=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/rgi3/src/rgi/rgizero/models/action_history_transformer.py:25\u001b[39m, in \u001b[36mvalidate_probabilities_or_die\u001b[39m\u001b[34m(tensor, dim, tol)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrgi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrgizero\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malphazero\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NetworkEvaluator, NetworkEvaluatorResult\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# TODO: Move to util class.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_probabilities_or_die\u001b[39m(tensor: torch.Tensor, dim: \u001b[38;5;28mint\u001b[39m = \u001b[32m1\u001b[39m, tol: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1e-6\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# 1. Check if all values are >= 0 and <= 1\u001b[39;00m\n\u001b[32m     27\u001b[39m     in_range = (tensor >= \u001b[32m0\u001b[39m).all() \u001b[38;5;129;01mand\u001b[39;00m (tensor <= \u001b[32m1\u001b[39m).all()\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_range:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tuner = Tuner(\n",
    "    fixed_params=fixed_params.copy(),\n",
    "    initial_params=initial_params.copy(),\n",
    "    tune_options=tune_options.copy(), \n",
    "    computed_tune_options=computed_tune_options.copy(),\n",
    "    cache_version=TUNER_VERSION,\n",
    "    target_improvement_per_minute=0.001)\n",
    "tuner.autotune_smart()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
